From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from mgamail.intel.com (mgamail.intel.com [198.175.65.12])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 160CA846C;
	Fri, 15 Dec 2023 05:05:03 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=none dis=none) header.from=intel.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=intel.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=intel.com header.i=@intel.com header.b="F21HQ4Ba"
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple;
  d=intel.com; i=@intel.com; q=dns/txt; s=Intel;
  t=1702616704; x=1734152704;
  h=from:to:cc:subject:in-reply-to:references:date:
   message-id:mime-version:content-transfer-encoding;
  bh=zVDTobLFJhMgqVsvxBgPsU6QiHyyeU7rAJxmclOn3CI=;
  b=F21HQ4BaQcYH3+7/Fryu98kelSJuwRLRI/KIDq6xa0SE+V2GUwoOg1A1
   gL/DXWVKPHwv8bkJLc7BUfGSP20cyOjyq8GbJj/LICBdleQlYQKy3U1NI
   WSBlZYkUbH1X9P2f271vHTRKqFDT5BMq1KbhXHOoL1zbbffq+855tl/zR
   W1F78eZTmNlpKcldF6k3rMuFr+HZ9F+s5qRfneqYUIOQOJOYkwU9UkWmU
   8rPXEgYxQfBdYNVbrLHEHj7cOE8Y5U3jSXx38Lm15Kmd9Qce/4KSGoYYE
   3458Zl4m8ei0UwW73orfhiV6oIYLQ9XmWBDiGX3gCuu7ICYna5S6HHAk9
   A==;
X-IronPort-AV: E=McAfee;i="6600,9927,10924"; a="2398142"
X-IronPort-AV: E=Sophos;i="6.04,277,1695711600"; 
   d="scan'208";a="2398142"
Received: from orsmga008.jf.intel.com ([10.7.209.65])
  by orvoesa104.jf.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 14 Dec 2023 21:05:04 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=McAfee;i="6600,9927,10924"; a="803585229"
X-IronPort-AV: E=Sophos;i="6.04,277,1695711600"; 
   d="scan'208";a="803585229"
Received: from yhuang6-desk2.sh.intel.com (HELO yhuang6-desk2.ccr.corp.intel.com) ([10.238.208.55])
  by orsmga008-auth.jf.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 14 Dec 2023 21:04:59 -0800
From: "Huang, Ying" <ying.huang@intel.com>
To: <sthanneeru.opensrc@micron.com>
Cc: <linux-cxl@vger.kernel.org>,  <linux-mm@kvack.org>,
  <sthanneeru@micron.com>,  <aneesh.kumar@linux.ibm.com>,
  <dan.j.williams@intel.com>,  <gregory.price@memverge.com>,
  <mhocko@suse.com>,  <tj@kernel.org>,  <john@jagalactic.com>,
  <emirakhur@micron.com>,  <vtavarespetr@micron.com>,
  <Ravis.OpenSrc@micron.com>,  <Jonathan.Cameron@huawei.com>,
  <linux-kernel@vger.kernel.org>
Subject: Re: [RFC PATCH v2 0/2] Node migration between memory tiers
In-Reply-To: <20231213175329.594-1-sthanneeru.opensrc@micron.com> (sthanneeru
	opensrc's message of "Wed, 13 Dec 2023 23:23:27 +0530")
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
Date: Fri, 15 Dec 2023 13:02:59 +0800
Message-ID: <87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
User-Agent: Gnus/5.13 (Gnus v5.13)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

<sthanneeru.opensrc@micron.com> writes:

> From: Srinivasulu Thanneeru <sthanneeru.opensrc@micron.com>
>
> The memory tiers feature allows nodes with similar memory types
> or performance characteristics to be grouped together in a
> memory tier. However, there is currently no provision for
> moving a node from one tier to another on demand.
>
> This patch series aims to support node migration between tiers
> on demand by sysadmin/root user using the provided sysfs for
> node migration.
>
> To migrate a node to a tier, the corresponding node=E2=80=99s sysfs
> memtier_override is written with target tier id.
>
> Example: Move node2 to memory tier2 from its default tier(i.e 4)
>
> 1. To check current memtier of node2
> $cat  /sys/devices/system/node/node2/memtier_override
> memory_tier4
>
> 2. To migrate node2 to memory_tier2
> $echo 2 > /sys/devices/system/node/node2/memtier_override
> $cat  /sys/devices/system/node/node2/memtier_override
> memory_tier2
>
> Usecases:
>
> 1. Useful to move cxl nodes to the right tiers from userspace, when
>    the hardware fails to assign the tiers correctly based on
>    memorytypes.
>
>    On some platforms we have observed cxl memory being assigned to
>    the same tier as DDR memory. This is arguably a system firmware
>    bug, but it is true that tiers represent *ranges* of performance
>    and we believe it's important for the system operator to have
>    the ability to override bad firmware or OS decisions about tier
>    assignment as a fail-safe against potential bad outcomes.
>
> 2. Useful if we want interleave weights to be applied on memory tiers
>    instead of nodes.
> In a previous thread, Huang Ying <ying.huang@intel.com> thought
> this feature might be useful to overcome limitations of systems
> where nodes with different bandwidth characteristics are grouped
> in a single tier.
> https://lore.kernel.org/lkml/87a5rw1wu8.fsf@yhuang6-desk2.ccr.corp.intel.=
com/
>
> =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
> Version Notes:
>
> V2 : Changed interface to memtier_override from adistance_offset.
> memtier_override was recommended by
> 1. John Groves <john@jagalactic.com>
> 2. Ravi Shankar <ravis.opensrc@micron.com>
> 3. Brice Goglin <Brice.Goglin@inria.fr>

It appears that you ignored my comments for V1 as follows ...

https://lore.kernel.org/lkml/87o7f62vur.fsf@yhuang6-desk2.ccr.corp.intel.co=
m/
https://lore.kernel.org/lkml/87jzpt2ft5.fsf@yhuang6-desk2.ccr.corp.intel.co=
m/
https://lore.kernel.org/lkml/87a5qp2et0.fsf@yhuang6-desk2.ccr.corp.intel.co=
m/

--
Best Regards,
Huang, Ying

> V1 : Introduced adistance_offset sysfs.
>
> =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
>
> Srinivasulu Thanneeru (2):
>   base/node: Add sysfs for memtier_override
>   memory tier: Support node migration between tiers
>
>  Documentation/ABI/stable/sysfs-devices-node |  7 ++
>  drivers/base/node.c                         | 47 ++++++++++++
>  include/linux/memory-tiers.h                | 11 +++
>  include/linux/node.h                        | 11 +++
>  mm/memory-tiers.c                           | 85 ++++++++++++---------
>  5 files changed, 125 insertions(+), 36 deletions(-)

From mboxrd@z Thu Jan  1 00:00:00 1970
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=micron.com header.i=@micron.com header.b="gKv4X5l/"
Received: from NAM12-BN8-obe.outbound.protection.outlook.com (mail-bn8nam12on2065.outbound.protection.outlook.com [40.107.237.65])
	by lindbergh.monkeyblade.net (Postfix) with ESMTPS id 3A0A511A;
	Wed, 13 Dec 2023 09:54:10 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=PQKv6L3DcElaSzL/DbCr3zoN6SRPiFoshMSH3S4zU7cRr2jjCK+1irIO01VM/AsXi01lg45xEtYVDrGKt3NC7DQ3c8lOGJbeY12vM+cKn8zTzTV8sHufBhLyAWAMVLQ01aUvrWIgeWu+gO6H18bH0JgYpNLyRc1YaEvGEf+Q0UxH3mxttb2CNi9Pkf05oWubxbACk5aFFb+mP5ZZLEK57TMQk/P+ix2aHhYRv9CYos83mq14xyHxFYtUsaZpo0VkS/OJ/bSyFdPr1iykELMWIm25vcII4zOzE0UAfI0USiF+Vn+CXxG4VZt6ZD1KYEDHcOBJ1BqIdyZ2PyWsSTTuVQ==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-AntiSpam-MessageData-ChunkCount:X-MS-Exchange-AntiSpam-MessageData-0:X-MS-Exchange-AntiSpam-MessageData-1;
 bh=vTNf944D++5RAaxuPuIOcMEvY0ECfOxgHNlMz9SZ+9w=;
 b=dPcKcSmfiknRk1HEZs6KCqGA9wy77lcyFOy7YRqSFt7Vyv8cEwjx6Sjo1yChGABvXjqDmOJoKVzMPZBw+e8lL27EuOApv5oG/5/ZWE0U3BYle9TH3pMsdtpMm72NkmaGkc4oz17FA1ZB38/VuSVoYd73t5+B2XC51Ei029nYh7Am9zsF2DSR79zCHxUfT9+cfbrKQYwvz1gZgBceVY/88bgkcOj5t9C/1MVkgwBH9l5jvDc2Gzmcjs00zKziX55wdJujwUGNPHUFodYxVTlP33txhnaGALxBhHbSVuSvQdbeNa9068Ea7Xr2q0OebERuUmuVLnHDTiVonb4IvhKUCA==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass (sender ip is
 137.201.242.130) smtp.rcpttodomain=vger.kernel.org smtp.mailfrom=micron.com;
 dmarc=pass (p=reject sp=reject pct=100) action=none header.from=micron.com;
 dkim=none (message not signed); arc=none (0)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=micron.com;
 s=selector2;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=vTNf944D++5RAaxuPuIOcMEvY0ECfOxgHNlMz9SZ+9w=;
 b=gKv4X5l/Pfu7KRGEwb0Wjx/VZANowDg4sqSQhKn5xINhsdRbMi2yEsOKhyJa5icVBaqNohmfwyamw/ddqWulTrSCFzuyz62wjHxoWne+RnwfEz2NEMjkwAfEYbQnFdI90H5Rkmm+vZceSLC8EYjV77hnNC7d5AWJBCRxK45vFIM2QFYmpOo+U6xMcZDpQCjCz6JmJRs/PTbmJkFGuiLChOaJlfaVC7a965NZKTfRmpBRBStFmXEbrKC52f4QG7xUsb8wfHy4+bUOfIEXwovLAZ7hoqvluYD1nK7gERw97BeeODvemOb7xKLWkyZdQa/173L2zHuInYKrtwvjQGZILg==
Received: from CH0P221CA0046.NAMP221.PROD.OUTLOOK.COM (2603:10b6:610:11d::19)
 by DM4PR08MB8673.namprd08.prod.outlook.com (2603:10b6:8:190::10) with
 Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.7113.8; Wed, 13 Dec
 2023 17:54:06 +0000
Received: from CY4PEPF0000FCC4.namprd03.prod.outlook.com
 (2603:10b6:610:11d:cafe::d0) by CH0P221CA0046.outlook.office365.com
 (2603:10b6:610:11d::19) with Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.7091.26 via Frontend
 Transport; Wed, 13 Dec 2023 17:54:06 +0000
X-MS-Exchange-Authentication-Results: spf=pass (sender IP is 137.201.242.130)
 smtp.mailfrom=micron.com; dkim=none (message not signed)
 header.d=none;dmarc=pass action=none header.from=micron.com;
Received-SPF: Pass (protection.outlook.com: domain of micron.com designates
 137.201.242.130 as permitted sender) receiver=protection.outlook.com;
 client-ip=137.201.242.130; helo=mail.micron.com; pr=C
Received: from mail.micron.com (137.201.242.130) by
 CY4PEPF0000FCC4.mail.protection.outlook.com (10.167.242.106) with Microsoft
 SMTP Server (version=TLS1_2, cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id
 15.20.7091.26 via Frontend Transport; Wed, 13 Dec 2023 17:54:06 +0000
Received: from BOW36EX19A.micron.com (137.201.85.33) by BOW36EX19A.micron.com
 (137.201.85.33) with Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.2.1258.27; Wed, 13 Dec
 2023 10:54:02 -0700
Received: from micron.com (10.3.116.19) by RestrictedRelay36EX19A.micron.com
 (137.201.85.33) with Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.2.1258.27 via Frontend
 Transport; Wed, 13 Dec 2023 10:53:56 -0700
From: <sthanneeru.opensrc@micron.com>
To: <sthanneeru.opensrc@micron.com>, <linux-cxl@vger.kernel.org>,
	<linux-mm@kvack.org>
CC: <sthanneeru@micron.com>, <aneesh.kumar@linux.ibm.com>,
	<dan.j.williams@intel.com>, <ying.huang@intel.com>,
	<gregory.price@memverge.com>, <mhocko@suse.com>, <tj@kernel.org>,
	<john@jagalactic.com>, <emirakhur@micron.com>, <vtavarespetr@micron.com>,
	<Ravis.OpenSrc@micron.com>, <Jonathan.Cameron@huawei.com>,
	<linux-kernel@vger.kernel.org>
Subject: [PATCH 2/2] memory tier: Support node migration between tiers
Date: Wed, 13 Dec 2023 23:23:29 +0530
Message-ID: <20231213175329.594-3-sthanneeru.opensrc@micron.com>
X-Mailer: git-send-email 2.25.1
In-Reply-To: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
Content-Type: text/plain
X-MT-Whitelisted: matched
X-EOPAttributedMessage: 0
X-MS-PublicTrafficType: Email
X-MS-TrafficTypeDiagnostic: CY4PEPF0000FCC4:EE_|DM4PR08MB8673:EE_
X-MS-Office365-Filtering-Correlation-Id: ae0d7293-1c6c-40d2-c3af-08dbfc048046
X-LD-Processed: f38a5ecd-2813-4862-b11b-ac1d563c806f,ExtAddr
X-EXT-ByPass: 1
X-MT-RULE-Whitelisted: Triggered
X-MS-Exchange-SenderADCheck: 1
X-MS-Exchange-AntiSpam-Relay: 0
X-Microsoft-Antispam: BCL:0;
X-Microsoft-Antispam-Message-Info: ORBEiw3+ZJXmX2+0UH0q98hwFgfOGz40DJnIjm9aBsnR5USLAUgaoMHltthNNIA8/1+zjW7dTX3iDK34rBExeJ26u40zPz/ucIzTnX5ajLROHuKtyqgWAba3jWbxhD5xkgGewJueP3RdaWsycW+DwIgVePV2Ks39PZa6gcsMATn01JHp8yEjka28dQCeHdOgQVpaR5vhh0ik4gRNKbFxmZFrRKgqpI0q4M2xoYqsg3jg5SBFEhUVBEF1SW5LDjZaPHpXasCG1INWZucOs8bv4cfdddyVm6jJrkh63aXAmuFisOorbTpj1V3O0taAFJBOVHvshmeV23ipzVEf/VPt+Id091BfoST05x0b7F6/T0dAjd9J/5Lt3XNRUmv7Rt6PjoaHUyfRZIOLAtxcmDZ7nE4UYHbS46YMZI+cCI65zLyqfs//tP7v2A/T2ueO50COC6LmGm6xq7Yxc84b9m3kQyU73Jt1yrjN0hga/mFbzweruqbjaf7VEX29LyIt1gcPt0w1QCcoRJkvNYTkBMdHDcoGO/0g2mYQ/SbZHFk5EjmC2aaPxjp0E2PGrkX4rlLijqZGjZFNBXBp84eDj5cq4l8qWVDHJ3CkASt8Jf2aABqeibfYROw/WK6fIVfQxyzG0zgngwJwIOUW+wkLoY9ZCkQiMWVANAE/GIh583pk5RYfnsZpq0eBQ4ArjTscjL7y32fNoQxsUAVPbrNZ+M8l/NyUiMiLr85FOgUeURokaHknO3IuqIQ8AlOi4kqRei0JAT20ciGtO+FaBeZKZPL+3w==
X-Forefront-Antispam-Report: CIP:137.201.242.130;CTRY:US;LANG:en;SCL:1;SRV:;IPV:NLI;SFV:NSPM;H:mail.micron.com;PTR:masquerade.micron.com;CAT:NONE;SFS:(13230031)(4636009)(136003)(376002)(396003)(39860400002)(346002)(230922051799003)(64100799003)(82310400011)(186009)(451199024)(1800799012)(36840700001)(40470700004)(46966006)(55016003)(40480700001)(40460700003)(70586007)(70206006)(54906003)(336012)(7636003)(82740400003)(356005)(36756003)(86362001)(36860700001)(47076005)(83380400001)(426003)(6286002)(26005)(1076003)(2616005)(2906002)(2876002)(316002)(110136005)(6666004)(478600001)(5660300002)(4326008)(8676002)(7696005)(41300700001)(8936002)(2101003);DIR:OUT;SFP:1101;
X-OriginatorOrg: micron.com
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 13 Dec 2023 17:54:06.4309
 (UTC)
X-MS-Exchange-CrossTenant-Network-Message-Id: ae0d7293-1c6c-40d2-c3af-08dbfc048046
X-MS-Exchange-CrossTenant-Id: f38a5ecd-2813-4862-b11b-ac1d563c806f
X-MS-Exchange-CrossTenant-OriginalAttributedTenantConnectingIp: TenantId=f38a5ecd-2813-4862-b11b-ac1d563c806f;Ip=[137.201.242.130];Helo=[mail.micron.com]
X-MS-Exchange-CrossTenant-AuthSource: CY4PEPF0000FCC4.namprd03.prod.outlook.com
X-MS-Exchange-CrossTenant-AuthAs: Anonymous
X-MS-Exchange-CrossTenant-FromEntityHeader: HybridOnPrem
X-MS-Exchange-Transport-CrossTenantHeadersStamped: DM4PR08MB8673

From: Srinivasulu Thanneeru <sthanneeru.opensrc@micron.com>

Node migration enables the grouping or migration of nodes
between tiers based on nodes' latencies and bandwidth characteristics.
Since nodes of the same memory-type can exist in different tiers and
can migrate from one tier to another, it is necessary to maintain
nodes per tier instead of maintaining a list of nodes grouped using
memory type(siblings) within the tier.

Signed-off-by: Srinivasulu Thanneeru <sthanneeru.opensrc@micron.com>
---
 drivers/base/node.c          |  6 ++++
 include/linux/memory-tiers.h |  5 +++
 include/linux/node.h         |  5 +++
 mm/memory-tiers.c            | 66 +++++++++++++++++-------------------
 4 files changed, 47 insertions(+), 35 deletions(-)

diff --git a/drivers/base/node.c b/drivers/base/node.c
index 788176b3585a..179d9004e4f3 100644
--- a/drivers/base/node.c
+++ b/drivers/base/node.c
@@ -597,6 +597,7 @@ static ssize_t memtier_override_store(struct device *dev,
 		return size;
 	ret = get_memtier_adistance_offset(nid, memtier);
 	node_devices[nid]->adistance_offset = ret;
+	node_memtier_change(nid);
 
 	return size;
 }
@@ -607,6 +608,11 @@ void set_node_memtierid(int node, int memtierid)
 	node_devices[node]->memtier = memtierid;
 }
 
+int get_node_adistance_offset(int node)
+{
+	return node_devices[node]->adistance_offset;
+}
+
 static struct attribute *node_dev_attrs[] = {
 	&dev_attr_meminfo.attr,
 	&dev_attr_numastat.attr,
diff --git a/include/linux/memory-tiers.h b/include/linux/memory-tiers.h
index 0dba8027e785..b323c2e2e417 100644
--- a/include/linux/memory-tiers.h
+++ b/include/linux/memory-tiers.h
@@ -54,6 +54,7 @@ int mt_set_default_dram_perf(int nid, struct node_hmem_attrs *perf,
 			     const char *source);
 int mt_perf_to_adistance(struct node_hmem_attrs *perf, int *adist);
 int get_memtier_adistance_offset(int node, int memtier);
+void node_memtier_change(int node);
 #ifdef CONFIG_MIGRATION
 int next_demotion_node(int node);
 void node_get_allowed_targets(pg_data_t *pgdat, nodemask_t *targets);
@@ -142,5 +143,9 @@ static inline int mt_perf_to_adistance(struct node_hmem_attrs *perf, int *adist)
 {
 	return -EIO;
 }
+
+static inline void node_memtier_change(int node)
+{
+}
 #endif	/* CONFIG_NUMA */
 #endif  /* _LINUX_MEMORY_TIERS_H */
diff --git a/include/linux/node.h b/include/linux/node.h
index 1c4f4be39db4..da679577a271 100644
--- a/include/linux/node.h
+++ b/include/linux/node.h
@@ -141,6 +141,7 @@ extern int register_memory_node_under_compute_node(unsigned int mem_nid,
 						   unsigned int cpu_nid,
 						   unsigned access);
 extern void set_node_memtierid(int node, int memtierid);
+extern int get_node_adistance_offset(int nid);
 #else
 static inline void node_dev_init(void)
 {
@@ -171,6 +172,10 @@ static inline void unregister_memory_block_under_nodes(struct memory_block *mem_
 static inline void set_node_memtierid(int node, int memtierid)
 {
 }
+static inline int get_node_adistance_offset(int nid)
+{
+	return 0;
+}
 #endif
 
 #define to_node(device) container_of(device, struct node, dev)
diff --git a/mm/memory-tiers.c b/mm/memory-tiers.c
index 31ed3c577836..66e1eae97e47 100644
--- a/mm/memory-tiers.c
+++ b/mm/memory-tiers.c
@@ -23,6 +23,8 @@ struct memory_tier {
 	struct device dev;
 	/* All the nodes that are part of all the lower memory tiers. */
 	nodemask_t lower_tier_mask;
+	/* Nodes linked to this tier*/
+	nodemask_t nodes;
 };
 
 struct demotion_nodes {
@@ -120,13 +122,7 @@ static inline struct memory_tier *to_memory_tier(struct device *device)
 
 static __always_inline nodemask_t get_memtier_nodemask(struct memory_tier *memtier)
 {
-	nodemask_t nodes = NODE_MASK_NONE;
-	struct memory_dev_type *memtype;
-
-	list_for_each_entry(memtype, &memtier->memory_types, tier_sibling)
-		nodes_or(nodes, nodes, memtype->nodes);
-
-	return nodes;
+	return memtier->nodes;
 }
 
 static void memory_tier_device_release(struct device *dev)
@@ -182,33 +178,22 @@ int get_memtier_adistance_offset(int node, int memtier)
 	return adistance_offset;
 }
 
-static struct memory_tier *find_create_memory_tier(struct memory_dev_type *memtype)
+static struct memory_tier *find_create_memory_tier(struct memory_dev_type *memtype,
+						   int tier_adistance)
 {
 	int ret;
 	bool found_slot = false;
 	struct memory_tier *memtier, *new_memtier;
-	int adistance = memtype->adistance;
+	int adistance;
 	unsigned int memtier_adistance_chunk_size = MEMTIER_CHUNK_SIZE;
 
 	lockdep_assert_held_once(&memory_tier_lock);
 
-	adistance = round_down(adistance, memtier_adistance_chunk_size);
-	/*
-	 * If the memtype is already part of a memory tier,
-	 * just return that.
-	 */
-	if (!list_empty(&memtype->tier_sibling)) {
-		list_for_each_entry(memtier, &memory_tiers, list) {
-			if (adistance == memtier->adistance_start)
-				return memtier;
-		}
-		WARN_ON(1);
-		return ERR_PTR(-EINVAL);
-	}
+	adistance = round_down(tier_adistance, memtier_adistance_chunk_size);
 
 	list_for_each_entry(memtier, &memory_tiers, list) {
 		if (adistance == memtier->adistance_start) {
-			goto link_memtype;
+			return memtier;
 		} else if (adistance < memtier->adistance_start) {
 			found_slot = true;
 			break;
@@ -238,11 +223,8 @@ static struct memory_tier *find_create_memory_tier(struct memory_dev_type *memty
 		put_device(&new_memtier->dev);
 		return ERR_PTR(ret);
 	}
-	memtier = new_memtier;
 
-link_memtype:
-	list_add(&memtype->tier_sibling, &memtier->memory_types);
-	return memtier;
+	return new_memtier;
 }
 
 static struct memory_tier *__node_get_memory_tier(int node)
@@ -500,7 +482,7 @@ static struct memory_tier *set_node_memory_tier(int node)
 	struct memory_tier *memtier;
 	struct memory_dev_type *memtype;
 	pg_data_t *pgdat = NODE_DATA(node);
-
+	int tier_adistance;
 
 	lockdep_assert_held_once(&memory_tier_lock);
 
@@ -511,11 +493,15 @@ static struct memory_tier *set_node_memory_tier(int node)
 
 	memtype = node_memory_types[node].memtype;
 	node_set(node, memtype->nodes);
-	memtier = find_create_memory_tier(memtype);
+	tier_adistance = get_node_adistance_offset(node);
+	tier_adistance = memtype->adistance + tier_adistance;
+
+	memtier = find_create_memory_tier(memtype, tier_adistance);
 	if (!IS_ERR(memtier)) {
 		rcu_assign_pointer(pgdat->memtier, memtier);
 		set_node_memtierid(node, memtier->dev.id);
 	}
+	node_set(node, memtier->nodes);
 	return memtier;
 }
 
@@ -551,11 +537,9 @@ static bool clear_node_memory_tier(int node)
 		synchronize_rcu();
 		memtype = node_memory_types[node].memtype;
 		node_clear(node, memtype->nodes);
-		if (nodes_empty(memtype->nodes)) {
-			list_del_init(&memtype->tier_sibling);
-			if (list_empty(&memtier->memory_types))
-				destroy_memory_tier(memtier);
-		}
+		node_clear(node, memtier->nodes);
+		if (nodes_empty(memtier->nodes))
+			destroy_memory_tier(memtier);
 		cleared = true;
 	}
 	return cleared;
@@ -578,7 +562,6 @@ struct memory_dev_type *alloc_memory_type(int adistance)
 		return ERR_PTR(-ENOMEM);
 
 	memtype->adistance = adistance;
-	INIT_LIST_HEAD(&memtype->tier_sibling);
 	memtype->nodes  = NODE_MASK_NONE;
 	kref_init(&memtype->kref);
 	return memtype;
@@ -618,6 +601,19 @@ void clear_node_memory_type(int node, struct memory_dev_type *memtype)
 }
 EXPORT_SYMBOL_GPL(clear_node_memory_type);
 
+void node_memtier_change(int node)
+{
+	struct memory_tier *memtier;
+
+	mutex_lock(&memory_tier_lock);
+	if (clear_node_memory_tier(node))
+		establish_demotion_targets();
+	memtier = set_node_memory_tier(node);
+	if (!IS_ERR(memtier))
+		establish_demotion_targets();
+	mutex_unlock(&memory_tier_lock);
+}
+
 static void dump_hmem_attrs(struct node_hmem_attrs *attrs, const char *prefix)
 {
 	pr_info(
-- 
2.25.1


From mboxrd@z Thu Jan  1 00:00:00 1970
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=micron.com header.i=@micron.com header.b="fNyKFD6P"
Received: from NAM11-CO1-obe.outbound.protection.outlook.com (mail-co1nam11on2080.outbound.protection.outlook.com [40.107.220.80])
	by lindbergh.monkeyblade.net (Postfix) with ESMTPS id 88C9311B;
	Wed, 13 Dec 2023 09:54:03 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=A6TvSv+FqV0QBX3Nqciauioymzm57GWsgFAynImzBerdj14IflvEwNzSQ2I5+KZEDYPf7iWp9aF10MfA3MMwZGUAMCp2/fAlQkZDBBYlPcXHYH3OlSlJGkB4EUC788IPUFlyU769xBQwjFcApLQv8mjuaLUY31+YZuY0XgNpqbvfTyfDDvXCijCWNbRSbz4rBDmMhFpPf9lsstThsH96mLStHb6aFj0IkE+sxgJyzH2rAFiGIAQeO5zrFt5H0B39oLt+GjTJ3O9Xg4COk2FYw0h/7Pe3z2SO2/5kcwD/WpyABmz0UuY/ih2kWljn+ffAAatFORyw5ZpRmsM5XvjCRA==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-AntiSpam-MessageData-ChunkCount:X-MS-Exchange-AntiSpam-MessageData-0:X-MS-Exchange-AntiSpam-MessageData-1;
 bh=Cr0ixxuqcPbGC2W7D030i2YyCFB31Xz9e/rZzFyCMBU=;
 b=dzhEa5d/Wk0KY5OmvGNSqWuNVAyGD8xZ/VFCH2FSKgY+fpBAOYc+EUsyVYVa8RvOXN4DiyrNy/HmhtsMlDgXZ12O3Qy2zF7Rdy9Rjlj52KYlHrilpNOga1x35hl9/roYdzf25ULj8JNnv/lUPY67FSBFe/J7ecaItUZuyV6n7Ic59MryHi8ZOC4XrUDbKIY8BZZEwXXq8yAWZgtkiPHTNAfK5XPXdZhlmOAN3gTNZEeNG8Z/sZno39QJVvqCVJtQfkMOg5Sd612NH9Fyph/Mikm2i0wMLmoigtQYJEUAk2acMIsRTM9zJV3fTJvdxGL1NWsZVlM+4Zz6OYj63wxtCg==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass (sender ip is
 137.201.242.130) smtp.rcpttodomain=vger.kernel.org smtp.mailfrom=micron.com;
 dmarc=pass (p=reject sp=reject pct=100) action=none header.from=micron.com;
 dkim=none (message not signed); arc=none (0)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=micron.com;
 s=selector2;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=Cr0ixxuqcPbGC2W7D030i2YyCFB31Xz9e/rZzFyCMBU=;
 b=fNyKFD6P8KXfeNHeCjA8A3xlJCHD3+W5S91AmnMapv2hXzSrGfO57xvinyP92iGcy84jwVDsVBeoz8kxmqTalmwggatNb46i0nuoYNZcVb1kXHbLXii5qK4OdtjMJhRMqo87NeYcY1m2dRCu56xp4r2Zc7xQRk0d82TujTwj7iN9CPEA2fh5hGl0WjspzOSVM8LfEKM9teIJ8h9LlSAA6HJxa0zc86a16zTlRihn5a1aqsRVwUEAwCkls24dGvAgeruBM9mnUDB/RJABnXfchCtUbBzb3m8RZkHlCmVqnahKVZ7NdPpIMWTA5TCbkmUjGG+ogcTdKMvMkoCFguCbmw==
Received: from BL1PR13CA0292.namprd13.prod.outlook.com (2603:10b6:208:2bc::27)
 by CO6PR08MB7769.namprd08.prod.outlook.com (2603:10b6:303:144::16) with
 Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.7091.26; Wed, 13 Dec
 2023 17:53:57 +0000
Received: from BL6PEPF0001AB54.namprd02.prod.outlook.com
 (2603:10b6:208:2bc:cafe::93) by BL1PR13CA0292.outlook.office365.com
 (2603:10b6:208:2bc::27) with Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.7091.26 via Frontend
 Transport; Wed, 13 Dec 2023 17:53:57 +0000
X-MS-Exchange-Authentication-Results: spf=pass (sender IP is 137.201.242.130)
 smtp.mailfrom=micron.com; dkim=none (message not signed)
 header.d=none;dmarc=pass action=none header.from=micron.com;
Received-SPF: Pass (protection.outlook.com: domain of micron.com designates
 137.201.242.130 as permitted sender) receiver=protection.outlook.com;
 client-ip=137.201.242.130; helo=mail.micron.com; pr=C
Received: from mail.micron.com (137.201.242.130) by
 BL6PEPF0001AB54.mail.protection.outlook.com (10.167.241.6) with Microsoft
 SMTP Server (version=TLS1_2, cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id
 15.20.7091.26 via Frontend Transport; Wed, 13 Dec 2023 17:53:57 +0000
Received: from BOW36EX19A.micron.com (137.201.85.33) by BOW36EX19B.micron.com
 (137.201.85.154) with Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.2.1258.27; Wed, 13 Dec
 2023 10:53:56 -0700
Received: from micron.com (10.3.116.19) by RestrictedRelay36EX19A.micron.com
 (137.201.85.33) with Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.2.1258.27 via Frontend
 Transport; Wed, 13 Dec 2023 10:53:49 -0700
From: <sthanneeru.opensrc@micron.com>
To: <sthanneeru.opensrc@micron.com>, <linux-cxl@vger.kernel.org>,
	<linux-mm@kvack.org>
CC: <sthanneeru@micron.com>, <aneesh.kumar@linux.ibm.com>,
	<dan.j.williams@intel.com>, <ying.huang@intel.com>,
	<gregory.price@memverge.com>, <mhocko@suse.com>, <tj@kernel.org>,
	<john@jagalactic.com>, <emirakhur@micron.com>, <vtavarespetr@micron.com>,
	<Ravis.OpenSrc@micron.com>, <Jonathan.Cameron@huawei.com>,
	<linux-kernel@vger.kernel.org>, Ravi Jonnalagadda <ravis.opensrc@micron.com>
Subject: [PATCH 1/2] base/node: Add sysfs for memtier_override
Date: Wed, 13 Dec 2023 23:23:28 +0530
Message-ID: <20231213175329.594-2-sthanneeru.opensrc@micron.com>
X-Mailer: git-send-email 2.25.1
In-Reply-To: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Transfer-Encoding: 8bit
Content-Type: text/plain
X-MT-Whitelisted: matched
X-EOPAttributedMessage: 0
X-MS-PublicTrafficType: Email
X-MS-TrafficTypeDiagnostic: BL6PEPF0001AB54:EE_|CO6PR08MB7769:EE_
X-MS-Office365-Filtering-Correlation-Id: 4b99d33b-3297-4022-6904-08dbfc047ad1
X-LD-Processed: f38a5ecd-2813-4862-b11b-ac1d563c806f,ExtAddr
X-EXT-ByPass: 1
X-MT-RULE-Whitelisted: Triggered
X-MS-Exchange-SenderADCheck: 1
X-MS-Exchange-AntiSpam-Relay: 0
X-Microsoft-Antispam: BCL:0;
X-Microsoft-Antispam-Message-Info: 1u2y+7Zv3exMnaX4qHg8ga1fz8bJoVT/jvIDsgDqH/8VtGix6I855NG39VU1ntvA9ZbYkrA0QKA5YhP/tEr7FdNlh+KVG+zUhjcnLZqqi78+B2jeBf1ywFE8+KL1R0/nES264h1zVZOtF/0gcrPhvqc7Y8wOL9wWy2X5imF0Loeb/Li/3pO4WFnAkUTkTIlZa+EdhYVUnOuBzDOnkSuBK8VP7rI38gWEFfgDA4T3DyiPaVTowrWJN1WjpgZXiPrHBYQGu3488KEXcRRDbtU3t8s4gBMmDnfk2WiojFyLJb/etPv0WViW67SF7cPB6R2DQd1GEaHqtGnzNs91Yor3/RkdTMPOyEOyAtUHquGFhFA10PpQ1vOwtyMbDHfVw1m28m+T1JntUE1a+qGQfWIYneW7WHnFW4uhktFWtQm13HmT1+SFtU3ifOvQt7BlEqPKWPlogNVdxn6JGn19tPlEdcrCmbYM8EuoZT01RX+vuw7Z0Lzmhu0gJNgrdkaQn3MHAurEjhG/0xYnp6GGi/B4NMmcBmofOIH5VPngqKPCB1BdKCqZTf3fVEcOM2VGRUU3wypzVUwwarSMGv0E/73ZW8nVYS6IDBT3IlsSzBLYHRgGuMAk+0vszKfKDaVH4ZcfscqHPI927cCEWfY+CMmMp+WI9ev4v+UmYx1bggui2s7px3CuM3x+Pe02ktyhfu1I4PGBuZQZIjqqtw+o3SXnl0b6mtHb52Zw4ZdqSBCF7Gm+Kl+/pRD7UJYlojjMG+L0I9CPItIDF1G+UeMzXVvPhg==
X-Forefront-Antispam-Report: CIP:137.201.242.130;CTRY:US;LANG:en;SCL:1;SRV:;IPV:NLI;SFV:NSPM;H:mail.micron.com;PTR:masquerade.micron.com;CAT:NONE;SFS:(13230031)(4636009)(346002)(376002)(396003)(39860400002)(136003)(230922051799003)(451199024)(64100799003)(1800799012)(186009)(82310400011)(46966006)(36840700001)(40470700004)(40460700003)(26005)(6286002)(107886003)(2616005)(1076003)(336012)(426003)(7696005)(6666004)(47076005)(36860700001)(83380400001)(5660300002)(41300700001)(2906002)(2876002)(478600001)(110136005)(8676002)(8936002)(4326008)(70206006)(70586007)(316002)(54906003)(7636003)(82740400003)(86362001)(356005)(36756003)(55016003)(40480700001)(2101003);DIR:OUT;SFP:1101;
X-OriginatorOrg: micron.com
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 13 Dec 2023 17:53:57.2263
 (UTC)
X-MS-Exchange-CrossTenant-Network-Message-Id: 4b99d33b-3297-4022-6904-08dbfc047ad1
X-MS-Exchange-CrossTenant-Id: f38a5ecd-2813-4862-b11b-ac1d563c806f
X-MS-Exchange-CrossTenant-OriginalAttributedTenantConnectingIp: TenantId=f38a5ecd-2813-4862-b11b-ac1d563c806f;Ip=[137.201.242.130];Helo=[mail.micron.com]
X-MS-Exchange-CrossTenant-AuthSource: BL6PEPF0001AB54.namprd02.prod.outlook.com
X-MS-Exchange-CrossTenant-AuthAs: Anonymous
X-MS-Exchange-CrossTenant-FromEntityHeader: HybridOnPrem
X-MS-Exchange-Transport-CrossTenantHeadersStamped: CO6PR08MB7769

From: Srinivasulu Thanneeru <sthanneeru.opensrc@micron.com>

This patch introduces a new memtier_override sysfs.

memtier_override is the current memory tier of the node.
To migrate, replace it with the id of the desired memory tier.

adistance_offset is the required offset from memtype to move
the node to the target memory tier(i.e, memtier_override).

Signed-off-by: Srinivasulu Thanneeru <sthanneeru.opensrc@micron.com>
Signed-off-by: Ravi Jonnalagadda <ravis.opensrc@micron.com>
---
 Documentation/ABI/stable/sysfs-devices-node |  7 ++++
 drivers/base/node.c                         | 41 +++++++++++++++++++++
 include/linux/memory-tiers.h                |  6 +++
 include/linux/node.h                        |  6 +++
 mm/memory-tiers.c                           | 19 +++++++++-
 5 files changed, 78 insertions(+), 1 deletion(-)

diff --git a/Documentation/ABI/stable/sysfs-devices-node b/Documentation/ABI/stable/sysfs-devices-node
index 402af4b2b905..447a599cc536 100644
--- a/Documentation/ABI/stable/sysfs-devices-node
+++ b/Documentation/ABI/stable/sysfs-devices-node
@@ -70,6 +70,13 @@ Description:
 		Distance between the node and all the other nodes
 		in the system.
 
+What:		/sys/devices/system/node/nodeX/memtier_overwrite
+Date:		December 2023
+Contact:	Srinivasulu Thanneeru <sthanneeru.opensrc@micron.com>
+Description:
+		The current memory tier of the node.
+		To migrate, replace it with the id of the desired memory tier.
+
 What:		/sys/devices/system/node/nodeX/vmstat
 Date:		October 2002
 Contact:	Linux Memory Management list <linux-mm@kvack.org>
diff --git a/drivers/base/node.c b/drivers/base/node.c
index 493d533f8375..788176b3585a 100644
--- a/drivers/base/node.c
+++ b/drivers/base/node.c
@@ -7,6 +7,7 @@
 #include <linux/init.h>
 #include <linux/mm.h>
 #include <linux/memory.h>
+#include <linux/memory-tiers.h>
 #include <linux/vmstat.h>
 #include <linux/notifier.h>
 #include <linux/node.h>
@@ -569,11 +570,49 @@ static ssize_t node_read_distance(struct device *dev,
 }
 static DEVICE_ATTR(distance, 0444, node_read_distance, NULL);
 
+static ssize_t memtier_override_show(struct device *dev,
+				     struct device_attribute *attr, char *buf)
+{
+	int nid = dev->id;
+	int len = 0;
+
+	len += sysfs_emit(buf, "memory_tier%d\n", node_devices[nid]->memtier);
+	return len;
+}
+
+static ssize_t memtier_override_store(struct device *dev,
+				      struct device_attribute *attr,
+				      const char *buf, size_t size)
+{
+	int nid = dev->id;
+	int ret, memtier;
+
+	ret = kstrtoint(buf, 0, &memtier);
+
+	if (ret)
+		return ret;
+	if (memtier < 0 || memtier > MAX_MEMTIERID)
+		return -EINVAL;
+	if (node_devices[nid]->memtier == memtier)
+		return size;
+	ret = get_memtier_adistance_offset(nid, memtier);
+	node_devices[nid]->adistance_offset = ret;
+
+	return size;
+}
+static DEVICE_ATTR_RW(memtier_override);
+
+void set_node_memtierid(int node, int memtierid)
+{
+	node_devices[node]->memtier = memtierid;
+}
+
 static struct attribute *node_dev_attrs[] = {
 	&dev_attr_meminfo.attr,
 	&dev_attr_numastat.attr,
 	&dev_attr_distance.attr,
 	&dev_attr_vmstat.attr,
+	&dev_attr_memtier_override.attr,
 	NULL
 };
 
@@ -883,6 +922,8 @@ int __register_one_node(int nid)
 
 	INIT_LIST_HEAD(&node_devices[nid]->access_list);
 	node_init_caches(nid);
+	node_devices[nid]->memtier = 0;
+	node_devices[nid]->adistance_offset = 0;
 
 	return error;
 }
diff --git a/include/linux/memory-tiers.h b/include/linux/memory-tiers.h
index 1e39d27bee41..0dba8027e785 100644
--- a/include/linux/memory-tiers.h
+++ b/include/linux/memory-tiers.h
@@ -20,6 +20,11 @@
  */
 #define MEMTIER_ADISTANCE_DRAM	((4 * MEMTIER_CHUNK_SIZE) + (MEMTIER_CHUNK_SIZE >> 1))
 
+/*
+ * Memory tier id is derived from abstract distance(signed 32bits)
+ */
+#define MAX_MEMTIERID (0xFFFFFFFF >> (MEMTIER_CHUNK_BITS + 1))
+
 struct memory_tier;
 struct memory_dev_type {
 	/* list of memory types that are part of same tier as this type */
@@ -48,6 +53,7 @@ int mt_calc_adistance(int node, int *adist);
 int mt_set_default_dram_perf(int nid, struct node_hmem_attrs *perf,
 			     const char *source);
 int mt_perf_to_adistance(struct node_hmem_attrs *perf, int *adist);
+int get_memtier_adistance_offset(int node, int memtier);
 #ifdef CONFIG_MIGRATION
 int next_demotion_node(int node);
 void node_get_allowed_targets(pg_data_t *pgdat, nodemask_t *targets);
diff --git a/include/linux/node.h b/include/linux/node.h
index 427a5975cf40..1c4f4be39db4 100644
--- a/include/linux/node.h
+++ b/include/linux/node.h
@@ -83,6 +83,8 @@ static inline void node_set_perf_attrs(unsigned int nid,
 struct node {
 	struct device	dev;
 	struct list_head access_list;
+	int memtier;
+	int adistance_offset;
 #ifdef CONFIG_HMEM_REPORTING
 	struct list_head cache_attrs;
 	struct device *cache_dev;
@@ -138,6 +140,7 @@ extern void unregister_memory_block_under_nodes(struct memory_block *mem_blk);
 extern int register_memory_node_under_compute_node(unsigned int mem_nid,
 						   unsigned int cpu_nid,
 						   unsigned access);
+extern void set_node_memtierid(int node, int memtierid);
 #else
 static inline void node_dev_init(void)
 {
@@ -165,6 +168,9 @@ static inline int unregister_cpu_under_node(unsigned int cpu, unsigned int nid)
 static inline void unregister_memory_block_under_nodes(struct memory_block *mem_blk)
 {
 }
+static inline void set_node_memtierid(int node, int memtierid)
+{
+}
 #endif
 
 #define to_node(device) container_of(device, struct node, dev)
diff --git a/mm/memory-tiers.c b/mm/memory-tiers.c
index 8d5291add2bc..31ed3c577836 100644
--- a/mm/memory-tiers.c
+++ b/mm/memory-tiers.c
@@ -167,6 +167,21 @@ static const struct attribute_group *memtier_dev_groups[] = {
 	NULL
 };
 
+int get_memtier_adistance_offset(int node, int memtier)
+{
+	struct memory_dev_type *memtype;
+	int adistance_offset;
+
+	memtype = node_memory_types[node].memtype;
+	/*
+	 * Calculate the adistance offset required from memtype
+	 * to move node to target memory tier.
+	 */
+	adistance_offset = (memtier << MEMTIER_CHUNK_BITS) -
+			   memtype->adistance;
+	return adistance_offset;
+}
+
 static struct memory_tier *find_create_memory_tier(struct memory_dev_type *memtype)
 {
 	int ret;
@@ -497,8 +512,10 @@ static struct memory_tier *set_node_memory_tier(int node)
 	memtype = node_memory_types[node].memtype;
 	node_set(node, memtype->nodes);
 	memtier = find_create_memory_tier(memtype);
-	if (!IS_ERR(memtier))
+	if (!IS_ERR(memtier)) {
 		rcu_assign_pointer(pgdat->memtier, memtier);
+		set_node_memtierid(node, memtier->dev.id);
+	}
 	return memtier;
 }
 
-- 
2.25.1


From mboxrd@z Thu Jan  1 00:00:00 1970
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=micron.com header.i=@micron.com header.b="BAssblea"
Received: from NAM10-MW2-obe.outbound.protection.outlook.com (mail-mw2nam10on2078.outbound.protection.outlook.com [40.107.94.78])
	by lindbergh.monkeyblade.net (Postfix) with ESMTPS id 8126A83;
	Wed, 13 Dec 2023 09:53:55 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=lbw7VEtjUgQym5lKOMbhgQlWIKJ/FNlont36YbYAM8Frj9SDlRthmlupP4bKkHLwGeDoflRo89a3XUgKIe6226okeNRHer7K6JaDLI2iweAreu0Hn5W2JHikY4h9yCt9ZJzTTOOU3GpT2U9I4HCOsm8aKbCEP7Ww/FKCv+DZPBFdT7YliocIDD1ZfEiocGliRZI3BZhCmRuQnbDMXMmglgRBEoPnid3Bx5uvFH47iHtHCb6Ug8ACiDm8Dfuze3SV/n9wl8tFuYqGqnBFtpJoah4lwD/HAEuNvrPMVoAYVJrQ+bisPrw2pj9Tu9+/S6qa0+pucNXSQ4hklBO4fyB1lQ==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-AntiSpam-MessageData-ChunkCount:X-MS-Exchange-AntiSpam-MessageData-0:X-MS-Exchange-AntiSpam-MessageData-1;
 bh=bPTYIujbxYcieE8zsPh1x43g4nGtCoz1IKVa5SKcC3Q=;
 b=QYjnKO7mFU9y0OXt1tu7sydfgyhpNYcjSMP4u+jWCxpQA0b5h+8/qZYDYpFsNvd8ljMT6g7GJj2kO2KqWrwwi6sy4Z9lakjRujLt7YX3QsANGxf+2LR6WUZLEynVnIGgBAw4qcl9UswbcKu3IkV8L/Y1ak4xq/Cm1p4+LOjxn8U+VnVBHeUqFAvqt2DIIzeepFCQu+ewA4p7W8qU4OmuBjNa69MxeiHHEjJP6/AYy6MFhbMVe0WmcYY/sLiV1nrZwsAvHSNa8i1gvUTGdqoMvX/yvkBHM3CvqUtvnuPN5xZPEb1OS668+s+/uR28ezDUPutPOnuHCgei8PwQ0UmtnQ==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass (sender ip is
 137.201.242.130) smtp.rcpttodomain=vger.kernel.org smtp.mailfrom=micron.com;
 dmarc=pass (p=reject sp=reject pct=100) action=none header.from=micron.com;
 dkim=none (message not signed); arc=none (0)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=micron.com;
 s=selector2;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=bPTYIujbxYcieE8zsPh1x43g4nGtCoz1IKVa5SKcC3Q=;
 b=BAssbleaEZ3qE8GavUNTHRFXaG1GEPI3WVR4qnjCrXZ605H9SJxcD33Anr591jPh0vcbBIk++zUSR5bJt2o2fGNjCNYz1QNNT531yzPPWII2m623iVLAR15ifG4d6AxtRtVYCYzV6IvCtckzV4tKY0KA7+zMsNdBlkM/W4qQt3bX4srQIbDgn0qSDF3Nl399rjufCpttjzfDy6C17dn+qBYDfmyRCyvurdIGKm68RL+hMxEg+OzkoZHejov2VKNeDJ0Siym97ItPJDnATXaBIQdZhry+sqZqVoj73b2XDpX0TmgXB+QA3rbkXus3/Mw7ttv6/OwSTjogiy/yfm0VKg==
Received: from MN2PR15CA0015.namprd15.prod.outlook.com (2603:10b6:208:1b4::28)
 by DS0PR08MB9424.namprd08.prod.outlook.com (2603:10b6:8:1b5::12) with
 Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.7091.25; Wed, 13 Dec
 2023 17:53:50 +0000
Received: from BL6PEPF0001AB52.namprd02.prod.outlook.com
 (2603:10b6:208:1b4:cafe::3d) by MN2PR15CA0015.outlook.office365.com
 (2603:10b6:208:1b4::28) with Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.7091.26 via Frontend
 Transport; Wed, 13 Dec 2023 17:53:50 +0000
X-MS-Exchange-Authentication-Results: spf=pass (sender IP is 137.201.242.130)
 smtp.mailfrom=micron.com; dkim=none (message not signed)
 header.d=none;dmarc=pass action=none header.from=micron.com;
Received-SPF: Pass (protection.outlook.com: domain of micron.com designates
 137.201.242.130 as permitted sender) receiver=protection.outlook.com;
 client-ip=137.201.242.130; helo=mail.micron.com; pr=C
Received: from mail.micron.com (137.201.242.130) by
 BL6PEPF0001AB52.mail.protection.outlook.com (10.167.241.4) with Microsoft
 SMTP Server (version=TLS1_2, cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id
 15.20.7091.26 via Frontend Transport; Wed, 13 Dec 2023 17:53:49 +0000
Received: from BOW36EX19A.micron.com (137.201.85.33) by BOW36EX19B.micron.com
 (137.201.85.154) with Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.2.1258.27; Wed, 13 Dec
 2023 10:53:49 -0700
Received: from micron.com (10.3.116.19) by RestrictedRelay36EX19A.micron.com
 (137.201.85.33) with Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.2.1258.27 via Frontend
 Transport; Wed, 13 Dec 2023 10:53:43 -0700
From: <sthanneeru.opensrc@micron.com>
To: <sthanneeru.opensrc@micron.com>, <linux-cxl@vger.kernel.org>,
	<linux-mm@kvack.org>
CC: <sthanneeru@micron.com>, <aneesh.kumar@linux.ibm.com>,
	<dan.j.williams@intel.com>, <ying.huang@intel.com>,
	<gregory.price@memverge.com>, <mhocko@suse.com>, <tj@kernel.org>,
	<john@jagalactic.com>, <emirakhur@micron.com>, <vtavarespetr@micron.com>,
	<Ravis.OpenSrc@micron.com>, <Jonathan.Cameron@huawei.com>,
	<linux-kernel@vger.kernel.org>
Subject: [RFC PATCH v2 0/2] Node migration between memory tiers
Date: Wed, 13 Dec 2023 23:23:27 +0530
Message-ID: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
X-Mailer: git-send-email 2.25.1
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Type: text/plain; charset="UTF-8"
Content-Transfer-Encoding: 8bit
X-MT-Whitelisted: matched
X-EOPAttributedMessage: 0
X-MS-PublicTrafficType: Email
X-MS-TrafficTypeDiagnostic: BL6PEPF0001AB52:EE_|DS0PR08MB9424:EE_
X-MS-Office365-Filtering-Correlation-Id: 84b880a5-a234-4407-0a36-08dbfc047678
X-LD-Processed: f38a5ecd-2813-4862-b11b-ac1d563c806f,ExtAddr
X-EXT-ByPass: 1
X-MT-RULE-Whitelisted: Triggered
X-MS-Exchange-SenderADCheck: 1
X-MS-Exchange-AntiSpam-Relay: 0
X-Microsoft-Antispam: BCL:0;
X-Microsoft-Antispam-Message-Info: v5pN6J85TBtbITYv8skWa6C6jasX06rx5z5d2pe/4tVV2a+AJrRbnVF03GREmjJoNlaeMmPHh43SzW/yrePAAIzYfrgBaTtzymidnhtoH9pSSIXgAoqtrsll9KRVxS/7cc+IPls4pZVUwDfG1WMBu8gMGUwkQ7r7xeyt1591vJberYOU2rFouR2nG0NN7isIzPRrXVQXB4aMp2uRZsMNGKG+niGaQyKErVoEU6WG4UJx4csfMQLLyb2CZ59cUE9Sw5tuCUIiLH++0MfyN1yx0yzjFViD7X9gEqaWblQtgFzkjpXVT04Q3vPvsqIlm2gD7biz/6b6IXwgPJxXFzHChsyfRBaj9iIyzkvSELrZLUtZc8UHzogevEQDkLCbSV9dmZoOklSk3NFARWdzjz2afq48/VB7zDtd2RS5wekib3LtTcffylaMHI2GXyjuN6V/Tqv8/OngaTnQIlXQvoIhGsMGG7Z6icknf7qC22JCixb/CPNXiBZGN+wkmrUkLjZA9XW1U7cKXzgana9+XA8barDMTcIZjrS3ZKRsV7PYPcMzg5uX3pznVLpJ9XIj69K/7+imHn8512A1jaqqUOcodvzLLv157YqCdAi3bsg98yQXUTkEa29bT7ETgWdQn/iQHZurm13jcNLs+ZpLl4Znoo6luPRAQ/x92L9oXnf75aW0x+cmMGK3xk+59DLGGuRpVco10BzD2BuAj9N6dfmbg44WPJcgydvgckXVZc0MYobZBRpQYTbDYOe69no7d0SZ
X-Forefront-Antispam-Report: CIP:137.201.242.130;CTRY:US;LANG:en;SCL:1;SRV:;IPV:NLI;SFV:NSPM;H:mail.micron.com;PTR:masquerade.micron.com;CAT:NONE;SFS:(13230031)(4636009)(39860400002)(136003)(396003)(376002)(346002)(230922051799003)(451199024)(64100799003)(82310400011)(186009)(1800799012)(36840700001)(46966006)(40470700004)(54906003)(70586007)(70206006)(110136005)(1076003)(7696005)(6286002)(2616005)(7636003)(336012)(26005)(426003)(6666004)(36756003)(47076005)(86362001)(82740400003)(356005)(83380400001)(966005)(36860700001)(478600001)(41300700001)(40480700001)(8676002)(8936002)(2906002)(2876002)(4326008)(55016003)(5660300002)(316002)(40460700003)(2101003);DIR:OUT;SFP:1101;
X-OriginatorOrg: micron.com
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 13 Dec 2023 17:53:49.8673
 (UTC)
X-MS-Exchange-CrossTenant-Network-Message-Id: 84b880a5-a234-4407-0a36-08dbfc047678
X-MS-Exchange-CrossTenant-Id: f38a5ecd-2813-4862-b11b-ac1d563c806f
X-MS-Exchange-CrossTenant-OriginalAttributedTenantConnectingIp: TenantId=f38a5ecd-2813-4862-b11b-ac1d563c806f;Ip=[137.201.242.130];Helo=[mail.micron.com]
X-MS-Exchange-CrossTenant-AuthSource: BL6PEPF0001AB52.namprd02.prod.outlook.com
X-MS-Exchange-CrossTenant-AuthAs: Anonymous
X-MS-Exchange-CrossTenant-FromEntityHeader: HybridOnPrem
X-MS-Exchange-Transport-CrossTenantHeadersStamped: DS0PR08MB9424

From: Srinivasulu Thanneeru <sthanneeru.opensrc@micron.com>

The memory tiers feature allows nodes with similar memory types
or performance characteristics to be grouped together in a
memory tier. However, there is currently no provision for
moving a node from one tier to another on demand.

This patch series aims to support node migration between tiers
on demand by sysadmin/root user using the provided sysfs for
node migration.

To migrate a node to a tier, the corresponding node’s sysfs
memtier_override is written with target tier id.

Example: Move node2 to memory tier2 from its default tier(i.e 4)

1. To check current memtier of node2
$cat  /sys/devices/system/node/node2/memtier_override
memory_tier4

2. To migrate node2 to memory_tier2
$echo 2 > /sys/devices/system/node/node2/memtier_override
$cat  /sys/devices/system/node/node2/memtier_override
memory_tier2

Usecases:

1. Useful to move cxl nodes to the right tiers from userspace, when
   the hardware fails to assign the tiers correctly based on
   memorytypes.

   On some platforms we have observed cxl memory being assigned to
   the same tier as DDR memory. This is arguably a system firmware
   bug, but it is true that tiers represent *ranges* of performance
   and we believe it's important for the system operator to have
   the ability to override bad firmware or OS decisions about tier
   assignment as a fail-safe against potential bad outcomes.

2. Useful if we want interleave weights to be applied on memory tiers
   instead of nodes.
In a previous thread, Huang Ying <ying.huang@intel.com> thought
this feature might be useful to overcome limitations of systems
where nodes with different bandwidth characteristics are grouped
in a single tier.
https://lore.kernel.org/lkml/87a5rw1wu8.fsf@yhuang6-desk2.ccr.corp.intel.com/

=============
Version Notes:

V2 : Changed interface to memtier_override from adistance_offset.
memtier_override was recommended by
1. John Groves <john@jagalactic.com>
2. Ravi Shankar <ravis.opensrc@micron.com>
3. Brice Goglin <Brice.Goglin@inria.fr>

V1 : Introduced adistance_offset sysfs.

=============

Srinivasulu Thanneeru (2):
  base/node: Add sysfs for memtier_override
  memory tier: Support node migration between tiers

 Documentation/ABI/stable/sysfs-devices-node |  7 ++
 drivers/base/node.c                         | 47 ++++++++++++
 include/linux/memory-tiers.h                | 11 +++
 include/linux/node.h                        | 11 +++
 mm/memory-tiers.c                           | 85 ++++++++++++---------
 5 files changed, 125 insertions(+), 36 deletions(-)

-- 
2.25.1


From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from mgamail.intel.com (mgamail.intel.com [134.134.136.20])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 6254CBE55;
	Tue, 19 Dec 2023 03:59:16 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=none dis=none) header.from=intel.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=intel.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=intel.com header.i=@intel.com header.b="eQ0nxbo1"
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple;
  d=intel.com; i=@intel.com; q=dns/txt; s=Intel;
  t=1702958356; x=1734494356;
  h=from:to:cc:subject:in-reply-to:references:date:
   message-id:mime-version:content-transfer-encoding;
  bh=3s4M1Ke7Zp6dpbGPTolOm9J70ngTk0LFGbPc1ei/amY=;
  b=eQ0nxbo1MXmiT5C6ACUpn4NouqgpK2BG95tsLpSDo8ZiqkFho4gnZ8MO
   +R435YpmLXIbfTBKPOeX4snjc4DTfJsD/DcU2aFM4q/AaF9poU/JNC5yf
   +Kqnn3gsbVNuxOuwev+swv9Hb/WLCxo26WXroIp/8ymKYb51oU4XaJ3iJ
   9cc8jqrahruoBlMGU2ooH0VuCv/2PrmOGh4kQCuYv7MLBdS9uTGUOGzrT
   YXnaw/BvrYh2yLTCHxJFgrlSI2RYxIegRdkBahOJG4mYy8ASVO6PudC6E
   BbbMWnNzP7AUAGlW6CEfEiLUrZwzoNVvldXPkP4akBAEGmX/7FT9A4ABe
   A==;
X-IronPort-AV: E=McAfee;i="6600,9927,10928"; a="386023776"
X-IronPort-AV: E=Sophos;i="6.04,287,1695711600"; 
   d="scan'208";a="386023776"
Received: from fmsmga008.fm.intel.com ([10.253.24.58])
  by orsmga101.jf.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 18 Dec 2023 19:59:15 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=McAfee;i="6600,9927,10928"; a="841740575"
X-IronPort-AV: E=Sophos;i="6.04,287,1695711600"; 
   d="scan'208";a="841740575"
Received: from yhuang6-desk2.sh.intel.com (HELO yhuang6-desk2.ccr.corp.intel.com) ([10.238.208.55])
  by fmsmga008-auth.fm.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 18 Dec 2023 19:59:11 -0800
From: "Huang, Ying" <ying.huang@intel.com>
To: Srinivasulu Thanneeru <sthanneeru@micron.com>
Cc: Srinivasulu Opensrc <sthanneeru.opensrc@micron.com>,
  "linux-cxl@vger.kernel.org" <linux-cxl@vger.kernel.org>,
  "linux-mm@kvack.org" <linux-mm@kvack.org>,  "aneesh.kumar@linux.ibm.com"
 <aneesh.kumar@linux.ibm.com>,  "dan.j.williams@intel.com"
 <dan.j.williams@intel.com>,  gregory.price <gregory.price@memverge.com>,
  "mhocko@suse.com" <mhocko@suse.com>,  "tj@kernel.org" <tj@kernel.org>,
  "john@jagalactic.com" <john@jagalactic.com>,  Eishan Mirakhur
 <emirakhur@micron.com>,  Vinicius Tavares Petrucci
 <vtavarespetr@micron.com>,  Ravis OpenSrc <Ravis.OpenSrc@micron.com>,
  "Jonathan.Cameron@huawei.com" <Jonathan.Cameron@huawei.com>,
  "linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>, Johannes
 Weiner <hannes@cmpxchg.org>, Wei Xu <weixugc@google.com>
Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
In-Reply-To: <PH0PR08MB79551628EFA3B1B3CB55DFFEA890A@PH0PR08MB7955.namprd08.prod.outlook.com>
	(Srinivasulu Thanneeru's message of "Mon, 18 Dec 2023 08:56:02 +0000")
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
	<87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79551628EFA3B1B3CB55DFFEA890A@PH0PR08MB7955.namprd08.prod.outlook.com>
Date: Tue, 19 Dec 2023 11:57:12 +0800
Message-ID: <87o7emn8tj.fsf@yhuang6-desk2.ccr.corp.intel.com>
User-Agent: Gnus/5.13 (Gnus v5.13)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

Hi, Srinivasulu,

Please use a email client that works for kernel patch review.  Your
email is hard to read.  It's hard to identify which part is your text
and which part is my text.  Please refer to,

https://www.kernel.org/doc/html/latest/process/email-clients.html

Or something similar, for example,

https://elinux.org/Mail_client_tips

Srinivasulu Thanneeru <sthanneeru@micron.com> writes:

> Micron Confidential
>
>
>
> Micron Confidential
> ________________________________________
> From: Huang, Ying <ying.huang@intel.com>
> Sent: Friday, December 15, 2023 10:32 AM
> To: Srinivasulu Opensrc
> Cc: linux-cxl@vger.kernel.org; linux-mm@kvack.org; Srinivasulu
> Thanneeru; aneesh.kumar@linux.ibm.com; dan.j.williams@intel.com;
> gregory.price; mhocko@suse.com; tj@kernel.org; john@jagalactic.com;
> Eishan Mirakhur; Vinicius Tavares Petrucci; Ravis OpenSrc;
> Jonathan.Cameron@huawei.com; linux-kernel@vger.kernel.org
> Subject: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
>
> CAUTION: EXTERNAL EMAIL. Do not click links or open attachments unless yo=
u recognize the sender and were expecting this message.
>
>
> <sthanneeru.opensrc@micron.com> writes:
>
>> From: Srinivasulu Thanneeru <sthanneeru.opensrc@micron.com>
>>
>> The memory tiers feature allows nodes with similar memory types
>> or performance characteristics to be grouped together in a
>> memory tier. However, there is currently no provision for
>> moving a node from one tier to another on demand.
>>
>> This patch series aims to support node migration between tiers
>> on demand by sysadmin/root user using the provided sysfs for
>> node migration.
>>
>> To migrate a node to a tier, the corresponding node=E2=80=99s sysfs
>> memtier_override is written with target tier id.
>>
>> Example: Move node2 to memory tier2 from its default tier(i.e 4)
>>
>> 1. To check current memtier of node2
>> $cat  /sys/devices/system/node/node2/memtier_override
>> memory_tier4
>>
>> 2. To migrate node2 to memory_tier2
>> $echo 2 > /sys/devices/system/node/node2/memtier_override
>> $cat  /sys/devices/system/node/node2/memtier_override
>> memory_tier2
>>
>> Usecases:
>>
>> 1. Useful to move cxl nodes to the right tiers from userspace, when
>>    the hardware fails to assign the tiers correctly based on
>>    memorytypes.
>>
>>    On some platforms we have observed cxl memory being assigned to
>>    the same tier as DDR memory. This is arguably a system firmware
>>    bug, but it is true that tiers represent *ranges* of performance
>>    and we believe it's important for the system operator to have
>>    the ability to override bad firmware or OS decisions about tier
>>    assignment as a fail-safe against potential bad outcomes.
>>
>> 2. Useful if we want interleave weights to be applied on memory tiers
>>    instead of nodes.
>> In a previous thread, Huang Ying <ying.huang@intel.com> thought
>> this feature might be useful to overcome limitations of systems
>> where nodes with different bandwidth characteristics are grouped
>> in a single tier.
>> https://lore.kernel.org/lkml/87a5rw1wu8.fsf@yhuang6-desk2.ccr.corp.intel=
.com/
>>
>> =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
>> Version Notes:
>>
>> V2 : Changed interface to memtier_override from adistance_offset.
>> memtier_override was recommended by
>> 1. John Groves <john@jagalactic.com>
>> 2. Ravi Shankar <ravis.opensrc@micron.com>
>> 3. Brice Goglin <Brice.Goglin@inria.fr>
>
> It appears that you ignored my comments for V1 as follows ...
>
> https://lore.kernel.org/lkml/87o7f62vur.fsf@yhuang6-desk2.ccr.corp.intel.=
com/
>
> Thank you Huang, Ying for pointing to this.
>
> https://lpc.events/event/16/contributions/1209/attachments/1042/1995/Live=
%20In%20a%20World%20With%20Multiple%20Memory%20Types.pdf
>
> In the presentation above, the adistance_offsets are per memtype.
> We believe that adistance_offset per node is more suitable and flexible
> since we can change it per node. If we keep adistance_offset per memtype,
> then we cannot change it for a specific node of a given memtype.

Why do you need to change it for a specific node?  Why do you needn't to
chagne it for all nodes of a given memtype?

> https://lore.kernel.org/lkml/87jzpt2ft5.fsf@yhuang6-desk2.ccr.corp.intel.=
com/
>
> I guess that you need to move all NUMA nodes with same performance
> metrics together?  If so, That is why we previously proposed to place
> the knob in "memory_type"? (From: Huang, Ying )
>
> Yes, memory_type would be group the related memories togather as single t=
ier.
> We should also have a flexibility to move nodes between tiers, to address=
 the issues described in usecases above.
>
> https://lore.kernel.org/lkml/87a5qp2et0.fsf@yhuang6-desk2.ccr.corp.intel.=
com/
>
> This patch provides a way to move a node to the correct tier.
> We observed in test setups where DRAM and CXL are put under the same
> tier (memory_tier4).
> By using this patch, we can move the CXL node away from the DRAM-linked
> tier4 and put it in the desired tier.

Good!  Can you give more details?  So I can resend the patch with your
supporting data.

--
Best Regards,
Huang, Ying

> Regards,
> Srini
>
> --
> Best Regards,
> Huang, Ying
>
>> V1 : Introduced adistance_offset sysfs.
>>
>> =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
>>
>> Srinivasulu Thanneeru (2):
>>   base/node: Add sysfs for memtier_override
>>   memory tier: Support node migration between tiers
>>
>>  Documentation/ABI/stable/sysfs-devices-node |  7 ++
>>  drivers/base/node.c                         | 47 ++++++++++++
>>  include/linux/memory-tiers.h                | 11 +++
>>  include/linux/node.h                        | 11 +++
>>  mm/memory-tiers.c                           | 85 ++++++++++++---------
>>  5 files changed, 125 insertions(+), 36 deletions(-)

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from NAM10-DM6-obe.outbound.protection.outlook.com (mail-dm6nam10on2069.outbound.protection.outlook.com [40.107.93.69])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id ACB9E10945;
	Mon, 18 Dec 2023 08:56:07 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=reject dis=none) header.from=micron.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=micron.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=micron.com header.i=@micron.com header.b="gNMDWy+S"
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=a4UsnYYgl/jhsCKuuBzPVDLT1yDhrdM44lbjQfyadKfEqZSehPGtYVTXtlnMlh0ObQY5YKArFfTQPvJfGHy0bz2mnsTQN4UP0SxOZGtKoBALcdSKqCDM7QgPHPBZtvZJTykL7/NHXykcJMULwXoeEc9WjXPNf5pl3+2r+9xCvo7XF4edcmv5BQILrRLH6dYo53RdBVUVtFg2EN90S4pQW2I/ezmbUT2I1/5kQLDEuLU87mVhn3AivQoYD4isLVjrmbLMoxdJPWGsAhkYj0uZNw8yFSf9VfuRL2eoq29bSRPHgPFUsZW4UGGkgPujTkm+WDf22ypje8l+IWRXHq/O0A==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-AntiSpam-MessageData-ChunkCount:X-MS-Exchange-AntiSpam-MessageData-0:X-MS-Exchange-AntiSpam-MessageData-1;
 bh=yU975NSkeUvPa/7r56o+4apDy1VByIzIvc+oMEQ+j7w=;
 b=C0uQoqMvdm5HW5uREBm2NbnTZk5qQkM1MD9bvRQHEXRoT/kk6zFKKOgA4CnniATtFt7/3W2oSOjBQLWi2BAxgNM/0px0/4DD0rlVsQQ6Zo7LnwDdOOuYmH/150J5hlMnhwn8IbAHGOW6CCuhAl8aiR+LntoJNxFFDqkpIQoS1BLZYNSQ1LUKDty1REiUxlNqLXlERItJHuUZOQ6ZuMdSB0vF30zRVckfd5ZEpP2gs4F47apVb4nzPNI6EYmCgLziFydoCKncUa3tW8deTh4SIToL51jdpb4s7qCkBHEynInCKPA4HKwgU4NTiaZPyC7P55NfxmtIf60jIHMulnLUNA==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass
 smtp.mailfrom=micron.com; dmarc=pass action=none header.from=micron.com;
 dkim=pass header.d=micron.com; arc=none
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=micron.com;
 s=selector2;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=yU975NSkeUvPa/7r56o+4apDy1VByIzIvc+oMEQ+j7w=;
 b=gNMDWy+S+yGWNmob+p3RZsuGXPLKfim3IpiI0O/tdmNWKaksXtYza+idXKOdqNMBBrovbd4jVEfAgekUM3wjCT73s2JMAIAhmqKyRPXB5whMf/rbKhCu1lPAmH9iijGkjLNKlgTGV7/hO2hEruXfC8HKzNCrZxHOk3h0cIxrJ9T4Up/Hax66qV7T9qzXbJ6vnFSo9PS2U0pyPwoT6f+D7YVKPRqBDV0mYEI1iQHEr0wUxJk+qMJ/O+xS/Rubf9LA+1BztdRuSdkY7uv05cRD6DpC5r2xCtOfMUEunhwGem8XUpNmNH6q1kUxQib694GdxXq5kLSCYiADXBF/tpeBVA==
Received: from PH0PR08MB7955.namprd08.prod.outlook.com (2603:10b6:510:11a::17)
 by LV3PR08MB9170.namprd08.prod.outlook.com (2603:10b6:408:21f::6) with
 Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.7113.16; Mon, 18 Dec
 2023 08:56:03 +0000
Received: from PH0PR08MB7955.namprd08.prod.outlook.com
 ([fe80::c91e:e46f:6de0:65f5]) by PH0PR08MB7955.namprd08.prod.outlook.com
 ([fe80::c91e:e46f:6de0:65f5%7]) with mapi id 15.20.7113.016; Mon, 18 Dec 2023
 08:56:03 +0000
From: Srinivasulu Thanneeru <sthanneeru@micron.com>
To: "Huang, Ying" <ying.huang@intel.com>, Srinivasulu Opensrc
	<sthanneeru.opensrc@micron.com>
CC: "linux-cxl@vger.kernel.org" <linux-cxl@vger.kernel.org>,
	"linux-mm@kvack.org" <linux-mm@kvack.org>, "aneesh.kumar@linux.ibm.com"
	<aneesh.kumar@linux.ibm.com>, "dan.j.williams@intel.com"
	<dan.j.williams@intel.com>, gregory.price <gregory.price@memverge.com>,
	"mhocko@suse.com" <mhocko@suse.com>, "tj@kernel.org" <tj@kernel.org>,
	"john@jagalactic.com" <john@jagalactic.com>, Eishan Mirakhur
	<emirakhur@micron.com>, Vinicius Tavares Petrucci <vtavarespetr@micron.com>,
	Ravis OpenSrc <Ravis.OpenSrc@micron.com>, "Jonathan.Cameron@huawei.com"
	<Jonathan.Cameron@huawei.com>, "linux-kernel@vger.kernel.org"
	<linux-kernel@vger.kernel.org>
Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
Thread-Topic: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
Thread-Index: AQHaLe1WCWEmLbBSRk2O5Sdey42WeLCpzLPHgAT264E=
Date: Mon, 18 Dec 2023 08:56:02 +0000
Message-ID: <PH0PR08MB79551628EFA3B1B3CB55DFFEA890A@PH0PR08MB7955.namprd08.prod.outlook.com>
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
 <87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
In-Reply-To: <87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
msip_labels: MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_Enabled=True;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_SiteId=f38a5ecd-2813-4862-b11b-ac1d563c806f;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_SetDate=2023-12-18T08:56:02.479Z;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_Name=Confidential;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_ContentBits=0;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_Method=Standard;
authentication-results: dkim=none (message not signed)
 header.d=none;dmarc=none action=none header.from=micron.com;
x-ms-publictraffictype: Email
x-ms-traffictypediagnostic: PH0PR08MB7955:EE_|LV3PR08MB9170:EE_
x-ms-office365-filtering-correlation-id: e81d6057-80d9-4b5f-a131-08dbffa729d4
x-ld-processed: f38a5ecd-2813-4862-b11b-ac1d563c806f,ExtAddr
x-ms-exchange-senderadcheck: 1
x-ms-exchange-antispam-relay: 0
x-microsoft-antispam: BCL:0;
x-microsoft-antispam-message-info: EbkqUwY3OW93uiNqG0ufFu4oim2o3uiHccpzg4XpFjisarlptNG14kibvsioA6aIpp1ZY6sCPocwt/S2gnkAFeIjfJEslC9R4x89gCRtZz+1NPZ+HX/er1VHBca86y43M3SvZrNnwSckgxLBcepv7p+759uevGuP6FNW8H8ljU1vpf4aHww0GGzyB7bYn0ghMtrqK6zO4aHgJNBT0IAHzCImADWJxq69o9wtKcmvQyvN7Ygp7YmXfYeEAT8xdTckofCY2JqcFeBhk9IicPEOjF7ji08rWZEYF9r553ijnWUmBGulEA/SQqANBC/av8M7bVI+uZZwWHUf3+gvIi9kqTIJDCZga8b2bTZrd3qA6qggVu8SdkNjSnY3sbcPCImgcTUa6ZkQoS+D/cXG/XefHsJ4vJvbkUZcZXmVN6RxTsn0kQ5NEKjLO+3GFcsW+7PWnUjX3s9ydaE4p4I/4ZJINNAj0VMCf8s8oGDjBarb0j0o5fXuCiqply3db+r9TVn3NwzSQ4l8boZVmPmPEh29OJQxCJFoVRL5SreEaHx6FJ6YgBQB4gxocW4NttA2f3vEQMmrYWawDfIaTjFjfIM6rbIuDPkwS6+owOJdqqxq+Bk9QawYKPCS4Jl5gasNoFvhqDbMW6WKpiEB1/fOatx75w==
x-forefront-antispam-report: CIP:255.255.255.255;CTRY:;LANG:en;SCL:1;SRV:;IPV:NLI;SFV:NSPM;H:PH0PR08MB7955.namprd08.prod.outlook.com;PTR:;CAT:NONE;SFS:(13230031)(39860400002)(376002)(136003)(396003)(366004)(346002)(230922051799003)(230173577357003)(230273577357003)(1800799012)(186009)(451199024)(64100799003)(83380400001)(66556008)(66946007)(55016003)(110136005)(6636002)(64756008)(91956017)(66476007)(76116006)(66446008)(478600001)(316002)(54906003)(38100700002)(26005)(966005)(4326008)(53546011)(52536014)(8676002)(8936002)(6506007)(45080400002)(55236004)(7696005)(9686003)(71200400001)(7416002)(5660300002)(2906002)(33656002)(86362001)(122000001)(41300700001)(38070700009);DIR:OUT;SFP:1101;
x-ms-exchange-antispam-messagedata-chunkcount: 1
x-ms-exchange-antispam-messagedata-0: =?utf-7?B?N254MlhMR3pRcm1NMDBzcUV5L2xIQ2JLTDNzWDlsc0QxME1WNDQ1T0w5elQ0?=
 =?utf-7?B?YmdUYkJPdFVGUnpveWRpRVE1QjNiL09adTBLcmkwbklTcWUrLVRCTWx3Q0Jj?=
 =?utf-7?B?QistcTB6MEhEem45U3FUdEpwYm4vNFFobWJWQkNMY04xaTk3aE5hbjhJb1pQ?=
 =?utf-7?B?M1hYYkQrLUdwc1E0R1NYdi9xenFxcVdrU2JQQjBoYk5lMmExbXRob01Mc2RV?=
 =?utf-7?B?WGRWV2Jwb0pEbER1OVluVEUvVjRKdG5rZVJUMG5yREJIU0VCQThEeENCY1dP?=
 =?utf-7?B?RWlkUEg2TUc3bkxXMjdxZ2JUNENQUEVuTzU5OWhIaWNRSmRwM2hpcWlTZ2hR?=
 =?utf-7?B?a2RPeWlhOGE0cnlJMUJXSkkvQ3FIRWdhZktWczJjemxMUGNwdjdLZE5KYURk?=
 =?utf-7?B?YXdRWDc5RW5mekdlcERZNElYMmd1Wm81RXR5cnVMdDVDdHRjZTZmR0JrelMx?=
 =?utf-7?B?VlBxMTkzL1FFSjhGRElIRmVvSjdzMjF3Z3VmRDVnYWlOSzFZb0c5VG1jRE14?=
 =?utf-7?B?S00xWTNNeTNjbVl6RUJTOVozWXpwa2hoTEYvV1AzNVZ2QmJDVDNJMVhUYzg5?=
 =?utf-7?B?NnBzTjRsSmdqa3pPbEg3NEhudm5kQm5NNVh2a3hVdmJOcDhnendhVkFib3Bk?=
 =?utf-7?B?dDNvTmFiKy1OUFlobExnSVdMaWhwOGRRTVhNdzhYQTc5dmROZFplNm85bjdz?=
 =?utf-7?B?L04zcGZaNnBEanY4RGFPajlxMlNWUWZ0eTVSSzNhRnpic2pjc1NZYlc1YWYx?=
 =?utf-7?B?Ky00Vll0cDdWTVdCZkF3dEI0SGF5ZW5EVFBFRFhOakVsVS9ia0FYREY3NnBF?=
 =?utf-7?B?NzFaTS9OOHc5Ky1uZVJWeDVlcFpMNm1xOWZMdGlaQUc5ZmRINDFmeTRpWjUy?=
 =?utf-7?B?NUVVUjhIS2RFdWErLTZsUEFCdVBHbUx3MEZ5blhxdVE4U3lJenN3bm51amtK?=
 =?utf-7?B?R0RvdDZGbDBGY2M5SzlCOG51RjhuT2xjZ2ExUllSM1VTREI2N2s5RGo5ekNP?=
 =?utf-7?B?N3JuajljUjVmYkF5a1hrejN6MjJRdktub3NsY00vT2tvUnZaQThZa2J3a1hm?=
 =?utf-7?B?ckRmNXJNNEwrLWZzZVhCa1Rqb29aak1XTmF4Yk1ZeU94dG92cW5ySmg0S3k0?=
 =?utf-7?B?ekVuR25EUENoNGk5RkdLVkFLVUVUR2xUc3l0MGdtbFVxYzFCbDVadnoxR0t5?=
 =?utf-7?B?amhES1MwS2kvaU4rLXRMcE4xTistQ1BwcUw0Y2Z3RXBBU09rNWJ4WVdWT2E=?=
 =?utf-7?B?Tystc3pxbGNobWUyNWRrcG8yZGc2a1JGTWVSeTZaMkoydTNtdy9jV08wVmFy?=
 =?utf-7?B?aFU0RE0rLTQvbDJGSEtYZ0I1Zzljck8wMGZvRmlHbnhlMHIwWm5LTXlPejU4?=
 =?utf-7?B?Z0R0TUFibE1zKy1nRWQ1Ky1nS280Y2lKKy1LOVorLTAzc3NaSnJQZENZME85?=
 =?utf-7?B?SVpCWVhRRnlscmo5eU9TdWFLQmZlSEVnWVZnVUk1dWswamlaTEtHWUhoczZ2?=
 =?utf-7?B?bnBrVnhQalNDYWplLzNNNm9oWEdFU0R3RkZRc09DZjFUdUxFQ2tkVXhxem4v?=
 =?utf-7?B?eTlneDRUMEM5SjczczVnV3RLTHdPc0tKZXRzRDYzS3NaKy1KT1lLbkRwc2V6?=
 =?utf-7?B?YTVneCstR2FKd2pJRjVBUjIwZ3FFaDZjU3NCbU9rdjVkZ1FoQVJ1MDBycVU4?=
 =?utf-7?B?M3lWc3dEeUxYMzc5aXBPYkpYYjZSeGNVTnkwYWJidkRpdkdvN3dUY3cwR0pL?=
 =?utf-7?B?NXZXbkhTUHhsTlRYRGJ0UVdiNlNvWEFGS01hRlJTWVlYWUZtWEFGL2lvV1ZM?=
 =?utf-7?B?bE5LZ002WWZlZ0xZblZEVlRPZ01QamdUdEFwam1wT3VEYU5ESjBZbS93T0V4?=
 =?utf-7?B?anJjaXFIUWdGVGNRMjRQaFh1bkMrLXduaUtBSG95WGhlb2U4S1ExdzNBbSst?=
 =?utf-7?B?MGhFS1VCSzdnMzJtRk95WXJzNHFsQ3ZiVzFnZUs4MFMxOGszYjZpWVFFNC8y?=
 =?utf-7?B?d2JuL3M1VUJDQmNRRTVKT2IvNTBxenhlKy1zY01lNlhMOWpMcnJzYjhIOVJD?=
 =?utf-7?B?YlY5NFpTL3crLVlaWVYzUDY3VGcxeFlsQ3o1d2tickFTYVliSkJZcystYmdE?=
 =?utf-7?B?VnJTMistV09ORmZoeWFvVTBud3pZR2l0S2hYL1hIYWxUQU8xd0RRcTd1cWFT?=
 =?utf-7?B?Z2ZvS2o=?=
Content-Type: text/plain; charset="utf-7"
Content-Transfer-Encoding: quoted-printable
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
X-OriginatorOrg: micron.com
X-MS-Exchange-CrossTenant-AuthAs: Internal
X-MS-Exchange-CrossTenant-AuthSource: PH0PR08MB7955.namprd08.prod.outlook.com
X-MS-Exchange-CrossTenant-Network-Message-Id: e81d6057-80d9-4b5f-a131-08dbffa729d4
X-MS-Exchange-CrossTenant-originalarrivaltime: 18 Dec 2023 08:56:02.9369
 (UTC)
X-MS-Exchange-CrossTenant-fromentityheader: Hosted
X-MS-Exchange-CrossTenant-id: f38a5ecd-2813-4862-b11b-ac1d563c806f
X-MS-Exchange-CrossTenant-mailboxtype: HOSTED
X-MS-Exchange-CrossTenant-userprincipalname: poFjYyaKuu93QYLy4x2V9TY9rKjoeRHbAFgDP1k/ew3Z3Zls7pGTNNUyzJpojf03ZTTWaTi1EbpNjzVj/CNF1w==
X-MS-Exchange-Transport-CrossTenantHeadersStamped: LV3PR08MB9170


Micron Confidential



Micron Confidential
+AF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF=
8AXwBfAF8AXwBfAF8AXwBfAF8AXwBfAF8-
From: Huang, Ying +ADw-ying.huang+AEA-intel.com+AD4-
Sent: Friday, December 15, 2023 10:32 AM
To: Srinivasulu Opensrc
Cc: linux-cxl+AEA-vger.kernel.org+ADs- linux-mm+AEA-kvack.org+ADs- Srinivas=
ulu Thanneeru+ADs- aneesh.kumar+AEA-linux.ibm.com+ADs- dan.j.williams+AEA-i=
ntel.com+ADs- gregory.price+ADs- mhocko+AEA-suse.com+ADs- tj+AEA-kernel.org=
+ADs- john+AEA-jagalactic.com+ADs- Eishan Mirakhur+ADs- Vinicius Tavares Pe=
trucci+ADs- Ravis OpenSrc+ADs- Jonathan.Cameron+AEA-huawei.com+ADs- linux-k=
ernel+AEA-vger.kernel.org
Subject: +AFs-EXT+AF0- Re: +AFs-RFC PATCH v2 0/2+AF0- Node migration betwee=
n memory tiers

CAUTION: EXTERNAL EMAIL. Do not click links or open attachments unless you =
recognize the sender and were expecting this message.


+ADw-sthanneeru.opensrc+AEA-micron.com+AD4- writes:

+AD4- From: Srinivasulu Thanneeru +ADw-sthanneeru.opensrc+AEA-micron.com+AD=
4-
+AD4-
+AD4- The memory tiers feature allows nodes with similar memory types
+AD4- or performance characteristics to be grouped together in a
+AD4- memory tier. However, there is currently no provision for
+AD4- moving a node from one tier to another on demand.
+AD4-
+AD4- This patch series aims to support node migration between tiers
+AD4- on demand by sysadmin/root user using the provided sysfs for
+AD4- node migration.
+AD4-
+AD4- To migrate a node to a tier, the corresponding node+IBk-s sysfs
+AD4- memtier+AF8-override is written with target tier id.
+AD4-
+AD4- Example: Move node2 to memory tier2 from its default tier(i.e 4)
+AD4-
+AD4- 1. To check current memtier of node2
+AD4- +ACQ-cat  /sys/devices/system/node/node2/memtier+AF8-override
+AD4- memory+AF8-tier4
+AD4-
+AD4- 2. To migrate node2 to memory+AF8-tier2
+AD4- +ACQ-echo 2 +AD4- /sys/devices/system/node/node2/memtier+AF8-override
+AD4- +ACQ-cat  /sys/devices/system/node/node2/memtier+AF8-override
+AD4- memory+AF8-tier2
+AD4-
+AD4- Usecases:
+AD4-
+AD4- 1. Useful to move cxl nodes to the right tiers from userspace, when
+AD4-    the hardware fails to assign the tiers correctly based on
+AD4-    memorytypes.
+AD4-
+AD4-    On some platforms we have observed cxl memory being assigned to
+AD4-    the same tier as DDR memory. This is arguably a system firmware
+AD4-    bug, but it is true that tiers represent +ACo-ranges+ACo- of perfo=
rmance
+AD4-    and we believe it's important for the system operator to have
+AD4-    the ability to override bad firmware or OS decisions about tier
+AD4-    assignment as a fail-safe against potential bad outcomes.
+AD4-
+AD4- 2. Useful if we want interleave weights to be applied on memory tiers
+AD4-    instead of nodes.
+AD4- In a previous thread, Huang Ying +ADw-ying.huang+AEA-intel.com+AD4- t=
hought
+AD4- this feature might be useful to overcome limitations of systems
+AD4- where nodes with different bandwidth characteristics are grouped
+AD4- in a single tier.
+AD4- https://lore.kernel.org/lkml/87a5rw1wu8.fsf+AEA-yhuang6-desk2.ccr.cor=
p.intel.com/
+AD4-
+AD4- +AD0APQA9AD0APQA9AD0APQA9AD0APQA9AD0-
+AD4- Version Notes:
+AD4-
+AD4- V2 : Changed interface to memtier+AF8-override from adistance+AF8-off=
set.
+AD4- memtier+AF8-override was recommended by
+AD4- 1. John Groves +ADw-john+AEA-jagalactic.com+AD4-
+AD4- 2. Ravi Shankar +ADw-ravis.opensrc+AEA-micron.com+AD4-
+AD4- 3. Brice Goglin +ADw-Brice.Goglin+AEA-inria.fr+AD4-

It appears that you ignored my comments for V1 as follows ...

https://lore.kernel.org/lkml/87o7f62vur.fsf+AEA-yhuang6-desk2.ccr.corp.inte=
l.com/

Thank you Huang, Ying for pointing to this.

https://lpc.events/event/16/contributions/1209/attachments/1042/1995/Live+A=
CU-20In+ACU-20a+ACU-20World+ACU-20With+ACU-20Multiple+ACU-20Memory+ACU-20Ty=
pes.pdf

In the presentation above, the adistance+AF8-offsets are per memtype.
We believe that adistance+AF8-offset per node is more suitable and flexible
since we can change it per node. If we keep adistance+AF8-offset per memtyp=
e,
then we cannot change it for a specific node of a given memtype.


https://lore.kernel.org/lkml/87jzpt2ft5.fsf+AEA-yhuang6-desk2.ccr.corp.inte=
l.com/

I guess that you need to move all NUMA nodes with same performance
metrics together?  If so, That is why we previously proposed to place
the knob in +ACI-memory+AF8-type+ACI-? (From: Huang, Ying )

Yes, memory+AF8-type would be group the related memories togather as single=
 tier.
We should also have a flexibility to move nodes between tiers, to address t=
he issues described in usecases above.

https://lore.kernel.org/lkml/87a5qp2et0.fsf+AEA-yhuang6-desk2.ccr.corp.inte=
l.com/

This patch provides a way to move a node to the correct tier.
We observed in test setups where DRAM and CXL are put under the same
tier (memory+AF8-tier4).
By using this patch, we can move the CXL node away from the DRAM-linked
tier4 and put it in the desired tier.

Regards,
Srini

--
Best Regards,
Huang, Ying

+AD4- V1 : Introduced adistance+AF8-offset sysfs.
+AD4-
+AD4- +AD0APQA9AD0APQA9AD0APQA9AD0APQA9AD0-
+AD4-
+AD4- Srinivasulu Thanneeru (2):
+AD4-   base/node: Add sysfs for memtier+AF8-override
+AD4-   memory tier: Support node migration between tiers
+AD4-
+AD4-  Documentation/ABI/stable/sysfs-devices-node +AHw-  7 +-+-
+AD4-  drivers/base/node.c                         +AHw- 47 +-+-+-+-+-+-+-+=
-+-+-+-+-
+AD4-  include/linux/memory-tiers.h                +AHw- 11 +-+-+-
+AD4-  include/linux/node.h                        +AHw- 11 +-+-+-
+AD4-  mm/memory-tiers.c                           +AHw- 85 +-+-+-+-+-+-+-+=
-+-+-+-+----------
+AD4-  5 files changed, 125 insertions(+-), 36 deletions(-)

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from mgamail.intel.com (mgamail.intel.com [192.55.52.43])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 075E763D7;
	Mon, 18 Dec 2023 05:57:37 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=none dis=none) header.from=intel.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=intel.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=intel.com header.i=@intel.com header.b="jWyTJBrB"
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple;
  d=intel.com; i=@intel.com; q=dns/txt; s=Intel;
  t=1702879058; x=1734415058;
  h=from:to:cc:subject:in-reply-to:references:date:
   message-id:mime-version;
  bh=EUwgnCLnOCjvSoWerIdZN9qy6Wju/5BfP/1nGT2V6Qc=;
  b=jWyTJBrB83C6Pe1qChtM0vLoXQhWf5y0cDLrZvWZWqxKYNfpCGdIzfF8
   pO2RDFg11HR2FZiY9ARAbGJqSFMN/E/ZlxhRCP137/CcwwEk836tSKr2F
   2ilbjn1kd/WcmKSsFoSMBqOwl9iUvFM2GMBokBdHaVG+m/4eSLftfsJQZ
   llLz1TmXXNUp5sFBik8gFo8UxrH9mdc3EbIQJMxZEa++tFGh0oatdz/I6
   rgL6i1VU6ZgXyab/9f/rOi4vhd0k40aCnF3T4lfK7a274NEEHcWsFcFnc
   MVnkkp2sconZeZ8erR1xR+O8XZ0lfDipgHY6yiBDtrZnA8HxR9T4LGlP/
   g==;
X-IronPort-AV: E=McAfee;i="6600,9927,10927"; a="481645807"
X-IronPort-AV: E=Sophos;i="6.04,284,1695711600"; 
   d="scan'208";a="481645807"
Received: from fmviesa001.fm.intel.com ([10.60.135.141])
  by fmsmga105.fm.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 17 Dec 2023 21:57:37 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="6.04,284,1695711600"; 
   d="scan'208";a="17803674"
Received: from yhuang6-desk2.sh.intel.com (HELO yhuang6-desk2.ccr.corp.intel.com) ([10.238.208.55])
  by smtpauth.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 17 Dec 2023 21:57:33 -0800
From: "Huang, Ying" <ying.huang@intel.com>
To: Gregory Price <gregory.price@memverge.com>
Cc: <sthanneeru.opensrc@micron.com>,  <linux-cxl@vger.kernel.org>,
  <linux-mm@kvack.org>,  <sthanneeru@micron.com>,
  <aneesh.kumar@linux.ibm.com>,  <dan.j.williams@intel.com>,
  <mhocko@suse.com>,  <tj@kernel.org>,  <john@jagalactic.com>,
  <emirakhur@micron.com>,  <vtavarespetr@micron.com>,
  <Ravis.OpenSrc@micron.com>,  <Jonathan.Cameron@huawei.com>,
  <linux-kernel@vger.kernel.org>, Johannes Weiner <hannes@cmpxchg.org>, Wei
 Xu <weixugc@google.com>
Subject: Re: [RFC PATCH v2 0/2] Node migration between memory tiers
In-Reply-To: <ZXyQIJOim1+tE0Qr@memverge.com> (Gregory Price's message of "Fri,
	15 Dec 2023 12:42:56 -0500")
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
	<87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZXyQIJOim1+tE0Qr@memverge.com>
Date: Mon, 18 Dec 2023 13:55:34 +0800
Message-ID: <87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
User-Agent: Gnus/5.13 (Gnus v5.13)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Type: text/plain; charset=ascii

Gregory Price <gregory.price@memverge.com> writes:

> On Fri, Dec 15, 2023 at 01:02:59PM +0800, Huang, Ying wrote:
>> <sthanneeru.opensrc@micron.com> writes:
>> 
>> > =============
>> > Version Notes:
>> >
>> > V2 : Changed interface to memtier_override from adistance_offset.
>> > memtier_override was recommended by
>> > 1. John Groves <john@jagalactic.com>
>> > 2. Ravi Shankar <ravis.opensrc@micron.com>
>> > 3. Brice Goglin <Brice.Goglin@inria.fr>
>> 
>> It appears that you ignored my comments for V1 as follows ...
>> 
>> https://lore.kernel.org/lkml/87o7f62vur.fsf@yhuang6-desk2.ccr.corp.intel.com/
>> https://lore.kernel.org/lkml/87jzpt2ft5.fsf@yhuang6-desk2.ccr.corp.intel.com/
>> https://lore.kernel.org/lkml/87a5qp2et0.fsf@yhuang6-desk2.ccr.corp.intel.com/
>> 
>
> Not speaking for the group, just chiming in because i'd discussed it
> with them.
>
> "Memory Type" is a bit nebulous.  Is a Micron Type-3 with performance X
> and an SK Hynix Type-3 with performance Y a "Different type", or are
> they the "Same Type" given that they're both Type 3 backed by some form
> of DDR?  Is socket placement of those devices relevant for determining
> "Type"?  Is whether they are behind a switch relevant for determining
> "Type"? "Type" is frustrating when everything we're talking about
> managing is "Type-3" with difference performance.
>
> A concrete example:
> To the system, a Multi-Headed Single Logical Device (MH-SLD) looks
> exactly the same as an standard SLD.  I may want to have some
> combination of local memory expansion devices on the majority of my
> expansion slots, but reserve 1 slot on each socket for a connection to
> the MH-SLD.   As of right now: There is no good way to differentiate the
> devices in terms of "Type" - and even if you had that, the tiering
> system would still lump them together.
>
> Similarly, an initial run of switches may or may not allow enumeration
> of devices behind it (depends on the configuration), so you may end up
> with a static numa node that "looks like" another SLD - despite it being
> some definition of "GFAM".  Do number of hops matter in determining
> "Type"?

In the original design, the memory devices of same memory type are
managed by the same device driver, linked with system in same way
(including switches), built with same media.  So, the performance is
same too.  And, same as memory tiers, memory types are orthogonal to
sockets.  Do you think the definition itself is clear enough?

I admit "memory type" is a confusing name.  Do you have some better
suggestion?

> So I really don't think "Type" is useful for determining tier placement.
>
> As of right now, the system lumps DRAM nodes as one tier, and pretty
> much everything else as "the other tier". To me, this patch set is an
> initial pass meant to allow user-control over tier composition while
> the internal mechanism is sussed out and the environment develops.

The patchset to identify the performance of memory devices and put them
in proper "memory types" and memory tiers via HMAT has been merged by
v6.7-rc1.

      07a8bdd4120c (memory tiering: add abstract distance calculation algorithms management, 2023-09-26)
      d0376aac59a1 (acpi, hmat: refactor hmat_register_target_initiators(), 2023-09-26)
      3718c02dbd4c (acpi, hmat: calculate abstract distance with HMAT, 2023-09-26)
      6bc2cfdf82d5 (dax, kmem: calculate abstract distance with general interface, 2023-09-26)

> In general, a release valve that lets you redefine tiers is very welcome
> for testing and validation of different setups while the industry evolves.
>
> Just my two cents.

--
Best Regards,
Huang, Ying

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from NAM11-BN8-obe.outbound.protection.outlook.com (mail-bn8nam11on2040.outbound.protection.outlook.com [40.107.236.40])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 7F13A30120;
	Fri, 15 Dec 2023 17:43:09 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=none dis=none) header.from=memverge.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=memverge.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (1024-bit key) header.d=memverge.com header.i=@memverge.com header.b="ML3l9Nfi"
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=GS2gnzJIvVpiUXe21z2Of1uy1st8iHU15YTQ0r+Ejhh6MkoKR3+sAikrnXIP1e89tlMhT85MCk6QTNjC5gNkIW2X27iT4tjw91KQISEgAAMq2EkHbNs5PAHyY7OfjlNwYZnyp3QrUuXefVG2fTRp3JXDLb76hYUYodMLFOe2ClNa6RkYJaCJus9B7g4TYdP8irovcrMf6Fuk3o2KQo7RHcEY6wsI0Z+saIpf10O9m/GL1TlJwtizRBJMbmjFg5VMURUgDH/EQ0MFSdUG8xYkGtw4qyrCnEdY45mVMZnnOmx4IOsJUoQ77KL+YqPvk0j8k8pY8V3KxtJkZt2hFjIuJw==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-AntiSpam-MessageData-ChunkCount:X-MS-Exchange-AntiSpam-MessageData-0:X-MS-Exchange-AntiSpam-MessageData-1;
 bh=Xs8b5T3/it40OjUoOr268t4NxdigYV1DrI7lbLsyghU=;
 b=HrxYfbllUzHIluYZurZqVsqR/jjkfH3TzROxK6oKzKnnsKHs7Mw2Jg8yszekvyUsgXJqJzCavI2AN7drqlms0c3Iq3wWMSfvw8+tXrsRAM75ETQuoPiFtS2vp5pC/yTaGSuicuPSbHXe740Y7M1s50w1t0v2tLJR18UVZPAYV3fgJdAQv6ai+/vwRgicKZMhbxT5GUqwQ5ujtshNZ7K+N1fbnTIutxhi91l6b92fznG483zzRgEYTAXrZmyIxY6kUv8p41r7QhOfrfmUaSzag6K2seUALanvyNihtNnOb/rXLqDoc5Xklb/vOZi7spnFW2ZfDpfQzlBCcd1uR3NVkw==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass
 smtp.mailfrom=memverge.com; dmarc=pass action=none header.from=memverge.com;
 dkim=pass header.d=memverge.com; arc=none
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=memverge.com;
 s=selector2;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=Xs8b5T3/it40OjUoOr268t4NxdigYV1DrI7lbLsyghU=;
 b=ML3l9NfiBjm5UEnB0IBxr4wNb2bfy9j4FZTD+LIsNepqVBfHs8WB3mlj2U34Y9/v+ceuzc5+vTzay+MwUGpt/NfY20yt6l7ljP3puTrffdV675mmHRIxus2q1345XSMF8OHc8iFomlcsSoAmmi2zFfBYOWNyzNcFkfwvF8gnEY8=
Authentication-Results: dkim=none (message not signed)
 header.d=none;dmarc=none action=none header.from=memverge.com;
Received: from SJ0PR17MB5512.namprd17.prod.outlook.com (2603:10b6:a03:394::19)
 by BY5PR17MB3873.namprd17.prod.outlook.com (2603:10b6:a03:21e::23) with
 Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.7091.30; Fri, 15 Dec
 2023 17:43:05 +0000
Received: from SJ0PR17MB5512.namprd17.prod.outlook.com
 ([fe80::381c:7f11:1028:15f4]) by SJ0PR17MB5512.namprd17.prod.outlook.com
 ([fe80::381c:7f11:1028:15f4%5]) with mapi id 15.20.7091.032; Fri, 15 Dec 2023
 17:43:04 +0000
Date: Fri, 15 Dec 2023 12:42:56 -0500
From: Gregory Price <gregory.price@memverge.com>
To: "Huang, Ying" <ying.huang@intel.com>
Cc: sthanneeru.opensrc@micron.com, linux-cxl@vger.kernel.org,
	linux-mm@kvack.org, sthanneeru@micron.com,
	aneesh.kumar@linux.ibm.com, dan.j.williams@intel.com,
	mhocko@suse.com, tj@kernel.org, john@jagalactic.com,
	emirakhur@micron.com, vtavarespetr@micron.com,
	Ravis.OpenSrc@micron.com, Jonathan.Cameron@huawei.com,
	linux-kernel@vger.kernel.org
Subject: Re: [RFC PATCH v2 0/2] Node migration between memory tiers
Message-ID: <ZXyQIJOim1+tE0Qr@memverge.com>
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
 <87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
X-ClientProxiedBy: BY3PR10CA0018.namprd10.prod.outlook.com
 (2603:10b6:a03:255::23) To SJ0PR17MB5512.namprd17.prod.outlook.com
 (2603:10b6:a03:394::19)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
X-MS-PublicTrafficType: Email
X-MS-TrafficTypeDiagnostic: SJ0PR17MB5512:EE_|BY5PR17MB3873:EE_
X-MS-Office365-Filtering-Correlation-Id: c17b7672-beb9-4748-0847-08dbfd954a49
X-MS-Exchange-SenderADCheck: 1
X-MS-Exchange-AntiSpam-Relay: 0
X-Microsoft-Antispam: BCL:0;
X-Microsoft-Antispam-Message-Info: qtNfuqUUGqXw38/361ldaMoSCoW1DFcvLafBgeDBpzcHZlg7JyTsSWKpxmY7pi0g3PqqdPm9j6SjyZnvoCveNYo1rC0aJBt0LbAVefXSyDfi6gsgMtYcKRctJ1lGkKI6FgYwj+KlLNICwJi2sppjo5abmhE9vvh4EtKujhkQS4xfA1qh7VFytgiT9RxrXybsCwzsnopIy4SwTPVI6v7NyRPTG53Y/aszhs4DNYtmcziapNWJ9GTBFjL+g3HgVg8UOk8QLxfrfjQ/MdfHgtlx5cEGO5w0G46fllnAGWaWBjFxw30IvQNamDEKIrLuyXcgRNoHkvn3zPo3NJmIAUE7I6x5BkVDOklt5Dy4QxaM2gNiEhJZFNsVAu+4QjT12xUHHLb1PI/bBTeOonubAgw864Hew3rz+qVwCqHbJWlIOn30zTyQDx+HPL3HhCNS0Dn7nRwT4g+lBxbuNTkExBSUkW27QuejnHJAOxkGo6SuayScYOhMdHejmAbQJZRQStxloqHUZXGRW1s3omo/dd63/mdsGQM3EzdlNs8Bo1TzYwawe1HSi94TaREknnRxoo7EeodnleGAhpuzOC0nHW7ty22o+OudknN+6wXL2tr8qeE=
X-Forefront-Antispam-Report: CIP:255.255.255.255;CTRY:;LANG:en;SCL:1;SRV:;IPV:NLI;SFV:NSPM;H:SJ0PR17MB5512.namprd17.prod.outlook.com;PTR:;CAT:NONE;SFS:(13230031)(136003)(376002)(366004)(39830400003)(346002)(396003)(230922051799003)(64100799003)(1800799012)(451199024)(186009)(66899024)(36756003)(86362001)(38100700002)(316002)(26005)(2616005)(478600001)(6506007)(6666004)(6512007)(8676002)(66946007)(66556008)(66476007)(4326008)(44832011)(6486002)(8936002)(966005)(6916009)(2906002)(41300700001)(5660300002)(7416002)(67856001);DIR:OUT;SFP:1101;
X-MS-Exchange-AntiSpam-MessageData-ChunkCount: 1
X-MS-Exchange-AntiSpam-MessageData-0: =?us-ascii?Q?LvHmO1X/jLL9+s8cBAU9ANDDX2acNVj9CPGN+MNUM7u+Ryd6O5R19AaRpaXZ?=
 =?us-ascii?Q?yKhm/kQO9zaDu2IpOIybDh0nYoaod56qOU/7ei+C2Pul0XZ81nQM70d9Upa5?=
 =?us-ascii?Q?zXFLw6jXuk0+vbv+YfmGlWMCgUKxRgv1i6082qEfvI/v3XD/1jk9KK0oaaFO?=
 =?us-ascii?Q?B4M/VuAB+XVp/v6v6R0KdbF+laYGf3Npad7jSfyvYoyhLBYCa5jxMGtdTVXe?=
 =?us-ascii?Q?0k4LzU0yrIvWRr6glDNKuNIwTSCnXAbf+OvbSfu1ToV+4IlshrciJxWXIRoS?=
 =?us-ascii?Q?yEZQgjFUvV/E80jKSgnqrpXzSiS3jaqoiD6gz7an4/4eJeOkde1qbxNEpDP7?=
 =?us-ascii?Q?oWEehBy/cKHDiV6Jm7boL9DMSQkHFgtYYSakq13J4JoIBmv924+Nf0sHJ4nA?=
 =?us-ascii?Q?lr4zTVyOjRi4/uP31p3naYMxDYzLI/3ckapCcnLe7FF9kVP+KLoPmTUJwhhO?=
 =?us-ascii?Q?Gn7yupmz+XqpeaaoO/PmGyHAyIq1FalYnmbbB5Bg2Bp0/kDzA1+ajYS8lrZL?=
 =?us-ascii?Q?B+PZvP0Bb3BsqSHipIc1S+Ta9UPpTmnPNxx+OX79LuLgf7yMPTW2MqiHd0u7?=
 =?us-ascii?Q?83GaiuTvHgJ11iNH45HjxFDHmNvIWibVIG97dy04jQtZDnwF/r4ZTTl5W7EC?=
 =?us-ascii?Q?ihL4BO2bdwPuZQpBgMln47Oe+2ewQhjAosRzetTbgK2+F74MOkCGhIKENss0?=
 =?us-ascii?Q?P+WT7p5cuQYve3XdXopXmm/dnWS46P/v6J3rhBU/DHe+DsMQ3mCfTZRn36OS?=
 =?us-ascii?Q?3tEiyr/EpLbgktGQ3cwWaTz+l7JRzF/JA28f5rVFktGHIOKpbkYGvzDq+fyD?=
 =?us-ascii?Q?hM4QtJr21vm/JNHsE2UIOTyui4Zs0dTmDjjV/99RkE07rtsLmdPOzIa74D3R?=
 =?us-ascii?Q?Ky5yxeXRb9tIlKJl5xrW5QtiSkWuYDQcfjwTFGWjLCcVuxbyQNXXE7BrPl1g?=
 =?us-ascii?Q?YU3LC3bnEcobkuhJ+k9JHaRZLh+PcdVwGZltoMfOhWIiz2OxNTIAxMaEzwkn?=
 =?us-ascii?Q?3iNL+FWgr6HAGFON+j8r2FcCLmEsekTrRExTDN4v8r2AmEuSbFZY5yfkVsbd?=
 =?us-ascii?Q?BITaZZkzHiHTEGUb8scYzJzAv7al7IoDGBJ7MbPgbPohH8/tZznOvgqEkl8x?=
 =?us-ascii?Q?S8JQMZA3DYrSG+xzpUb+KqnuChe+TAK3G0NqAIHky3VVhHPnkKW5E2RDMx8D?=
 =?us-ascii?Q?mJH5zVtgWmuEyvw9Eg72vJSdt47LGB3841UvHFBo8re1VR2/sZh8j92PIjEI?=
 =?us-ascii?Q?YFzdkeQi+521K2GidDs0ucrm5DaUOSvxAIA4qVhrNBzI23wYhapmImjRAowZ?=
 =?us-ascii?Q?1alSfHyeH/RJUhMI8Royn12gztw6+9hv5X1SCgnpy+r4MLdZib+U0roliJxg?=
 =?us-ascii?Q?oikYBK6zwZjZn7Wdnk2TPPN22AB7D68w0X/6LTe1qRWq1gmloIZ9TJbtdmJy?=
 =?us-ascii?Q?9LUUNr2z3LDNynTMZ7CWAJnOBZ62wIU/l1Td/woX6LzIA5BL8NSkY6riQ8hE?=
 =?us-ascii?Q?ETg2z6WJH/EVqE6fS3od0FQu23aoRSPOPr7NdbW+oCrHQzme0V5Vtd7V6U2O?=
 =?us-ascii?Q?DQEynX1dE9rsP5bbImodYBGFuDroGjDrFmmpaoDq2vWiD0TuL6Zy/fE3EoBR?=
 =?us-ascii?Q?WA=3D=3D?=
X-OriginatorOrg: memverge.com
X-MS-Exchange-CrossTenant-Network-Message-Id: c17b7672-beb9-4748-0847-08dbfd954a49
X-MS-Exchange-CrossTenant-AuthSource: SJ0PR17MB5512.namprd17.prod.outlook.com
X-MS-Exchange-CrossTenant-AuthAs: Internal
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 15 Dec 2023 17:43:04.3528
 (UTC)
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-CrossTenant-Id: 5c90cb59-37e7-4c81-9c07-00473d5fb682
X-MS-Exchange-CrossTenant-MailboxType: HOSTED
X-MS-Exchange-CrossTenant-UserPrincipalName: +tyNjT48BM55/16fj+TVk5bU+ZTcsTnQeJZsBgCABQB17Rsa5xcTjoprr1B2x/ouiZlDAwGx4CGG+PDGEso2o+vz3+1TpZIh2FudEdK8Zb0=
X-MS-Exchange-Transport-CrossTenantHeadersStamped: BY5PR17MB3873

On Fri, Dec 15, 2023 at 01:02:59PM +0800, Huang, Ying wrote:
> <sthanneeru.opensrc@micron.com> writes:
> 
> > =============
> > Version Notes:
> >
> > V2 : Changed interface to memtier_override from adistance_offset.
> > memtier_override was recommended by
> > 1. John Groves <john@jagalactic.com>
> > 2. Ravi Shankar <ravis.opensrc@micron.com>
> > 3. Brice Goglin <Brice.Goglin@inria.fr>
> 
> It appears that you ignored my comments for V1 as follows ...
> 
> https://lore.kernel.org/lkml/87o7f62vur.fsf@yhuang6-desk2.ccr.corp.intel.com/
> https://lore.kernel.org/lkml/87jzpt2ft5.fsf@yhuang6-desk2.ccr.corp.intel.com/
> https://lore.kernel.org/lkml/87a5qp2et0.fsf@yhuang6-desk2.ccr.corp.intel.com/
> 

Not speaking for the group, just chiming in because i'd discussed it
with them.

"Memory Type" is a bit nebulous.  Is a Micron Type-3 with performance X
and an SK Hynix Type-3 with performance Y a "Different type", or are
they the "Same Type" given that they're both Type 3 backed by some form
of DDR?  Is socket placement of those devices relevant for determining
"Type"?  Is whether they are behind a switch relevant for determining
"Type"? "Type" is frustrating when everything we're talking about
managing is "Type-3" with difference performance.

A concrete example:
To the system, a Multi-Headed Single Logical Device (MH-SLD) looks
exactly the same as an standard SLD.  I may want to have some
combination of local memory expansion devices on the majority of my
expansion slots, but reserve 1 slot on each socket for a connection to
the MH-SLD.   As of right now: There is no good way to differentiate the
devices in terms of "Type" - and even if you had that, the tiering
system would still lump them together.

Similarly, an initial run of switches may or may not allow enumeration
of devices behind it (depends on the configuration), so you may end up
with a static numa node that "looks like" another SLD - despite it being
some definition of "GFAM".  Do number of hops matter in determining
"Type"?

So I really don't think "Type" is useful for determining tier placement.

As of right now, the system lumps DRAM nodes as one tier, and pretty
much everything else as "the other tier". To me, this patch set is an
initial pass meant to allow user-control over tier composition while
the internal mechanism is sussed out and the environment develops.

In general, a release valve that lets you redefine tiers is very welcome
for testing and validation of different setups while the industry evolves.

Just my two cents.

~Gregory

> --
> Best Regards,
> Huang, Ying
> 

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from mgamail.intel.com (mgamail.intel.com [198.175.65.13])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 8865E1798F;
	Wed,  3 Jan 2024 06:09:57 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=none dis=none) header.from=intel.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=intel.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=intel.com header.i=@intel.com header.b="TujT5M6C"
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple;
  d=intel.com; i=@intel.com; q=dns/txt; s=Intel;
  t=1704262198; x=1735798198;
  h=from:to:cc:subject:in-reply-to:references:date:
   message-id:mime-version;
  bh=SlVD6Rk0BkluSSjYPsszZ6WpuFk/Fh1OB487VtaCkVo=;
  b=TujT5M6C5DYdfncUqOYKwhbtUUdivG1BhH+6R6YYd+JsOiT6pSdUf69S
   F+Mi3ToUl1HUkqzacSn9nTzUdyjxHjq1xPTxrPA2GdXBurL7S22Okky/0
   Pf7b2VKXhP5q85NF4rhco+nrFVD2ax2F6dy3q2utrg4xvJDgm0JVKHA1Q
   VzbRLD344/nTntxMwt4B1/nYXr+IRmI63s9tO8Fu1L7/G7tQ/DyCg+eLK
   YVCfxeyEWY5PWIQcwaSIYyisnhalw6vmdfcS8kjVJYuX8tCOKAHeVFsgN
   tifbqrWrvmFFswjl77lPXRqb6xI/fodo9utnVZVT8yKlZMfUmhP2O4Y+c
   w==;
X-IronPort-AV: E=McAfee;i="6600,9927,10941"; a="4044339"
X-IronPort-AV: E=Sophos;i="6.04,327,1695711600"; 
   d="scan'208";a="4044339"
Received: from orsmga004.jf.intel.com ([10.7.209.38])
  by orvoesa105.jf.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 02 Jan 2024 22:09:57 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=McAfee;i="6600,9927,10941"; a="903334248"
X-IronPort-AV: E=Sophos;i="6.04,327,1695711600"; 
   d="scan'208";a="903334248"
Received: from yhuang6-desk2.sh.intel.com (HELO yhuang6-desk2.ccr.corp.intel.com) ([10.238.208.55])
  by orsmga004-auth.jf.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 02 Jan 2024 22:09:52 -0800
From: "Huang, Ying" <ying.huang@intel.com>
To: Srinivasulu Thanneeru <sthanneeru@micron.com>
Cc: gregory.price <gregory.price@memverge.com>,  Srinivasulu Opensrc
 <sthanneeru.opensrc@micron.com>,  "linux-cxl@vger.kernel.org"
 <linux-cxl@vger.kernel.org>,  "linux-mm@kvack.org" <linux-mm@kvack.org>,
  "aneesh.kumar@linux.ibm.com" <aneesh.kumar@linux.ibm.com>,
  "dan.j.williams@intel.com" <dan.j.williams@intel.com>,  "mhocko@suse.com"
 <mhocko@suse.com>,  "tj@kernel.org" <tj@kernel.org>,
  "john@jagalactic.com" <john@jagalactic.com>,  Eishan Mirakhur
 <emirakhur@micron.com>,  Vinicius Tavares Petrucci
 <vtavarespetr@micron.com>,  Ravis OpenSrc <Ravis.OpenSrc@micron.com>,
  "Jonathan.Cameron@huawei.com" <Jonathan.Cameron@huawei.com>,
  "linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>,  "Johannes
 Weiner" <hannes@cmpxchg.org>,  Wei Xu <weixugc@google.com>
Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
In-Reply-To: <PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	(Srinivasulu Thanneeru's message of "Wed, 3 Jan 2024 05:26:32 +0000")
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
	<87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZXyQIJOim1+tE0Qr@memverge.com>
	<87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
Date: Wed, 03 Jan 2024 14:07:54 +0800
Message-ID: <87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
User-Agent: Gnus/5.13 (Gnus v5.13)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Type: text/plain; charset=ascii

Srinivasulu Thanneeru <sthanneeru@micron.com> writes:

> Micron Confidential
>
> Hi Huang, Ying,
>
> My apologies for wrong mail reply format, my mail client settings got changed on my PC.
> Please find comments bellow inline.
>
> Regards,
> Srini
>
>
> Micron Confidential
>> -----Original Message-----
>> From: Huang, Ying <ying.huang@intel.com>
>> Sent: Monday, December 18, 2023 11:26 AM
>> To: gregory.price <gregory.price@memverge.com>
>> Cc: Srinivasulu Opensrc <sthanneeru.opensrc@micron.com>; linux-
>> cxl@vger.kernel.org; linux-mm@kvack.org; Srinivasulu Thanneeru
>> <sthanneeru@micron.com>; aneesh.kumar@linux.ibm.com;
>> dan.j.williams@intel.com; mhocko@suse.com; tj@kernel.org;
>> john@jagalactic.com; Eishan Mirakhur <emirakhur@micron.com>; Vinicius
>> Tavares Petrucci <vtavarespetr@micron.com>; Ravis OpenSrc
>> <Ravis.OpenSrc@micron.com>; Jonathan.Cameron@huawei.com; linux-
>> kernel@vger.kernel.org; Johannes Weiner <hannes@cmpxchg.org>; Wei Xu
>> <weixugc@google.com>
>> Subject: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
>>
>> CAUTION: EXTERNAL EMAIL. Do not click links or open attachments unless
>> you recognize the sender and were expecting this message.
>>
>>
>> Gregory Price <gregory.price@memverge.com> writes:
>>
>> > On Fri, Dec 15, 2023 at 01:02:59PM +0800, Huang, Ying wrote:
>> >> <sthanneeru.opensrc@micron.com> writes:
>> >>
>> >> > =============
>> >> > Version Notes:
>> >> >
>> >> > V2 : Changed interface to memtier_override from adistance_offset.
>> >> > memtier_override was recommended by
>> >> > 1. John Groves <john@jagalactic.com>
>> >> > 2. Ravi Shankar <ravis.opensrc@micron.com>
>> >> > 3. Brice Goglin <Brice.Goglin@inria.fr>
>> >>
>> >> It appears that you ignored my comments for V1 as follows ...
>> >>
>> >>
>> https://lore.k/
>> ernel.org%2Flkml%2F87o7f62vur.fsf%40yhuang6-
>> desk2.ccr.corp.intel.com%2F&data=05%7C02%7Csthanneeru%40micron.com
>> %7C5e614e5f028342b6b59c08dbff8e3e37%7Cf38a5ecd28134862b11bac1d56
>> 3c806f%7C0%7C0%7C638384758666895965%7CUnknown%7CTWFpbGZsb3d
>> 8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3
>> D%7C3000%7C%7C%7C&sdata=OpMkYCar%2Fv8uHb7AvXbmaNltnXeTvcNUTi
>> bLhwV12Fg%3D&reserved=0
>
> Thank you, Huang, Ying for pointing to this.
> https://lpc.events/event/16/contributions/1209/attachments/1042/1995/Live%20In%20a%20World%20With%20Multiple%20Memory%20Types.pdf
>
> In the presentation above, the adistance_offsets are per memtype.
> We believe that adistance_offset per node is more suitable and flexible.
> since we can change it per node. If we keep adistance_offset per memtype,
> then we cannot change it for a specific node of a given memtype.
>
>> >>
>> https://lore.k/
>> ernel.org%2Flkml%2F87jzpt2ft5.fsf%40yhuang6-
>> desk2.ccr.corp.intel.com%2F&data=05%7C02%7Csthanneeru%40micron.com
>> %7C5e614e5f028342b6b59c08dbff8e3e37%7Cf38a5ecd28134862b11bac1d56
>> 3c806f%7C0%7C0%7C638384758666895965%7CUnknown%7CTWFpbGZsb3d
>> 8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3
>> D%7C3000%7C%7C%7C&sdata=O0%2B6T%2FgU0TicCEYBac%2FAyjOLwAeouh
>> D%2BcMI%2BflOsI1M%3D&reserved=0
>
> Yes, memory_type would be grouping the related memories together as single tier.
> We should also have a flexibility to move nodes between tiers, to address the issues.
> described in use cases above.

We don't pursue absolute flexibility.  We add necessary flexibility
only.  Why do you need this kind of flexibility?  Can you provide some
use cases where memory_type based "adistance_offset" doesn't work?

--
Best Regards,
Huang, Ying

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from NAM12-BN8-obe.outbound.protection.outlook.com (mail-bn8nam12on2063.outbound.protection.outlook.com [40.107.237.63])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 6B2B3168DC;
	Wed,  3 Jan 2024 05:26:37 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=reject dis=none) header.from=micron.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=micron.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=micron.com header.i=@micron.com header.b="Vzo9t6ux"
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=XZQNs+PRHpNb6eIpp7kL50gamJyg1TweioDIU7MXmUFyqc3DmxKyiXx7pF6zDPyAAlb4CdV7brZmK7R2bO++jLxbYRySF74jlW03wX0cCZyWURFpZAm3YnMbceVV85+xAMQgVwPtx70WPuLdN/R3LVCV1rJ0ChCvgK8xL67UIEoTO2v/IjFkPe/h4gfTp5qxPts60YDU5f4tq/eLSXr7ImqXXFJ+jF6ez8DL5wX4sBTA1n0AaoKpYFiU77a6XG76xt8nfs2VjwqJAcD9JUJslWHSU5KnBtboKinwngXhkB9AG404PRZ7jCs5uI2emrPZxjaeD4JOAUck/TsMDS98QA==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-AntiSpam-MessageData-ChunkCount:X-MS-Exchange-AntiSpam-MessageData-0:X-MS-Exchange-AntiSpam-MessageData-1;
 bh=zOATxj3gAn1ZUclxGASVU/0MgJ/v5O6R+ufHOv+3mk0=;
 b=JyK7V/5bLwNddH9lfVsLVF1tH0g/zkS43sBvxdj0DxSJXhCyLfN04OdSVtCBcodBJO+Fuk3ZTCKk89EEvd2+7hAhnkI2DvGu3yhVj54GK16Cr+EQCYWOCMVCe8GSA975AgGOG60JPIyAI3LKbd1VM0SoXGhioytutQ1+xrC+5O1pvccG0etIWoIydiSKcXU1pJTpC6nOTgEkfVbfghTwlecXcMsaQFm3WF3n+x2c/YUfoUi5MRVd6D+P5yi1/ph4haRBpWq9VX+YRI6eSVaf0iBH9likcF7nNGn99SgEzi1hw6xukrCl168Fwaqt7cxhXYrHwI3jZwFaMYa/62EUxw==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass
 smtp.mailfrom=micron.com; dmarc=pass action=none header.from=micron.com;
 dkim=pass header.d=micron.com; arc=none
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=micron.com;
 s=selector2;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=zOATxj3gAn1ZUclxGASVU/0MgJ/v5O6R+ufHOv+3mk0=;
 b=Vzo9t6uxUFNOBJW8MPtBoGsDlOHH3lVY2Q9QKTA3RKXrjo28m7C296IiutFuShSAo0Baz+SAV0QZzw177xZzxZkQIWJ7IwTh2yKvpB6r6JDVjGx3KCnOkAE58V/roR7n4esQ9jRd/eaGi8LtPnCy6XCOSsdTGbhwNNnzRwImegxLtrKxo4enrkzq3U0Mgbp/YKXQtuxDVzeNi4LC5UR572xGJn8hdRsNC+0DJt+Pk3wTk/QE0QfXA0hahOlsCCXEwWhXPnDMzoGGtrMLeCNRcUGP1J8X2i5Q44FaPYmed684K3R6l5+Af/TAaYBENp6zEPk5uF11WnBbemMq6jmOVQ==
Received: from PH0PR08MB7955.namprd08.prod.outlook.com (2603:10b6:510:11a::17)
 by DM6PR08MB6236.namprd08.prod.outlook.com (2603:10b6:5:1e1::7) with
 Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.7159.12; Wed, 3 Jan
 2024 05:26:32 +0000
Received: from PH0PR08MB7955.namprd08.prod.outlook.com
 ([fe80::5049:9abf:ad65:9974]) by PH0PR08MB7955.namprd08.prod.outlook.com
 ([fe80::5049:9abf:ad65:9974%3]) with mapi id 15.20.7159.013; Wed, 3 Jan 2024
 05:26:32 +0000
From: Srinivasulu Thanneeru <sthanneeru@micron.com>
To: "Huang, Ying" <ying.huang@intel.com>, gregory.price
	<gregory.price@memverge.com>
CC: Srinivasulu Opensrc <sthanneeru.opensrc@micron.com>,
	"linux-cxl@vger.kernel.org" <linux-cxl@vger.kernel.org>, "linux-mm@kvack.org"
	<linux-mm@kvack.org>, "aneesh.kumar@linux.ibm.com"
	<aneesh.kumar@linux.ibm.com>, "dan.j.williams@intel.com"
	<dan.j.williams@intel.com>, "mhocko@suse.com" <mhocko@suse.com>,
	"tj@kernel.org" <tj@kernel.org>, "john@jagalactic.com" <john@jagalactic.com>,
	Eishan Mirakhur <emirakhur@micron.com>, Vinicius Tavares Petrucci
	<vtavarespetr@micron.com>, Ravis OpenSrc <Ravis.OpenSrc@micron.com>,
	"Jonathan.Cameron@huawei.com" <Jonathan.Cameron@huawei.com>,
	"linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>, Johannes
 Weiner <hannes@cmpxchg.org>, Wei Xu <weixugc@google.com>
Subject: RE: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
Thread-Topic: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
Thread-Index: AQHaLe1WCWEmLbBSRk2O5Sdey42WeLCpzLPHgADTuACAA/H6xIAZGhOA
Date: Wed, 3 Jan 2024 05:26:32 +0000
Message-ID: <PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
	<87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZXyQIJOim1+tE0Qr@memverge.com>
 <87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
In-Reply-To: <87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
msip_labels: MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_ActionId=1871acef-68e6-4a74-bff7-df01830ee16b;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_ContentBits=0;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_Enabled=true;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_Method=Standard;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_Name=Confidential;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_SetDate=2024-01-03T05:17:36Z;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_SiteId=f38a5ecd-2813-4862-b11b-ac1d563c806f;
authentication-results: dkim=none (message not signed)
 header.d=none;dmarc=none action=none header.from=micron.com;
x-ms-publictraffictype: Email
x-ms-traffictypediagnostic: PH0PR08MB7955:EE_|DM6PR08MB6236:EE_
x-ms-office365-filtering-correlation-id: a1ca4657-39bf-4289-4b52-08dc0c1c8bbc
x-ld-processed: f38a5ecd-2813-4862-b11b-ac1d563c806f,ExtAddr
x-ms-exchange-senderadcheck: 1
x-ms-exchange-antispam-relay: 0
x-microsoft-antispam: BCL:0;
x-microsoft-antispam-message-info: g1qOLgjpqCV+F+lzp5mMjM1N7nPA0ADx2SJgu1fkEomtCXRki0LphVuck3hhF/ejV8qIDezE448uu8Nnn2sfpl6xLdoJKFFdFy2PNVyopoc/Qy4M1B/W5dvxrFWdRqpsl4AesYcURUkJiLthRzdze3lyKbVKdgRoBvtkcwimwt1Qk+bOLUaV8OO+G6Gq2Nd/uagMgN7airZqlCFC48c+Jb65m1tRQTZXsKf9eKchVz5IdZVd5RHo39AE5I7zVDCiKRWw9WFznWzuMrQ6sK6fLQxzpT82fHY1Kr8Sk49jw+EQzGFE3mMYklaz5LLRA0cV2ikaHMmne6fcdqj8VqBx6BwGzZ8qLlcQlw7pgpTkg/ynpLJQx/IKf/v/ecFq2ZAak/YmKMlg0ZWOzWjz/HCIu/4oUIFmzOLGB1TwoD6sBQmGHRAFO8mEh4FHx27h5szkNi3KQXqimrxQWNTIzlvLnQuaHm2TdAXK6PP4cYWKvO50TxmpflpThVQEPX+l3zwnAukhx7XWe8TbCtvF3QhXkrFyPkrcrr0b3bbZoMhoY8ImSFm0cKZETQLb4S8uzWRRB6CMdyLdY34Ah+sqhs6doO3B6sSScic++rdAx4fHaTbYP11QnlbxCksxGF4qrO7Wpo5+knj9ZhmajmgNS/TFvA==
x-forefront-antispam-report: CIP:255.255.255.255;CTRY:;LANG:en;SCL:1;SRV:;IPV:NLI;SFV:NSPM;H:PH0PR08MB7955.namprd08.prod.outlook.com;PTR:;CAT:NONE;SFS:(13230031)(346002)(39860400002)(376002)(136003)(396003)(366004)(230173577357003)(230273577357003)(230922051799003)(64100799003)(186009)(1800799012)(451199024)(66476007)(66446008)(76116006)(66946007)(64756008)(66556008)(4326008)(110136005)(8676002)(8936002)(54906003)(316002)(26005)(83380400001)(966005)(71200400001)(45080400002)(478600001)(9686003)(53546011)(7696005)(52536014)(2906002)(5660300002)(41300700001)(7416002)(6506007)(33656002)(38070700009)(122000001)(66899024)(38100700002)(86362001)(55016003);DIR:OUT;SFP:1101;
x-ms-exchange-antispam-messagedata-chunkcount: 1
x-ms-exchange-antispam-messagedata-0: =?utf-7?B?Wm1nUWtqOElRUURlcEdCc1RoUFNuSnZhb2VyUnpnVzZidXJ4R0E4cVpDdmdN?=
 =?utf-7?B?YzVuM0JESmVJZ3RtV3RFRDJBR3ZzbFhxd2ZhNldsOFhRTEJMZ1RhQmkrLVFt?=
 =?utf-7?B?azNRTWZ4TnpzWmk0L3Zzdm0xSmxGTUpueFFjdTVDRDQvbHhYUTdURGtMNFQ=?=
 =?utf-7?B?Ky1kQXJlUFI0bHRmQ2VJNHNPZGRocEtCTng4QkN5R3J4eE1icGVrVFVwbHJR?=
 =?utf-7?B?LzdaKy1tNE43Mjd0MTRLTlZTL2ZLa3ZNeGtEaDY1QXZxTWl3b2c0QlYvNFBY?=
 =?utf-7?B?THpCSEtjUVpCQ0VuV2NaYXdoY0cxa3dPcVF1L1RIYzlZcWtOak8xSzZoNDZJ?=
 =?utf-7?B?Z1diQnJoNCstU21RVmRNTGtyYzB2TmtQQUpSaXh2OTM5WEs4M3hHNDhmTTJp?=
 =?utf-7?B?THRXOGpEdnNvN1V1alJNSEdXVFN4ZnBIdEY2d3FRVjJ3bFN4amFEM3dPNTEv?=
 =?utf-7?B?SVRhNnJBeXVyZkJTMy82Wm9GZElJcWpkeUh6aDJweXBsR2VGTW1XeThYQVJT?=
 =?utf-7?B?Q0pNUVBtRlNHOUZLb2doZEh3cVh4RjBtQ2ZCZ0dxZkFLcUtjbHVHS0h4dVhY?=
 =?utf-7?B?NWlFY2NoSUpjTDRnTW5xTTVhR0syWmRZNjlOc2pCeFkzWi93RU9mL2p0MVNs?=
 =?utf-7?B?RVdYZTJnSGJwNnYxb3dKb0RzUEF0QVlOSnJxa0ZBdWV4Ulc1MW9NRCstSXc1?=
 =?utf-7?B?elRvM0MxRkZMZExscXpESEtYOFpHOHFzaHY0MkZock1oOVlDVSstSEd5UExY?=
 =?utf-7?B?d3JnMGpIMmEyRUs1NnhGWjluS2xNMnE0TjR3S0hYblBUTVNnQ04rLUczQzY=?=
 =?utf-7?B?ZystS2hyaHBSbE1oeW5xMlNqNFVpNG9jeW9BWWV2UjVydXcxRnRvVDV3dVhu?=
 =?utf-7?B?V0VJTUdqNzE1UUE5bUs4TG5oYzRENFMwYkVQdHk0VHBTTkpQeUQ1c3dPdTlT?=
 =?utf-7?B?aUozZmVKb3VsNi9EemZaTXpxMXJPZ3l0aFNTbmtlL3FINlVUeFJjQW9nUjB2?=
 =?utf-7?B?d3BCczJaT2RDS2c3SGdvYW5SZ1VtS3k0aXFYTnEvRWVHV21rbGl0M0d6L084?=
 =?utf-7?B?ZkJhM3Nzb2daTUdqTFE5T1N5ckF2V3NTS3UwMjdxeUNOMmNSR2Q1cEF6blNU?=
 =?utf-7?B?aW8rLW01Tk5uVDlrMFhicEVrNU05RlR6MXRDNUh0QVJPdmtmV1E5S2ZBSk43?=
 =?utf-7?B?bVZ5RXEwYkcyUjgrLVUvbUt1UE4xY1FUenY4cXRqOEtlVk1NWXdhOGZtb1V5?=
 =?utf-7?B?QTdhZU9OKy1DM25pM21Wc1hTOXRuQ1lld08xZmREejVFc255L3pBUEJoakdw?=
 =?utf-7?B?QUNsblNMYWthOE9RNks3YzRiYkE3ZFNzOUswZE9waGJsQ1VSeGRxT1QvMDNq?=
 =?utf-7?B?eG54NDhlcVFDYjdCeGN4UTZqd1dWNkhhYzY2SW1qaHRpZDRXQmlqa3NZWG1M?=
 =?utf-7?B?VVNsV3lPMDJMemRRbVNMZkpxYmFodzJ2MUtNNUp2bistTjQwTEUrLWFKU2xU?=
 =?utf-7?B?TmFKMUsvdGdCRTR2UnVqeEJrWng5ZXpEUXpvL2hHRHh4c1loWDVVNWFnL08=?=
 =?utf-7?B?Ky1wbDlkS1ZXbC9oL08vQmtZNHBDZjFmU3ZVZS9mNGw2ai9vOWI3NHBNR2pr?=
 =?utf-7?B?cCstNTc5REp5dkU0VkswMVhlYzE5ai9Qem1Rbnk3bDB5YlNwS2tycG5iVy83?=
 =?utf-7?B?eUY0Ly8zdThCcURTN0s0SkNpRnZEckVnYURWZ1lnSS9ySUFxVE1xRVZHSXRE?=
 =?utf-7?B?SmJnTjZqbVVsMjB1eGt1QVZMeDlQTWk0Um5leGJTR01vUWtvNjlMYkk0RU1X?=
 =?utf-7?B?NzlWS0xLQkhHNWxkSnNLbzNaTmIxM1o5SkhTQjJtMCstNTBMYmtueistVXFR?=
 =?utf-7?B?bjFlU3hvc25jKy05OTRkSFZNTGt4ZkJnakcxS0VJVEE2MTc2WC9JMHdlZXc4?=
 =?utf-7?B?TERUMUFYSUM2aGJXSystbXNiTEUzdDg1Ky1QUDAxOENzMmFqN0Q5R3NsczFw?=
 =?utf-7?B?elhRU2t2VlM3czYrLTJpVFcvSkF1bVdyTHg3TTlVZndBQUUrLVVZVkJLYkZh?=
 =?utf-7?B?SGpNSk4zeFhkbERqNnI2WFp1TGtEb2VnY2dOVWZXdURQNU1BelcvcEZ6UXk0?=
 =?utf-7?B?ZU53NFBldUhZKy1xbkdRZEJ5L0U3WU94MzVCbVA5ZjRZaWdYRWdhTnlEd0tn?=
 =?utf-7?B?MWFxcVlD?=
Content-Type: text/plain; charset="utf-7"
Content-Transfer-Encoding: quoted-printable
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
X-OriginatorOrg: micron.com
X-MS-Exchange-CrossTenant-AuthAs: Internal
X-MS-Exchange-CrossTenant-AuthSource: PH0PR08MB7955.namprd08.prod.outlook.com
X-MS-Exchange-CrossTenant-Network-Message-Id: a1ca4657-39bf-4289-4b52-08dc0c1c8bbc
X-MS-Exchange-CrossTenant-originalarrivaltime: 03 Jan 2024 05:26:32.2648
 (UTC)
X-MS-Exchange-CrossTenant-fromentityheader: Hosted
X-MS-Exchange-CrossTenant-id: f38a5ecd-2813-4862-b11b-ac1d563c806f
X-MS-Exchange-CrossTenant-mailboxtype: HOSTED
X-MS-Exchange-CrossTenant-userprincipalname: 4mqks+FTcp1EK+GfVfObFbMWoa01uuO9iFkLu86mMHfjqhOlzcZIzaFBQO+BA12qvIQEF2Zu2NboKql28sGP/g==
X-MS-Exchange-Transport-CrossTenantHeadersStamped: DM6PR08MB6236

Micron Confidential

Hi Huang, Ying,

My apologies for wrong mail reply format, my mail client settings got chang=
ed on my PC.
Please find comments bellow inline.

Regards,
Srini


Micron Confidential
+AD4- -----Original Message-----
+AD4- From: Huang, Ying +ADw-ying.huang+AEA-intel.com+AD4-
+AD4- Sent: Monday, December 18, 2023 11:26 AM
+AD4- To: gregory.price +ADw-gregory.price+AEA-memverge.com+AD4-
+AD4- Cc: Srinivasulu Opensrc +ADw-sthanneeru.opensrc+AEA-micron.com+AD4AOw=
- linux-
+AD4- cxl+AEA-vger.kernel.org+ADs- linux-mm+AEA-kvack.org+ADs- Srinivasulu =
Thanneeru
+AD4- +ADw-sthanneeru+AEA-micron.com+AD4AOw- aneesh.kumar+AEA-linux.ibm.com=
+ADs-
+AD4- dan.j.williams+AEA-intel.com+ADs- mhocko+AEA-suse.com+ADs- tj+AEA-ker=
nel.org+ADs-
+AD4- john+AEA-jagalactic.com+ADs- Eishan Mirakhur +ADw-emirakhur+AEA-micro=
n.com+AD4AOw- Vinicius
+AD4- Tavares Petrucci +ADw-vtavarespetr+AEA-micron.com+AD4AOw- Ravis OpenS=
rc
+AD4- +ADw-Ravis.OpenSrc+AEA-micron.com+AD4AOw- Jonathan.Cameron+AEA-huawei=
.com+ADs- linux-
+AD4- kernel+AEA-vger.kernel.org+ADs- Johannes Weiner +ADw-hannes+AEA-cmpxc=
hg.org+AD4AOw- Wei Xu
+AD4- +ADw-weixugc+AEA-google.com+AD4-
+AD4- Subject: +AFs-EXT+AF0- Re: +AFs-RFC PATCH v2 0/2+AF0- Node migration =
between memory tiers
+AD4-
+AD4- CAUTION: EXTERNAL EMAIL. Do not click links or open attachments unles=
s
+AD4- you recognize the sender and were expecting this message.
+AD4-
+AD4-
+AD4- Gregory Price +ADw-gregory.price+AEA-memverge.com+AD4- writes:
+AD4-
+AD4- +AD4- On Fri, Dec 15, 2023 at 01:02:59PM +-0800, Huang, Ying wrote:
+AD4- +AD4APg- +ADw-sthanneeru.opensrc+AEA-micron.com+AD4- writes:
+AD4- +AD4APg-
+AD4- +AD4APg- +AD4- +AD0APQA9AD0APQA9AD0APQA9AD0APQA9AD0-
+AD4- +AD4APg- +AD4- Version Notes:
+AD4- +AD4APg- +AD4-
+AD4- +AD4APg- +AD4- V2 : Changed interface to memtier+AF8-override from ad=
istance+AF8-offset.
+AD4- +AD4APg- +AD4- memtier+AF8-override was recommended by
+AD4- +AD4APg- +AD4- 1. John Groves +ADw-john+AEA-jagalactic.com+AD4-
+AD4- +AD4APg- +AD4- 2. Ravi Shankar +ADw-ravis.opensrc+AEA-micron.com+AD4-
+AD4- +AD4APg- +AD4- 3. Brice Goglin +ADw-Brice.Goglin+AEA-inria.fr+AD4-
+AD4- +AD4APg-
+AD4- +AD4APg- It appears that you ignored my comments for V1 as follows ..=
.
+AD4- +AD4APg-
+AD4- +AD4APg-
+AD4- https://lore.k/
+AD4- ernel.org+ACU-2Flkml+ACU-2F87o7f62vur.fsf+ACU-40yhuang6-
+AD4- desk2.ccr.corp.intel.com+ACU-2F+ACY-data+AD0-05+ACU-7C02+ACU-7Csthann=
eeru+ACU-40micron.com
+AD4- +ACU-7C5e614e5f028342b6b59c08dbff8e3e37+ACU-7Cf38a5ecd28134862b11bac1=
d56
+AD4- 3c806f+ACU-7C0+ACU-7C0+ACU-7C638384758666895965+ACU-7CUnknown+ACU-7CT=
WFpbGZsb3d
+AD4- 8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0+ACU-=
3
+AD4- D+ACU-7C3000+ACU-7C+ACU-7C+ACU-7C+ACY-sdata+AD0-OpMkYCar+ACU-2Fv8uHb7=
AvXbmaNltnXeTvcNUTi
+AD4- bLhwV12Fg+ACU-3D+ACY-reserved+AD0-0

Thank you, Huang, Ying for pointing to this.
https://lpc.events/event/16/contributions/1209/attachments/1042/1995/Live+A=
CU-20In+ACU-20a+ACU-20World+ACU-20With+ACU-20Multiple+ACU-20Memory+ACU-20Ty=
pes.pdf

In the presentation above, the adistance+AF8-offsets are per memtype.
We believe that adistance+AF8-offset per node is more suitable and flexible=
.
since we can change it per node. If we keep adistance+AF8-offset per memtyp=
e,
then we cannot change it for a specific node of a given memtype.

+AD4- +AD4APg-
+AD4- https://lore.k/
+AD4- ernel.org+ACU-2Flkml+ACU-2F87jzpt2ft5.fsf+ACU-40yhuang6-
+AD4- desk2.ccr.corp.intel.com+ACU-2F+ACY-data+AD0-05+ACU-7C02+ACU-7Csthann=
eeru+ACU-40micron.com
+AD4- +ACU-7C5e614e5f028342b6b59c08dbff8e3e37+ACU-7Cf38a5ecd28134862b11bac1=
d56
+AD4- 3c806f+ACU-7C0+ACU-7C0+ACU-7C638384758666895965+ACU-7CUnknown+ACU-7CT=
WFpbGZsb3d
+AD4- 8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0+ACU-=
3
+AD4- D+ACU-7C3000+ACU-7C+ACU-7C+ACU-7C+ACY-sdata+AD0-O0+ACU-2B6T+ACU-2FgU0=
TicCEYBac+ACU-2FAyjOLwAeouh
+AD4- D+ACU-2BcMI+ACU-2BflOsI1M+ACU-3D+ACY-reserved+AD0-0

Yes, memory+AF8-type would be grouping the related memories together as sin=
gle tier.
We should also have a flexibility to move nodes between tiers, to address t=
he issues.
described in use cases above.

+AD4- +AD4APg-
+AD4- https://lore.k/
+AD4- ernel.org+ACU-2Flkml+ACU-2F87a5qp2et0.fsf+ACU-40yhuang6-
+AD4- desk2.ccr.corp.intel.com+ACU-2F+ACY-data+AD0-05+ACU-7C02+ACU-7Csthann=
eeru+ACU-40micron.com
+AD4- +ACU-7C5e614e5f028342b6b59c08dbff8e3e37+ACU-7Cf38a5ecd28134862b11bac1=
d56
+AD4- 3c806f+ACU-7C0+ACU-7C0+ACU-7C638384758666895965+ACU-7CUnknown+ACU-7CT=
WFpbGZsb3d
+AD4- 8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0+ACU-=
3
+AD4- D+ACU-7C3000+ACU-7C+ACU-7C+ACU-7C+ACY-sdata+AD0-W+ACU-2FWcAD4b9od+ACU=
-2BS0zIak+ACU-2Bv5hkjFG1Xcf
+AD4- 6p8q3xwmspUiI+ACU-3D+ACY-reserved+AD0-0

This patch provides a way to move a node to the correct tier.
We observed in test setups where DRAM and CXL are put under the same.
tier (memory+AF8-tier4).
By using this patch, we can move the CXL node away from the DRAM-linked (me=
mory+AF8-tier4)
and put it in the desired tier.

+AD4- +AD4APg-
+AD4- +AD4-
+AD4- +AD4- Not speaking for the group, just chiming in because i'd discuss=
ed it
+AD4- +AD4- with them.
+AD4- +AD4-
+AD4- +AD4- +ACI-Memory Type+ACI- is a bit nebulous.  Is a Micron Type-3 wi=
th performance X
+AD4- +AD4- and an SK Hynix Type-3 with performance Y a +ACI-Different type=
+ACI-, or are
+AD4- +AD4- they the +ACI-Same Type+ACI- given that they're both Type 3 bac=
ked by some form
+AD4- +AD4- of DDR?  Is socket placement of those devices relevant for dete=
rmining
+AD4- +AD4- +ACI-Type+ACI-?  Is whether they are behind a switch relevant f=
or determining
+AD4- +AD4- +ACI-Type+ACI-? +ACI-Type+ACI- is frustrating when everything w=
e're talking about
+AD4- +AD4- managing is +ACI-Type-3+ACI- with difference performance.
+AD4- +AD4-
+AD4- +AD4- A concrete example:
+AD4- +AD4- To the system, a Multi-Headed Single Logical Device (MH-SLD) lo=
oks
+AD4- +AD4- exactly the same as an standard SLD.  I may want to have some
+AD4- +AD4- combination of local memory expansion devices on the majority o=
f my
+AD4- +AD4- expansion slots, but reserve 1 slot on each socket for a connec=
tion to
+AD4- +AD4- the MH-SLD.   As of right now: There is no good way to differen=
tiate the
+AD4- +AD4- devices in terms of +ACI-Type+ACI- - and even if you had that, =
the tiering
+AD4- +AD4- system would still lump them together.
+AD4- +AD4-
+AD4- +AD4- Similarly, an initial run of switches may or may not allow enum=
eration
+AD4- +AD4- of devices behind it (depends on the configuration), so you may=
 end up
+AD4- +AD4- with a static numa node that +ACI-looks like+ACI- another SLD -=
 despite it being
+AD4- +AD4- some definition of +ACI-GFAM+ACI-.  Do number of hops matter in=
 determining
+AD4- +AD4- +ACI-Type+ACI-?
+AD4-
+AD4- In the original design, the memory devices of same memory type are
+AD4- managed by the same device driver, linked with system in same way
+AD4- (including switches), built with same media.  So, the performance is
+AD4- same too.  And, same as memory tiers, memory types are orthogonal to
+AD4- sockets.  Do you think the definition itself is clear enough?
+AD4-
+AD4- I admit +ACI-memory type+ACI- is a confusing name.  Do you have some =
better
+AD4- suggestion?
+AD4-
+AD4- +AD4- So I really don't think +ACI-Type+ACI- is useful for determinin=
g tier placement.
+AD4- +AD4-
+AD4- +AD4- As of right now, the system lumps DRAM nodes as one tier, and p=
retty
+AD4- +AD4- much everything else as +ACI-the other tier+ACI-. To me, this p=
atch set is an
+AD4- +AD4- initial pass meant to allow user-control over tier composition =
while
+AD4- +AD4- the internal mechanism is sussed out and the environment develo=
ps.
+AD4-
+AD4- The patchset to identify the performance of memory devices and put th=
em
+AD4- in proper +ACI-memory types+ACI- and memory tiers via HMAT has been m=
erged by
+AD4- v6.7-rc1.
+AD4-
+AD4-       07a8bdd4120c (memory tiering: add abstract distance calculation
+AD4- algorithms management, 2023-09-26)
+AD4-       d0376aac59a1 (acpi, hmat: refactor hmat+AF8-register+AF8-target=
+AF8-initiators(),
+AD4- 2023-09-26)
+AD4-       3718c02dbd4c (acpi, hmat: calculate abstract distance with HMAT=
, 2023-09-
+AD4- 26)
+AD4-       6bc2cfdf82d5 (dax, kmem: calculate abstract distance with gener=
al
+AD4- interface, 2023-09-26)
+AD4-
+AD4- +AD4- In general, a release valve that lets you redefine tiers is ver=
y welcome
+AD4- +AD4- for testing and validation of different setups while the indust=
ry evolves.
+AD4- +AD4-
+AD4- +AD4- Just my two cents.
+AD4-
+AD4- --
+AD4- Best Regards,
+AD4- Huang, Ying

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from mgamail.intel.com (mgamail.intel.com [192.55.52.120])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 7E1EA18059;
	Wed,  3 Jan 2024 08:31:46 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=none dis=none) header.from=intel.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=intel.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=intel.com header.i=@intel.com header.b="KZ3RxjMN"
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple;
  d=intel.com; i=@intel.com; q=dns/txt; s=Intel;
  t=1704270706; x=1735806706;
  h=from:to:cc:subject:in-reply-to:references:date:
   message-id:mime-version;
  bh=K2D+DOH/3k8UCY1rTsgGy6wghC2CdFVcWHWsDmKE3ec=;
  b=KZ3RxjMN9232lkF+LevQsNw5gbdXrH8fE7lmHMicTyjV9y0mUskoJ4ug
   AiHThL+2qYVlsMzbg7do5A6fkW8ZFOcctdZBHwE+oPrVz89sat9VmXndI
   NtVHBIAnFgk55wPq4YaSOzhVU/E8Dd82r1bEiOuCPAauvfyRUcPAb321F
   saezyA9rLFzLx4jScHpTzMNu6e7Ypix47qFDzNKJei6XHYD5rO2jB/Aua
   1fnlfmlSANOfbo0xyqOKZ2s2g7bqTCalgu0jKPxswzp6xljN5ON646TXO
   batwxC+E35aGvub4wOlxHFy2cey9JWeTPOnsBf9wy+ine014dOFoU9tYb
   A==;
X-IronPort-AV: E=McAfee;i="6600,9927,10941"; a="395854473"
X-IronPort-AV: E=Sophos;i="6.04,327,1695711600"; 
   d="scan'208";a="395854473"
Received: from orsmga007.jf.intel.com ([10.7.209.58])
  by fmsmga104.fm.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 03 Jan 2024 00:31:45 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=McAfee;i="6600,9927,10941"; a="773079904"
X-IronPort-AV: E=Sophos;i="6.04,327,1695711600"; 
   d="scan'208";a="773079904"
Received: from yhuang6-desk2.sh.intel.com (HELO yhuang6-desk2.ccr.corp.intel.com) ([10.238.208.55])
  by orsmga007-auth.jf.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 03 Jan 2024 00:31:41 -0800
From: "Huang, Ying" <ying.huang@intel.com>
To: Srinivasulu Thanneeru <sthanneeru@micron.com>
Cc: gregory.price <gregory.price@memverge.com>,  Srinivasulu Opensrc
 <sthanneeru.opensrc@micron.com>,  "linux-cxl@vger.kernel.org"
 <linux-cxl@vger.kernel.org>,  "linux-mm@kvack.org" <linux-mm@kvack.org>,
  "aneesh.kumar@linux.ibm.com" <aneesh.kumar@linux.ibm.com>,
  "dan.j.williams@intel.com" <dan.j.williams@intel.com>,  "mhocko@suse.com"
 <mhocko@suse.com>,  "tj@kernel.org" <tj@kernel.org>,
  "john@jagalactic.com" <john@jagalactic.com>,  Eishan Mirakhur
 <emirakhur@micron.com>,  "Vinicius Tavares Petrucci"
 <vtavarespetr@micron.com>,  Ravis OpenSrc <Ravis.OpenSrc@micron.com>,
  "Jonathan.Cameron@huawei.com" <Jonathan.Cameron@huawei.com>,
  "linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>,  Johannes
 Weiner <hannes@cmpxchg.org>,  Wei Xu <weixugc@google.com>
Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
In-Reply-To: <PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	(Srinivasulu Thanneeru's message of "Wed, 3 Jan 2024 07:56:42 +0000")
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
	<87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZXyQIJOim1+tE0Qr@memverge.com>
	<87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
Date: Wed, 03 Jan 2024 16:29:42 +0800
Message-ID: <87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com>
User-Agent: Gnus/5.13 (Gnus v5.13)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Type: text/plain; charset=ascii

Srinivasulu Thanneeru <sthanneeru@micron.com> writes:

> Micron Confidential
>
>
>
> Micron Confidential
>> -----Original Message-----
>> From: Huang, Ying <ying.huang@intel.com>
>> Sent: Wednesday, January 3, 2024 11:38 AM
>> To: Srinivasulu Thanneeru <sthanneeru@micron.com>
>> Cc: gregory.price <gregory.price@memverge.com>; Srinivasulu Opensrc
>> <sthanneeru.opensrc@micron.com>; linux-cxl@vger.kernel.org; linux-
>> mm@kvack.org; aneesh.kumar@linux.ibm.com; dan.j.williams@intel.com;
>> mhocko@suse.com; tj@kernel.org; john@jagalactic.com; Eishan Mirakhur
>> <emirakhur@micron.com>; Vinicius Tavares Petrucci
>> <vtavarespetr@micron.com>; Ravis OpenSrc <Ravis.OpenSrc@micron.com>;
>> Jonathan.Cameron@huawei.com; linux-kernel@vger.kernel.org; Johannes
>> Weiner <hannes@cmpxchg.org>; Wei Xu <weixugc@google.com>
>> Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory
>> tiers
>>
>> CAUTION: EXTERNAL EMAIL. Do not click links or open attachments unless
>> you recognize the sender and were expecting this message.
>>
>>
>> Srinivasulu Thanneeru <sthanneeru@micron.com> writes:
>>
>> > Micron Confidential
>> >
>> > Hi Huang, Ying,
>> >
>> > My apologies for wrong mail reply format, my mail client settings got
>> changed on my PC.
>> > Please find comments bellow inline.
>> >
>> > Regards,
>> > Srini
>> >
>> >
>> > Micron Confidential
>> >> -----Original Message-----
>> >> From: Huang, Ying <ying.huang@intel.com>
>> >> Sent: Monday, December 18, 2023 11:26 AM
>> >> To: gregory.price <gregory.price@memverge.com>
>> >> Cc: Srinivasulu Opensrc <sthanneeru.opensrc@micron.com>; linux-
>> >> cxl@vger.kernel.org; linux-mm@kvack.org; Srinivasulu Thanneeru
>> >> <sthanneeru@micron.com>; aneesh.kumar@linux.ibm.com;
>> >> dan.j.williams@intel.com; mhocko@suse.com; tj@kernel.org;
>> >> john@jagalactic.com; Eishan Mirakhur <emirakhur@micron.com>; Vinicius
>> >> Tavares Petrucci <vtavarespetr@micron.com>; Ravis OpenSrc
>> >> <Ravis.OpenSrc@micron.com>; Jonathan.Cameron@huawei.com; linux-
>> >> kernel@vger.kernel.org; Johannes Weiner <hannes@cmpxchg.org>; Wei Xu
>> >> <weixugc@google.com>
>> >> Subject: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory
>> tiers
>> >>
>> >> CAUTION: EXTERNAL EMAIL. Do not click links or open attachments unless
>> >> you recognize the sender and were expecting this message.
>> >>
>> >>
>> >> Gregory Price <gregory.price@memverge.com> writes:
>> >>
>> >> > On Fri, Dec 15, 2023 at 01:02:59PM +0800, Huang, Ying wrote:
>> >> >> <sthanneeru.opensrc@micron.com> writes:
>> >> >>
>> >> >> > =============
>> >> >> > Version Notes:
>> >> >> >
>> >> >> > V2 : Changed interface to memtier_override from adistance_offset.
>> >> >> > memtier_override was recommended by
>> >> >> > 1. John Groves <john@jagalactic.com>
>> >> >> > 2. Ravi Shankar <ravis.opensrc@micron.com>
>> >> >> > 3. Brice Goglin <Brice.Goglin@inria.fr>
>> >> >>
>> >> >> It appears that you ignored my comments for V1 as follows ...
>> >> >>
>> >> >>
>> >>
>> https://lore.k/
>> %2F&data=05%7C02%7Csthanneeru%40micron.com%7C3e5d38eb47be463c2
>> 95c08dc0c229d22%7Cf38a5ecd28134862b11bac1d563c806f%7C0%7C0%7C63
>> 8398590664228240%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMD
>> AiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C
>> &sdata=7fPxb1YYR2tZ0v2FB1vlXnMJFcI%2Fr9HT2%2BUD1MNUd%2FI%3D&re
>> served=0
>> >> ernel.org%2Flkml%2F87o7f62vur.fsf%40yhuang6-
>> >>
>> desk2.ccr.corp.intel.com%2F&data=05%7C02%7Csthanneeru%40micron.com
>> >>
>> %7C5e614e5f028342b6b59c08dbff8e3e37%7Cf38a5ecd28134862b11bac1d56
>> >>
>> 3c806f%7C0%7C0%7C638384758666895965%7CUnknown%7CTWFpbGZsb3d
>> >>
>> 8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3
>> >>
>> D%7C3000%7C%7C%7C&sdata=OpMkYCar%2Fv8uHb7AvXbmaNltnXeTvcNUTi
>> >> bLhwV12Fg%3D&reserved=0
>> >
>> > Thank you, Huang, Ying for pointing to this.
>> >
>> https://lpc.ev/
>> ents%2Fevent%2F16%2Fcontributions%2F1209%2Fattachments%2F1042%2F1
>> 995%2FLive%2520In%2520a%2520World%2520With%2520Multiple%2520Me
>> mory%2520Types.pdf&data=05%7C02%7Csthanneeru%40micron.com%7C3e
>> 5d38eb47be463c295c08dc0c229d22%7Cf38a5ecd28134862b11bac1d563c806
>> f%7C0%7C0%7C638398590664228240%7CUnknown%7CTWFpbGZsb3d8eyJW
>> IjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3
>> 000%7C%7C%7C&sdata=1fGraxff7%2F1hNaE0an0xEudSKSUvaF3HgClMkmdC7
>> n8%3D&reserved=0
>> >
>> > In the presentation above, the adistance_offsets are per memtype.
>> > We believe that adistance_offset per node is more suitable and flexible.
>> > since we can change it per node. If we keep adistance_offset per memtype,
>> > then we cannot change it for a specific node of a given memtype.
>> >
>> >> >>
>> >>
>> https://lore.k/
>> %2F&data=05%7C02%7Csthanneeru%40micron.com%7C3e5d38eb47be463c2
>> 95c08dc0c229d22%7Cf38a5ecd28134862b11bac1d563c806f%7C0%7C0%7C63
>> 8398590664228240%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMD
>> AiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C
>> &sdata=7fPxb1YYR2tZ0v2FB1vlXnMJFcI%2Fr9HT2%2BUD1MNUd%2FI%3D&re
>> served=0
>> >> ernel.org%2Flkml%2F87jzpt2ft5.fsf%40yhuang6-
>> >>
>> desk2.ccr.corp.intel.com%2F&data=05%7C02%7Csthanneeru%40micron.com
>> >>
>> %7C5e614e5f028342b6b59c08dbff8e3e37%7Cf38a5ecd28134862b11bac1d56
>> >>
>> 3c806f%7C0%7C0%7C638384758666895965%7CUnknown%7CTWFpbGZsb3d
>> >>
>> 8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3
>> >>
>> D%7C3000%7C%7C%7C&sdata=O0%2B6T%2FgU0TicCEYBac%2FAyjOLwAeouh
>> >> D%2BcMI%2BflOsI1M%3D&reserved=0
>> >
>> > Yes, memory_type would be grouping the related memories together as
>> single tier.
>> > We should also have a flexibility to move nodes between tiers, to address
>> the issues.
>> > described in use cases above.
>>
>> We don't pursue absolute flexibility.  We add necessary flexibility
>> only.  Why do you need this kind of flexibility?  Can you provide some
>> use cases where memory_type based "adistance_offset" doesn't work?
>
> - /sys/devices/virtual/memory_type/memory_type/ adistance_offset
> memory_type based "adistance_offset will provide a way to move all nodes of same memory_type (e.g. all cxl nodes)
> to different tier.

We will not put the CXL nodes with different performance metrics in one
memory_type.  If so, do you still need to move one of them?

> Whereas /sys/devices/system/node/node2/memtier_override provide a way migrate a node from one tier to another.
> Considering a case where we would like to move two cxl nodes into two different tiers in future.
> So, I thought it would be good to have flexibility at node level instead of at memory_type.

--
Best Regards,
Huang, Ying

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from NAM12-BN8-obe.outbound.protection.outlook.com (mail-bn8nam12on2059.outbound.protection.outlook.com [40.107.237.59])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 33A201803B;
	Wed,  3 Jan 2024 07:56:47 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=reject dis=none) header.from=micron.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=micron.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=micron.com header.i=@micron.com header.b="PZv2jw4m"
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=IYLrqqMKrFpewOIom5mD0C1FtMnTxFNn4h1qgA3BenRecI5/8u/yw0aS7QWkUdgjmYQFP9/RwIDb8+p/MsC1NqFNjDdQYObLLnIRnu/2o1L3YKchp4o0K9i5osCDsSMfo5jico0Ec8OMZadAxw6oBmzxUEJCTuhF3zXY2vBbAeMhopu2Dlj1yXrAcELI7OQZQO1NOuGOBry0ZPb1Zr1bXQYwJIku5XTxhwu6VWceiLHQ+5GTADXWAS3LJWCJKv9dYuF2f3t0y9aza4+RoQBVDkhsZ1IF+Iq141n/1vCUOtxjD14CMCLV73VdU8RacR/QTgAdAE1flSa0cjUZrUArLw==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-AntiSpam-MessageData-ChunkCount:X-MS-Exchange-AntiSpam-MessageData-0:X-MS-Exchange-AntiSpam-MessageData-1;
 bh=NHQ3eSUTIlrT/G6KA++VN+jeSQc0CVWXibdnxUPdOhk=;
 b=Np+/oFgt491l2hkRXoNtpYtnKpg003UOVcn7xLRAC9WGkIyyPYHi2K9kxegwiQAI3gpqipsoq1ZgaO0Z6IjVQ9bxhXF7mQb8ezdS/m8kqjg+rtoKRAhRpncxcWijcPm7sVwARtWwPywNzPvB6RdC/o+xECGtqeLxPHl3F0h3ZIFA3DLLBGtuWHsa2ChudDepI5Pgkps2SksM+jCSg3va7E3hmt/ktTyWTVZFXjZLALVnzzTiph2RHlyK5cBV6+Vp1z1ClPKA0ot7T40onWE37QOY/56qWbKTI0ARSX27B2f9BdO+p4s4EpC1eFh6biLDfA5gDXfE/ojzCLGyzEmJQA==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass
 smtp.mailfrom=micron.com; dmarc=pass action=none header.from=micron.com;
 dkim=pass header.d=micron.com; arc=none
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=micron.com;
 s=selector2;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=NHQ3eSUTIlrT/G6KA++VN+jeSQc0CVWXibdnxUPdOhk=;
 b=PZv2jw4mQ4z3MTYUJUvWgMgrZO/Ic+NFEX61CpIrf69ZDEcdjn3NnmeCe82ZF8QVPmeqc6e3DUGKEaINszmteMQtQrWdsrNCZF7I0a5xT6QC8sCfL+tQocWpKBQb2Q8MYOknoThKQHh3G1z+RQ3kfE9td2oQnQHAWtOFKBB+U5dsY3K2h4UVefn8BVTqMh42uAFhs/Lyn4UwhQtFOjy+Ffelq3uw+si58Qcdp0/8yb6prZ6NbyHLv7BjDd55G6GddZ+Xfy8DRlWWJIsaqCVsojclbfXLBImCs/wGHbCpT9UMirhUmvzkrq41WDyC2cfb7JF2dd8OaoyWA5on6dBTgg==
Received: from PH0PR08MB7955.namprd08.prod.outlook.com (2603:10b6:510:11a::17)
 by DM4PR08MB8247.namprd08.prod.outlook.com (2603:10b6:8:46::12) with
 Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.7159.11; Wed, 3 Jan
 2024 07:56:43 +0000
Received: from PH0PR08MB7955.namprd08.prod.outlook.com
 ([fe80::5049:9abf:ad65:9974]) by PH0PR08MB7955.namprd08.prod.outlook.com
 ([fe80::5049:9abf:ad65:9974%3]) with mapi id 15.20.7159.013; Wed, 3 Jan 2024
 07:56:42 +0000
From: Srinivasulu Thanneeru <sthanneeru@micron.com>
To: "Huang, Ying" <ying.huang@intel.com>
CC: gregory.price <gregory.price@memverge.com>, Srinivasulu Opensrc
	<sthanneeru.opensrc@micron.com>, "linux-cxl@vger.kernel.org"
	<linux-cxl@vger.kernel.org>, "linux-mm@kvack.org" <linux-mm@kvack.org>,
	"aneesh.kumar@linux.ibm.com" <aneesh.kumar@linux.ibm.com>,
	"dan.j.williams@intel.com" <dan.j.williams@intel.com>, "mhocko@suse.com"
	<mhocko@suse.com>, "tj@kernel.org" <tj@kernel.org>, "john@jagalactic.com"
	<john@jagalactic.com>, Eishan Mirakhur <emirakhur@micron.com>, Vinicius
 Tavares Petrucci <vtavarespetr@micron.com>, Ravis OpenSrc
	<Ravis.OpenSrc@micron.com>, "Jonathan.Cameron@huawei.com"
	<Jonathan.Cameron@huawei.com>, "linux-kernel@vger.kernel.org"
	<linux-kernel@vger.kernel.org>, Johannes Weiner <hannes@cmpxchg.org>, Wei Xu
	<weixugc@google.com>
Subject: RE: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
Thread-Topic: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
Thread-Index: AQHaLe1WCWEmLbBSRk2O5Sdey42WeLCpzLPHgADTuACAA/H6xIAZGhOAgAAO84SAABl24A==
Date: Wed, 3 Jan 2024 07:56:42 +0000
Message-ID: <PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
	<87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZXyQIJOim1+tE0Qr@memverge.com>
	<87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
In-Reply-To: <87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
msip_labels: MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_ActionId=1f688faa-4c3f-40e2-b45d-409ec7bacdb0;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_ContentBits=0;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_Enabled=true;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_Method=Standard;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_Name=Confidential;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_SetDate=2024-01-03T07:42:13Z;MSIP_Label_37874100-6000-43b6-a204-2d77792600b9_SiteId=f38a5ecd-2813-4862-b11b-ac1d563c806f;
authentication-results: dkim=none (message not signed)
 header.d=none;dmarc=none action=none header.from=micron.com;
x-ms-publictraffictype: Email
x-ms-traffictypediagnostic: PH0PR08MB7955:EE_|DM4PR08MB8247:EE_
x-ms-office365-filtering-correlation-id: 2536b92d-bd78-40de-297c-08dc0c318682
x-ld-processed: f38a5ecd-2813-4862-b11b-ac1d563c806f,ExtAddr
x-ms-exchange-senderadcheck: 1
x-ms-exchange-antispam-relay: 0
x-microsoft-antispam: BCL:0;
x-microsoft-antispam-message-info: 2BEQRxT0+7w7pTj/QhDKwowt76Ov9KEIdzWZcPQgucEzhN4p5NWLarr+J1fD6+xCXshq440GvCFJ9Q5gXfDF+l/l5/1EwzpxXZvESI0USHhJ19lK1D8HFFCEPEugenAOqpfnptVtZYJyX1FpeuQD7Qr0eE7ySjgpU6H1t6g/0BibpUwEVkRl8E7fggW6nilpV51NJgXwUaE2EO0CgnTUw4DUEKlVF/fX6Fpk75jJ9jRs9aTbMoNKrCozd7JoBf/k20bsuClZuONbCPWH66OfLP1lvXQDZ7xdFMC9QBoEEkZSdpW/JvBHIUZu85sj4aD6+7DrePKie9aGpmaX2XvXdC0xi0qIr4PsaPGeje2qsqUbEoiyqmBlja6p/puzKbo3df6QcrvDNWuKd4awouk4NRxrN/G8lFQQVX0+oEAzSj2CUxEBPczTqcd0TXzgmmX5BWX6wKCje66CjhUDUyb79pX8ZBPQm2EkJ21oGu2W+pOUtIDLUye2FLzIPM8Yax8fuxwNu5UXIP/I+QX/KPNacL5EzwA6MeGplqrt5bvcOkCkiaHckC3b7Gjp+svftOigz0uvAy/dEwUSW+6caEiKvq5y/TbAdjD2Xrz25tPX3Zi3xYDelUjFVeEvtdCku+AuSf7K+cBiPpRqtgoB8lF1yA==
x-forefront-antispam-report: CIP:255.255.255.255;CTRY:;LANG:en;SCL:1;SRV:;IPV:NLI;SFV:NSPM;H:PH0PR08MB7955.namprd08.prod.outlook.com;PTR:;CAT:NONE;SFS:(13230031)(376002)(396003)(346002)(39860400002)(366004)(136003)(230273577357003)(230922051799003)(230173577357003)(451199024)(64100799003)(186009)(1800799012)(83380400001)(26005)(6506007)(76116006)(5660300002)(54906003)(53546011)(7416002)(4326008)(52536014)(45080400002)(2906002)(7696005)(6916009)(122000001)(316002)(478600001)(8676002)(8936002)(66446008)(66476007)(66556008)(41300700001)(64756008)(66946007)(966005)(86362001)(33656002)(9686003)(38100700002)(71200400001)(38070700009)(55016003);DIR:OUT;SFP:1101;
x-ms-exchange-antispam-messagedata-chunkcount: 1
x-ms-exchange-antispam-messagedata-0: =?utf-7?B?YjM3MDFrbExYd2ZIejdYb0loZnBuejNnalNTS3ZFd0R3ZlZPQnJoeGZ1ejdQ?=
 =?utf-7?B?RDZhb2hnSTlOU0xTd1BmV0wzOEVDMTBZUCsta0s5MDJ3a1V4eTQrLUZSZzNo?=
 =?utf-7?B?cjdIQ1pFaWJiZlROblpTS1QyMTd4Rkt1akY1RGdKZ1cwVlJuRXM1YUxCa1FC?=
 =?utf-7?B?M3MzQ05MWWU2SElUYnhoTk9NVnNadUpuME8zQ2R0MzAyNVYrLXB3REF2Z2Q4?=
 =?utf-7?B?UFBYc1JaWnpiMFhoVmp4SUpsM2VHekFkQUtiS2VuTlBXTDF4WXNUdUxrUUta?=
 =?utf-7?B?WVdvMFdJT0x1dHlsMWcyUFp5dm00Vm5RUUR4bDRwOEZoTHdwSVRzLzE1V3pB?=
 =?utf-7?B?NnhnaVVSN2hEckFjSXoyZUhibkUySjVwRlp3RVFXQWJLL1BwZlNGNmxsbGQy?=
 =?utf-7?B?NXJUczh2a2tlT3p5Mjh4QW8xRkVPak5tM0s3RXIrLWk0Z1pBSXM0elE3bXRQ?=
 =?utf-7?B?SWF2a09KNHF3VVYvdEE3WW1GRnYxRlNOaVFjZHJaVkttWFhsbXB4TjgzNWRh?=
 =?utf-7?B?azBrMXJwZlZnRDVYRkNPUk9JR1p2b0t3WUxvRGdOLzVzLzlGOVdiS21UOEox?=
 =?utf-7?B?eVRET1hQZXY3aUp6VTlXZlpQendSemJwZjNhMmVjQ3h3UDVHcGxpYy96NVZz?=
 =?utf-7?B?ZE5BTjBxUG41Wk1OZ05KekQxRk5uRVpFUUtzWWxybFBRSDB5T3RCaWRGdVl6?=
 =?utf-7?B?WUtRZk9HeS9jaUZWOUZ2TVI3cEtRNFBUTXlTQmtYZGlLMlVEaGtzQ05FckNJ?=
 =?utf-7?B?WWJ1aHdJSUMzSVRrVldoL3YvQURZMUtXUXdWT0lvRjFvWG55L0x3VjNHbldV?=
 =?utf-7?B?OFRxdER3MDl3NG5HN0VqS3dsaW1rNmpYcmtzc0NOdXQ2M1JiVUZBbzdBVUZp?=
 =?utf-7?B?OTNqd3RTaHEyVDA5SXhSUE9KY3JRKy16NkY2cmpXcld3ZzV6TFZKcHJaSVZL?=
 =?utf-7?B?Q1UwVlk3Rmllbk5Kb2xWd2pIeHZpZzFoRUtucHZZRHFFS3VyUXp6bjRSTXdV?=
 =?utf-7?B?YnBLTG9zM25DRlpjNnBuTGxZMWhyREFpeEs5bkRrdzFZU3NrU3BTNFFKODlp?=
 =?utf-7?B?ckNiQmwrLVBCR3FrU2xVL0dKRW9xeVFJOU1KTTliTkpHdkc4VTE0VHN6Z3pR?=
 =?utf-7?B?eVhuNjhram5vSFd6UXdQRUgzV0xxc1I3S2xib0szalZTY3JmVnZ4RzZGbWk2?=
 =?utf-7?B?L2tPbjhvZVY0V2hZUUN6WklQQVR2V0FDZWtYTHQvOFB5ajhtYU5hSHhTcHZq?=
 =?utf-7?B?WE1OckYxZCstWjg2VnZ0SjM3R2pOKy14Qk9wQWdhUXhkTFdRbUY4U1pqS0Rs?=
 =?utf-7?B?Z05UbG8rLW41WDRrZ1I0bFg5VzdPc0dqZ0ZpWWl4ckg4WFZNUHRITXNGTTlm?=
 =?utf-7?B?Nmw3bkR6UVY1NkJwaWU3NGxYU29GZGcxZmxBWlZYelFkb2dJcnNyMmVvenhY?=
 =?utf-7?B?Qnpka3hQTVNiTTV5TWRYNWVuVmJGb2I2d2o1eHRHRmpjYWdUTWJxNzY4VmRL?=
 =?utf-7?B?aHljQmVtWmVscEo1ZnpzUHN1eTNBTURJdk5aanZaVVNJS24rLXU1MUlsMnc0?=
 =?utf-7?B?RG1Ibjk4SjdQbDVGbm9mcjUrLU5NN1ZobjJ5SzJJckt6azQ4Z05PY0VTd2t1?=
 =?utf-7?B?UW1TRUptTkExYUFTbEZRbjE2aTA0bnFDQWxZMkpnSi9QcnhMWXRtdU5kN2Fx?=
 =?utf-7?B?b1pSeEl2MDc0c2ZOd3RVeFBISGVodEZ0d2tib2ttRFlVYXlLVUVhcUxKcXNm?=
 =?utf-7?B?cnF1bU45ZmREKy13bm1qQ3UzN0MwRVY0WFpCSzBtVFJjU0tiRy9IUE5TR2FU?=
 =?utf-7?B?d2lDa2RKcjh5bDBwVGREWVNkMUJxUGJNd0NFMUs2Q2F5T2F0dkwxNmhNcW1E?=
 =?utf-7?B?QXV1UHZORFA1S1hEVk9NQ1UycnpwQzJSRDNVMWJWSVJIOW9LRk1xOGNxT1RD?=
 =?utf-7?B?eEd4TUd6UjR3MThuaGE1WXM3eG16RkpLQXF5b0xBakMwNE1EYnJKTzJEOFZ1?=
 =?utf-7?B?Nll2QVNiSGs1dHE4RkhvbnpiVEpLZDdSQU51UTFnZzgvR2Z0QVFmOUZxOGJw?=
 =?utf-7?B?Q25nMGIzdzJMN0J5ZWU5TGN1OU9sanBQTDRuS25jNjRzZVdqSDBnZTVMUmJO?=
 =?utf-7?B?dFpzOTY0eTU3Tk8rLUk1SHlORjd3ZkpDWEJuMWovU1U4S3hVYjE=?=
Content-Type: text/plain; charset="utf-7"
Content-Transfer-Encoding: quoted-printable
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
X-OriginatorOrg: micron.com
X-MS-Exchange-CrossTenant-AuthAs: Internal
X-MS-Exchange-CrossTenant-AuthSource: PH0PR08MB7955.namprd08.prod.outlook.com
X-MS-Exchange-CrossTenant-Network-Message-Id: 2536b92d-bd78-40de-297c-08dc0c318682
X-MS-Exchange-CrossTenant-originalarrivaltime: 03 Jan 2024 07:56:42.9273
 (UTC)
X-MS-Exchange-CrossTenant-fromentityheader: Hosted
X-MS-Exchange-CrossTenant-id: f38a5ecd-2813-4862-b11b-ac1d563c806f
X-MS-Exchange-CrossTenant-mailboxtype: HOSTED
X-MS-Exchange-CrossTenant-userprincipalname: 1wXj1hCEWf9kQR+InAa1+FXzkuhPVAxgdMqOkoxZsxY8gRHmA1kF0NL3maOT1nQ1PmnUFf1A4JKb07lgx/48Qg==
X-MS-Exchange-Transport-CrossTenantHeadersStamped: DM4PR08MB8247


Micron Confidential



Micron Confidential
+AD4- -----Original Message-----
+AD4- From: Huang, Ying +ADw-ying.huang+AEA-intel.com+AD4-
+AD4- Sent: Wednesday, January 3, 2024 11:38 AM
+AD4- To: Srinivasulu Thanneeru +ADw-sthanneeru+AEA-micron.com+AD4-
+AD4- Cc: gregory.price +ADw-gregory.price+AEA-memverge.com+AD4AOw- Sriniva=
sulu Opensrc
+AD4- +ADw-sthanneeru.opensrc+AEA-micron.com+AD4AOw- linux-cxl+AEA-vger.ker=
nel.org+ADs- linux-
+AD4- mm+AEA-kvack.org+ADs- aneesh.kumar+AEA-linux.ibm.com+ADs- dan.j.willi=
ams+AEA-intel.com+ADs-
+AD4- mhocko+AEA-suse.com+ADs- tj+AEA-kernel.org+ADs- john+AEA-jagalactic.c=
om+ADs- Eishan Mirakhur
+AD4- +ADw-emirakhur+AEA-micron.com+AD4AOw- Vinicius Tavares Petrucci
+AD4- +ADw-vtavarespetr+AEA-micron.com+AD4AOw- Ravis OpenSrc +ADw-Ravis.Ope=
nSrc+AEA-micron.com+AD4AOw-
+AD4- Jonathan.Cameron+AEA-huawei.com+ADs- linux-kernel+AEA-vger.kernel.org=
+ADs- Johannes
+AD4- Weiner +ADw-hannes+AEA-cmpxchg.org+AD4AOw- Wei Xu +ADw-weixugc+AEA-go=
ogle.com+AD4-
+AD4- Subject: Re: +AFs-EXT+AF0- Re: +AFs-RFC PATCH v2 0/2+AF0- Node migrat=
ion between memory
+AD4- tiers
+AD4-
+AD4- CAUTION: EXTERNAL EMAIL. Do not click links or open attachments unles=
s
+AD4- you recognize the sender and were expecting this message.
+AD4-
+AD4-
+AD4- Srinivasulu Thanneeru +ADw-sthanneeru+AEA-micron.com+AD4- writes:
+AD4-
+AD4- +AD4- Micron Confidential
+AD4- +AD4-
+AD4- +AD4- Hi Huang, Ying,
+AD4- +AD4-
+AD4- +AD4- My apologies for wrong mail reply format, my mail client settin=
gs got
+AD4- changed on my PC.
+AD4- +AD4- Please find comments bellow inline.
+AD4- +AD4-
+AD4- +AD4- Regards,
+AD4- +AD4- Srini
+AD4- +AD4-
+AD4- +AD4-
+AD4- +AD4- Micron Confidential
+AD4- +AD4APg- -----Original Message-----
+AD4- +AD4APg- From: Huang, Ying +ADw-ying.huang+AEA-intel.com+AD4-
+AD4- +AD4APg- Sent: Monday, December 18, 2023 11:26 AM
+AD4- +AD4APg- To: gregory.price +ADw-gregory.price+AEA-memverge.com+AD4-
+AD4- +AD4APg- Cc: Srinivasulu Opensrc +ADw-sthanneeru.opensrc+AEA-micron.c=
om+AD4AOw- linux-
+AD4- +AD4APg- cxl+AEA-vger.kernel.org+ADs- linux-mm+AEA-kvack.org+ADs- Sri=
nivasulu Thanneeru
+AD4- +AD4APg- +ADw-sthanneeru+AEA-micron.com+AD4AOw- aneesh.kumar+AEA-linu=
x.ibm.com+ADs-
+AD4- +AD4APg- dan.j.williams+AEA-intel.com+ADs- mhocko+AEA-suse.com+ADs- t=
j+AEA-kernel.org+ADs-
+AD4- +AD4APg- john+AEA-jagalactic.com+ADs- Eishan Mirakhur +ADw-emirakhur+=
AEA-micron.com+AD4AOw- Vinicius
+AD4- +AD4APg- Tavares Petrucci +ADw-vtavarespetr+AEA-micron.com+AD4AOw- Ra=
vis OpenSrc
+AD4- +AD4APg- +ADw-Ravis.OpenSrc+AEA-micron.com+AD4AOw- Jonathan.Cameron+A=
EA-huawei.com+ADs- linux-
+AD4- +AD4APg- kernel+AEA-vger.kernel.org+ADs- Johannes Weiner +ADw-hannes+=
AEA-cmpxchg.org+AD4AOw- Wei Xu
+AD4- +AD4APg- +ADw-weixugc+AEA-google.com+AD4-
+AD4- +AD4APg- Subject: +AFs-EXT+AF0- Re: +AFs-RFC PATCH v2 0/2+AF0- Node m=
igration between memory
+AD4- tiers
+AD4- +AD4APg-
+AD4- +AD4APg- CAUTION: EXTERNAL EMAIL. Do not click links or open attachme=
nts unless
+AD4- +AD4APg- you recognize the sender and were expecting this message.
+AD4- +AD4APg-
+AD4- +AD4APg-
+AD4- +AD4APg- Gregory Price +ADw-gregory.price+AEA-memverge.com+AD4- write=
s:
+AD4- +AD4APg-
+AD4- +AD4APg- +AD4- On Fri, Dec 15, 2023 at 01:02:59PM +-0800, Huang, Ying=
 wrote:
+AD4- +AD4APg- +AD4APg- +ADw-sthanneeru.opensrc+AEA-micron.com+AD4- writes:
+AD4- +AD4APg- +AD4APg-
+AD4- +AD4APg- +AD4APg- +AD4- +AD0APQA9AD0APQA9AD0APQA9AD0APQA9AD0-
+AD4- +AD4APg- +AD4APg- +AD4- Version Notes:
+AD4- +AD4APg- +AD4APg- +AD4-
+AD4- +AD4APg- +AD4APg- +AD4- V2 : Changed interface to memtier+AF8-overrid=
e from adistance+AF8-offset.
+AD4- +AD4APg- +AD4APg- +AD4- memtier+AF8-override was recommended by
+AD4- +AD4APg- +AD4APg- +AD4- 1. John Groves +ADw-john+AEA-jagalactic.com+A=
D4-
+AD4- +AD4APg- +AD4APg- +AD4- 2. Ravi Shankar +ADw-ravis.opensrc+AEA-micron=
.com+AD4-
+AD4- +AD4APg- +AD4APg- +AD4- 3. Brice Goglin +ADw-Brice.Goglin+AEA-inria.f=
r+AD4-
+AD4- +AD4APg- +AD4APg-
+AD4- +AD4APg- +AD4APg- It appears that you ignored my comments for V1 as f=
ollows ...
+AD4- +AD4APg- +AD4APg-
+AD4- +AD4APg- +AD4APg-
+AD4- +AD4APg-
+AD4- https://lore.k/
+AD4- +ACU-2F+ACY-data+AD0-05+ACU-7C02+ACU-7Csthanneeru+ACU-40micron.com+AC=
U-7C3e5d38eb47be463c2
+AD4- 95c08dc0c229d22+ACU-7Cf38a5ecd28134862b11bac1d563c806f+ACU-7C0+ACU-7C=
0+ACU-7C63
+AD4- 8398590664228240+ACU-7CUnknown+ACU-7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMD
+AD4- AiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0+ACU-3D+ACU-7C3000+ACU-7=
C+ACU-7C+ACU-7C
+AD4- +ACY-sdata+AD0-7fPxb1YYR2tZ0v2FB1vlXnMJFcI+ACU-2Fr9HT2+ACU-2BUD1MNUd+=
ACU-2FI+ACU-3D+ACY-re
+AD4- served+AD0-0
+AD4- +AD4APg- ernel.org+ACU-2Flkml+ACU-2F87o7f62vur.fsf+ACU-40yhuang6-
+AD4- +AD4APg-
+AD4- desk2.ccr.corp.intel.com+ACU-2F+ACY-data+AD0-05+ACU-7C02+ACU-7Csthann=
eeru+ACU-40micron.com
+AD4- +AD4APg-
+AD4- +ACU-7C5e614e5f028342b6b59c08dbff8e3e37+ACU-7Cf38a5ecd28134862b11bac1=
d56
+AD4- +AD4APg-
+AD4- 3c806f+ACU-7C0+ACU-7C0+ACU-7C638384758666895965+ACU-7CUnknown+ACU-7CT=
WFpbGZsb3d
+AD4- +AD4APg-
+AD4- 8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0+ACU-=
3
+AD4- +AD4APg-
+AD4- D+ACU-7C3000+ACU-7C+ACU-7C+ACU-7C+ACY-sdata+AD0-OpMkYCar+ACU-2Fv8uHb7=
AvXbmaNltnXeTvcNUTi
+AD4- +AD4APg- bLhwV12Fg+ACU-3D+ACY-reserved+AD0-0
+AD4- +AD4-
+AD4- +AD4- Thank you, Huang, Ying for pointing to this.
+AD4- +AD4-
+AD4- https://lpc.ev/
+AD4- ents+ACU-2Fevent+ACU-2F16+ACU-2Fcontributions+ACU-2F1209+ACU-2Fattach=
ments+ACU-2F1042+ACU-2F1
+AD4- 995+ACU-2FLive+ACU-2520In+ACU-2520a+ACU-2520World+ACU-2520With+ACU-25=
20Multiple+ACU-2520Me
+AD4- mory+ACU-2520Types.pdf+ACY-data+AD0-05+ACU-7C02+ACU-7Csthanneeru+ACU-=
40micron.com+ACU-7C3e
+AD4- 5d38eb47be463c295c08dc0c229d22+ACU-7Cf38a5ecd28134862b11bac1d563c806
+AD4- f+ACU-7C0+ACU-7C0+ACU-7C638398590664228240+ACU-7CUnknown+ACU-7CTWFpbG=
Zsb3d8eyJW
+AD4- IjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0+ACU-3D+AC=
U-7C3
+AD4- 000+ACU-7C+ACU-7C+ACU-7C+ACY-sdata+AD0-1fGraxff7+ACU-2F1hNaE0an0xEudS=
KSUvaF3HgClMkmdC7
+AD4- n8+ACU-3D+ACY-reserved+AD0-0
+AD4- +AD4-
+AD4- +AD4- In the presentation above, the adistance+AF8-offsets are per me=
mtype.
+AD4- +AD4- We believe that adistance+AF8-offset per node is more suitable =
and flexible.
+AD4- +AD4- since we can change it per node. If we keep adistance+AF8-offse=
t per memtype,
+AD4- +AD4- then we cannot change it for a specific node of a given memtype=
.
+AD4- +AD4-
+AD4- +AD4APg- +AD4APg-
+AD4- +AD4APg-
+AD4- https://lore.k/
+AD4- +ACU-2F+ACY-data+AD0-05+ACU-7C02+ACU-7Csthanneeru+ACU-40micron.com+AC=
U-7C3e5d38eb47be463c2
+AD4- 95c08dc0c229d22+ACU-7Cf38a5ecd28134862b11bac1d563c806f+ACU-7C0+ACU-7C=
0+ACU-7C63
+AD4- 8398590664228240+ACU-7CUnknown+ACU-7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMD
+AD4- AiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0+ACU-3D+ACU-7C3000+ACU-7=
C+ACU-7C+ACU-7C
+AD4- +ACY-sdata+AD0-7fPxb1YYR2tZ0v2FB1vlXnMJFcI+ACU-2Fr9HT2+ACU-2BUD1MNUd+=
ACU-2FI+ACU-3D+ACY-re
+AD4- served+AD0-0
+AD4- +AD4APg- ernel.org+ACU-2Flkml+ACU-2F87jzpt2ft5.fsf+ACU-40yhuang6-
+AD4- +AD4APg-
+AD4- desk2.ccr.corp.intel.com+ACU-2F+ACY-data+AD0-05+ACU-7C02+ACU-7Csthann=
eeru+ACU-40micron.com
+AD4- +AD4APg-
+AD4- +ACU-7C5e614e5f028342b6b59c08dbff8e3e37+ACU-7Cf38a5ecd28134862b11bac1=
d56
+AD4- +AD4APg-
+AD4- 3c806f+ACU-7C0+ACU-7C0+ACU-7C638384758666895965+ACU-7CUnknown+ACU-7CT=
WFpbGZsb3d
+AD4- +AD4APg-
+AD4- 8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0+ACU-=
3
+AD4- +AD4APg-
+AD4- D+ACU-7C3000+ACU-7C+ACU-7C+ACU-7C+ACY-sdata+AD0-O0+ACU-2B6T+ACU-2FgU0=
TicCEYBac+ACU-2FAyjOLwAeouh
+AD4- +AD4APg- D+ACU-2BcMI+ACU-2BflOsI1M+ACU-3D+ACY-reserved+AD0-0
+AD4- +AD4-
+AD4- +AD4- Yes, memory+AF8-type would be grouping the related memories tog=
ether as
+AD4- single tier.
+AD4- +AD4- We should also have a flexibility to move nodes between tiers, =
to address
+AD4- the issues.
+AD4- +AD4- described in use cases above.
+AD4-
+AD4- We don't pursue absolute flexibility.  We add necessary flexibility
+AD4- only.  Why do you need this kind of flexibility?  Can you provide som=
e
+AD4- use cases where memory+AF8-type based +ACI-adistance+AF8-offset+ACI- =
doesn't work?

- /sys/devices/virtual/memory+AF8-type/memory+AF8-type/ adistance+AF8-offse=
t
memory+AF8-type based +ACI-adistance+AF8-offset will provide a way to move =
all nodes of same memory+AF8-type (e.g. all cxl nodes)
to different tier.

Whereas /sys/devices/system/node/node2/memtier+AF8-override provide a way m=
igrate a node from one tier to another.
Considering a case where we would like to move two cxl nodes into two diffe=
rent tiers in future.
So, I thought it would be good to have flexibility at node level instead of=
 at memory+AF8-type.

+AD4-
+AD4- --
+AD4- Best Regards,
+AD4- Huang, Ying

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from mgamail.intel.com (mgamail.intel.com [192.55.52.115])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 0E5601E52E;
	Thu,  4 Jan 2024 06:07:03 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=none dis=none) header.from=intel.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=intel.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=intel.com header.i=@intel.com header.b="SCoogXs2"
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple;
  d=intel.com; i=@intel.com; q=dns/txt; s=Intel;
  t=1704348424; x=1735884424;
  h=from:to:cc:subject:in-reply-to:references:date:
   message-id:mime-version;
  bh=uPiewepm8PfvEB9N3GZvZfx/+4uX3nbmL/Wb6i5OHqg=;
  b=SCoogXs2Vo9x5blnb3CNA0KzkIZ8HZBf191BTCO7bTA7ZOasKHHgUd+U
   YsJu8KdoxgVKIy/I2FrhQGekaQw1oub9rseKvZgQxbUMuXdfgZN77jORn
   XU+KwD0RjSTVw7VGLs46I5u8eprJFreY8U0SiJXuB3hZzsftBHPz9zINT
   PbgUm2gcR2xYnEkNJUAMBKilEUuM5+73fj1EYOsPRjCIShrkTdf/QTc3q
   lFS4N1WZ5TvLzuum5s88Qpa5mdoBvqeOuhO9kYSg5+dxZ8/hJr7Hh/xHV
   WVCo8R/4QbeUEMfNzyt49uMJfScRsYNRDSZHw2ytdg5W/g7kR98fPKJfU
   A==;
X-IronPort-AV: E=McAfee;i="6600,9927,10942"; a="396855975"
X-IronPort-AV: E=Sophos;i="6.04,329,1695711600"; 
   d="scan'208";a="396855975"
Received: from fmviesa002.fm.intel.com ([10.60.135.142])
  by fmsmga103.fm.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 03 Jan 2024 22:07:03 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=Sophos;i="6.04,329,1695711600"; 
   d="scan'208";a="14741076"
Received: from yhuang6-desk2.sh.intel.com (HELO yhuang6-desk2.ccr.corp.intel.com) ([10.238.208.55])
  by fmviesa002-auth.fm.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 03 Jan 2024 22:06:59 -0800
From: "Huang, Ying" <ying.huang@intel.com>
To: Srinivasulu Thanneeru <sthanneeru@micron.com>
Cc: gregory.price <gregory.price@memverge.com>,  Srinivasulu Opensrc
 <sthanneeru.opensrc@micron.com>,  "linux-cxl@vger.kernel.org"
 <linux-cxl@vger.kernel.org>,  "linux-mm@kvack.org" <linux-mm@kvack.org>,
  "aneesh.kumar@linux.ibm.com" <aneesh.kumar@linux.ibm.com>,
  "dan.j.williams@intel.com" <dan.j.williams@intel.com>,  "mhocko@suse.com"
 <mhocko@suse.com>,  "tj@kernel.org" <tj@kernel.org>,
  "john@jagalactic.com" <john@jagalactic.com>,  Eishan Mirakhur
 <emirakhur@micron.com>,  "Vinicius Tavares Petrucci"
 <vtavarespetr@micron.com>,  Ravis OpenSrc <Ravis.OpenSrc@micron.com>,
  "Jonathan.Cameron@huawei.com" <Jonathan.Cameron@huawei.com>,
  "linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>,  Johannes
 Weiner <hannes@cmpxchg.org>,  Wei Xu <weixugc@google.com>
Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
In-Reply-To: <PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	(Srinivasulu Thanneeru's message of "Wed, 3 Jan 2024 08:47:57 +0000")
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
	<87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZXyQIJOim1+tE0Qr@memverge.com>
	<87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
Date: Thu, 04 Jan 2024 14:05:01 +0800
Message-ID: <87wmspbpma.fsf@yhuang6-desk2.ccr.corp.intel.com>
User-Agent: Gnus/5.13 (Gnus v5.13)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Type: text/plain; charset=ascii

Srinivasulu Thanneeru <sthanneeru@micron.com> writes:

>> -----Original Message-----
>> From: Huang, Ying <ying.huang@intel.com>
>> Sent: Wednesday, January 3, 2024 2:00 PM
>> To: Srinivasulu Thanneeru <sthanneeru@micron.com>
>> Cc: gregory.price <gregory.price@memverge.com>; Srinivasulu Opensrc
>> <sthanneeru.opensrc@micron.com>; linux-cxl@vger.kernel.org; linux-
>> mm@kvack.org; aneesh.kumar@linux.ibm.com; dan.j.williams@intel.com;
>> mhocko@suse.com; tj@kernel.org; john@jagalactic.com; Eishan Mirakhur
>> <emirakhur@micron.com>; Vinicius Tavares Petrucci
>> <vtavarespetr@micron.com>; Ravis OpenSrc <Ravis.OpenSrc@micron.com>;
>> Jonathan.Cameron@huawei.com; linux-kernel@vger.kernel.org; Johannes
>> Weiner <hannes@cmpxchg.org>; Wei Xu <weixugc@google.com>
>> Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory
>> tiers
>>
>> CAUTION: EXTERNAL EMAIL. Do not click links or open attachments unless
>> you recognize the sender and were expecting this message.
>>
>>
>> Srinivasulu Thanneeru <sthanneeru@micron.com> writes:
>>
>> > Micron Confidential
>> >
>> >
>> >
>> > Micron Confidential
>> >> -----Original Message-----
>> >> From: Huang, Ying <ying.huang@intel.com>
>> >> Sent: Wednesday, January 3, 2024 11:38 AM
>> >> To: Srinivasulu Thanneeru <sthanneeru@micron.com>
>> >> Cc: gregory.price <gregory.price@memverge.com>; Srinivasulu Opensrc
>> >> <sthanneeru.opensrc@micron.com>; linux-cxl@vger.kernel.org; linux-
>> >> mm@kvack.org; aneesh.kumar@linux.ibm.com;
>> dan.j.williams@intel.com;
>> >> mhocko@suse.com; tj@kernel.org; john@jagalactic.com; Eishan Mirakhur
>> >> <emirakhur@micron.com>; Vinicius Tavares Petrucci
>> >> <vtavarespetr@micron.com>; Ravis OpenSrc
>> <Ravis.OpenSrc@micron.com>;
>> >> Jonathan.Cameron@huawei.com; linux-kernel@vger.kernel.org; Johannes
>> >> Weiner <hannes@cmpxchg.org>; Wei Xu <weixugc@google.com>
>> >> Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between
>> memory
>> >> tiers
>> >>
>> >> CAUTION: EXTERNAL EMAIL. Do not click links or open attachments unless
>> >> you recognize the sender and were expecting this message.
>> >>
>> >>
>> >> Srinivasulu Thanneeru <sthanneeru@micron.com> writes:
>> >>
>> >> > Micron Confidential
>> >> >
>> >> > Hi Huang, Ying,
>> >> >
>> >> > My apologies for wrong mail reply format, my mail client settings got
>> >> changed on my PC.
>> >> > Please find comments bellow inline.
>> >> >
>> >> > Regards,
>> >> > Srini
>> >> >
>> >> >
>> >> > Micron Confidential
>> >> >> -----Original Message-----
>> >> >> From: Huang, Ying <ying.huang@intel.com>
>> >> >> Sent: Monday, December 18, 2023 11:26 AM
>> >> >> To: gregory.price <gregory.price@memverge.com>
>> >> >> Cc: Srinivasulu Opensrc <sthanneeru.opensrc@micron.com>; linux-
>> >> >> cxl@vger.kernel.org; linux-mm@kvack.org; Srinivasulu Thanneeru
>> >> >> <sthanneeru@micron.com>; aneesh.kumar@linux.ibm.com;
>> >> >> dan.j.williams@intel.com; mhocko@suse.com; tj@kernel.org;
>> >> >> john@jagalactic.com; Eishan Mirakhur <emirakhur@micron.com>;
>> Vinicius
>> >> >> Tavares Petrucci <vtavarespetr@micron.com>; Ravis OpenSrc
>> >> >> <Ravis.OpenSrc@micron.com>; Jonathan.Cameron@huawei.com;
>> linux-
>> >> >> kernel@vger.kernel.org; Johannes Weiner <hannes@cmpxchg.org>; Wei
>> Xu
>> >> >> <weixugc@google.com>
>> >> >> Subject: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory
>> >> tiers
>> >> >>
>> >> >> CAUTION: EXTERNAL EMAIL. Do not click links or open attachments
>> unless
>> >> >> you recognize the sender and were expecting this message.
>> >> >>
>> >> >>
>> >> >> Gregory Price <gregory.price@memverge.com> writes:
>> >> >>
>> >> >> > On Fri, Dec 15, 2023 at 01:02:59PM +0800, Huang, Ying wrote:
>> >> >> >> <sthanneeru.opensrc@micron.com> writes:
>> >> >> >>
>> >> >> >> > =============
>> >> >> >> > Version Notes:
>> >> >> >> >
>> >> >> >> > V2 : Changed interface to memtier_override from adistance_offset.
>> >> >> >> > memtier_override was recommended by
>> >> >> >> > 1. John Groves <john@jagalactic.com>
>> >> >> >> > 2. Ravi Shankar <ravis.opensrc@micron.com>
>> >> >> >> > 3. Brice Goglin <Brice.Goglin@inria.fr>
>> >> >> >>
>> >> >> >> It appears that you ignored my comments for V1 as follows ...
>> >> >> >>
>> >> >> >>
>> >> >>
>> >>
>> https://lore.k/
>> %2F&data=05%7C02%7Csthanneeru%40micron.com%7Ce9e04d25ea7540100
>> cf308dc0c366eb1%7Cf38a5ecd28134862b11bac1d563c806f%7C0%7C0%7C63
>> 8398675187014390%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMD
>> AiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C
>> &sdata=k6J1wxcuHTwR9eoD9Yz137bkn6wt1L9zpf5YaOjoIqA%3D&reserved=0
>> >>
>> %2F&data=05%7C02%7Csthanneeru%40micron.com%7C3e5d38eb47be463c2
>> >>
>> 95c08dc0c229d22%7Cf38a5ecd28134862b11bac1d563c806f%7C0%7C0%7C63
>> >>
>> 8398590664228240%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMD
>> >>
>> AiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C
>> >>
>> &sdata=7fPxb1YYR2tZ0v2FB1vlXnMJFcI%2Fr9HT2%2BUD1MNUd%2FI%3D&re
>> >> served=0
>> >> >> ernel.org%2Flkml%2F87o7f62vur.fsf%40yhuang6-
>> >> >>
>> >>
>> desk2.ccr.corp.intel.com%2F&data=05%7C02%7Csthanneeru%40micron.com
>> >> >>
>> >>
>> %7C5e614e5f028342b6b59c08dbff8e3e37%7Cf38a5ecd28134862b11bac1d56
>> >> >>
>> >>
>> 3c806f%7C0%7C0%7C638384758666895965%7CUnknown%7CTWFpbGZsb3d
>> >> >>
>> >>
>> 8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3
>> >> >>
>> >>
>> D%7C3000%7C%7C%7C&sdata=OpMkYCar%2Fv8uHb7AvXbmaNltnXeTvcNUTi
>> >> >> bLhwV12Fg%3D&reserved=0
>> >> >
>> >> > Thank you, Huang, Ying for pointing to this.
>> >> >
>> >>
>> https://lpc.ev/
>> %2F&data=05%7C02%7Csthanneeru%40micron.com%7Ce9e04d25ea7540100
>> cf308dc0c366eb1%7Cf38a5ecd28134862b11bac1d563c806f%7C0%7C0%7C63
>> 8398675187014390%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMD
>> AiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C
>> &sdata=%2F0AW8RYpTIa7%2FiScnkzmmTeAE9TYqjsuWWjTuxBPptk%3D&rese
>> rved=0
>> >>
>> ents%2Fevent%2F16%2Fcontributions%2F1209%2Fattachments%2F1042%2F1
>> >>
>> 995%2FLive%2520In%2520a%2520World%2520With%2520Multiple%2520Me
>> >>
>> mory%2520Types.pdf&data=05%7C02%7Csthanneeru%40micron.com%7C3e
>> >>
>> 5d38eb47be463c295c08dc0c229d22%7Cf38a5ecd28134862b11bac1d563c806
>> >>
>> f%7C0%7C0%7C638398590664228240%7CUnknown%7CTWFpbGZsb3d8eyJW
>> >>
>> IjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3
>> >>
>> 000%7C%7C%7C&sdata=1fGraxff7%2F1hNaE0an0xEudSKSUvaF3HgClMkmdC7
>> >> n8%3D&reserved=0
>> >> >
>> >> > In the presentation above, the adistance_offsets are per memtype.
>> >> > We believe that adistance_offset per node is more suitable and flexible.
>> >> > since we can change it per node. If we keep adistance_offset per
>> memtype,
>> >> > then we cannot change it for a specific node of a given memtype.
>> >> >
>> >> >> >>
>> >> >>
>> >>
>> https://lore.k/
>> %2F&data=05%7C02%7Csthanneeru%40micron.com%7Ce9e04d25ea7540100
>> cf308dc0c366eb1%7Cf38a5ecd28134862b11bac1d563c806f%7C0%7C0%7C63
>> 8398675187014390%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMD
>> AiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C
>> &sdata=k6J1wxcuHTwR9eoD9Yz137bkn6wt1L9zpf5YaOjoIqA%3D&reserved=0
>> >>
>> %2F&data=05%7C02%7Csthanneeru%40micron.com%7C3e5d38eb47be463c2
>> >>
>> 95c08dc0c229d22%7Cf38a5ecd28134862b11bac1d563c806f%7C0%7C0%7C63
>> >>
>> 8398590664228240%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMD
>> >>
>> AiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C
>> >>
>> &sdata=7fPxb1YYR2tZ0v2FB1vlXnMJFcI%2Fr9HT2%2BUD1MNUd%2FI%3D&re
>> >> served=0
>> >> >> ernel.org%2Flkml%2F87jzpt2ft5.fsf%40yhuang6-
>> >> >>
>> >>
>> desk2.ccr.corp.intel.com%2F&data=05%7C02%7Csthanneeru%40micron.com
>> >> >>
>> >>
>> %7C5e614e5f028342b6b59c08dbff8e3e37%7Cf38a5ecd28134862b11bac1d56
>> >> >>
>> >>
>> 3c806f%7C0%7C0%7C638384758666895965%7CUnknown%7CTWFpbGZsb3d
>> >> >>
>> >>
>> 8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3
>> >> >>
>> >>
>> D%7C3000%7C%7C%7C&sdata=O0%2B6T%2FgU0TicCEYBac%2FAyjOLwAeouh
>> >> >> D%2BcMI%2BflOsI1M%3D&reserved=0
>> >> >
>> >> > Yes, memory_type would be grouping the related memories together as
>> >> single tier.
>> >> > We should also have a flexibility to move nodes between tiers, to
>> address
>> >> the issues.
>> >> > described in use cases above.
>> >>
>> >> We don't pursue absolute flexibility.  We add necessary flexibility
>> >> only.  Why do you need this kind of flexibility?  Can you provide some
>> >> use cases where memory_type based "adistance_offset" doesn't work?
>> >
>> > - /sys/devices/virtual/memory_type/memory_type/ adistance_offset
>> > memory_type based "adistance_offset will provide a way to move all nodes
>> of same memory_type (e.g. all cxl nodes)
>> > to different tier.
>>
>> We will not put the CXL nodes with different performance metrics in one
>> memory_type.  If so, do you still need to move one of them?
>
> From  https://lpc.events/event/16/contributions/1209/attachments/1042/1995/Live%20In%20a%20World%20With%20Multiple%20Memory%20Types.pdf
> abstract_distance_offset: override by users to deal with firmware issue.
>
> say firmware can configure the cxl node into wrong tiers, similar to
> that it may also configure all cxl nodes into single memtype, hence
> all these nodes can fall into a single wrong tier.
> In this case, per node adistance_offset would be good to have ?

I think that it's better to fix the error firmware if possible.  And
these are only theoretical, not practical issues.  Do you have some
practical issues?

I understand that users may want to move nodes between memory tiers for
different policy choices.  For that, memory_type based adistance_offset
should be good.

> --
> Srini
>> > Whereas /sys/devices/system/node/node2/memtier_override provide a
>> way migrate a node from one tier to another.
>> > Considering a case where we would like to move two cxl nodes into two
>> different tiers in future.
>> > So, I thought it would be good to have flexibility at node level instead of at
>> memory_type.

--
Best Regards,
Huang, Ying

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from NAM11-DM6-obe.outbound.protection.outlook.com (mail-dm6nam11on2057.outbound.protection.outlook.com [40.107.223.57])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id E87AD1804D;
	Wed,  3 Jan 2024 08:48:02 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=reject dis=none) header.from=micron.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=micron.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=micron.com header.i=@micron.com header.b="FVRaWZdd"
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=HJK9T3iqDr4KvjMvCq74g719+ulMV670tyNryyyV1aJluBeaqFAmgiPsg42xXdfHQY58LExu7IkF/44iAAopJ/yhT4wQ+2/TUOMfF/7u1pgOkeSFe72ud21jwsfF0OZoJr/58bx2CAcW7nBNaqXs8ID9Z26XDsMn32lms7yn8W9tfHkUSvqDVBMw+pgJC94NN8xbF/HA9gqonRt7z+ROMPuxSpdUx9cw4qJn09kWyHKaw0g2NjTUOeT8ljteAbW4Uym5koNAqOkyKUjHntjy7zTDf8a7bY4xBB1UumKm5FgWk64c78TV7Z8WygM9CtXYMt8YI9Xl6qrJRjqX62Nt8A==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-AntiSpam-MessageData-ChunkCount:X-MS-Exchange-AntiSpam-MessageData-0:X-MS-Exchange-AntiSpam-MessageData-1;
 bh=WEsXh66kM8P58ua7Lkwa03E9wD/Yvwhy5j+i02EIsPw=;
 b=EA4QB3edw10nD4tDjNjR/7rtJqTQp+QbRJvLLlVRefUw89ZIu7AlepaAKbYSo263oihZxT7j3kVUWFLQ+kdals/Km14n7DPtorCAEZ96oJiseeaiWQD5s1zaimt7m21k4wdWpO6Fbo05L+BMj4EW/FdoR+I0OyrniJLCnI5M9iOo09mYvNf+wTl/pfS0eWdFpl1bp4+xAoWp8pFWscEb1REYqXa0QUdeZu2La1tIse84eh80g4/qel0JWMCm3KYmsjmWanC6p4v7rBb2TVxh1EcTEdIME/6nnptCDnierOOKJ6stx+3lkZzXovSORQhwkKyYZQkz4fDEcT4K7qMuOg==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass
 smtp.mailfrom=micron.com; dmarc=pass action=none header.from=micron.com;
 dkim=pass header.d=micron.com; arc=none
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=micron.com;
 s=selector2;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=WEsXh66kM8P58ua7Lkwa03E9wD/Yvwhy5j+i02EIsPw=;
 b=FVRaWZddT9R/tpJ9GOcRTWsrl7/IGe2EbO/IHVxLe97fNHxTITCUnSml8E2Kw6vNASfEgXfEFNrHhI/WvVwWyDxDb1bv574Lag1yO7oRYgfmKe4xzXQuJ72J40D3f8ZuFw+mhqqfVgMPDa+zBE9dGtn3P1dM5aTfAKLQmVpScshaa4X3012NFkG0V1eUGmzTW+qOIjfcqogOpsN1j2B9ZwnQzpwaNGSstLlWXLeksZKnALb1/3QjuAZuBf+zWBwhALVehVxqxqOkVSdQFZZKaa1CmBFLY9nmt24HFz/HtqT6DbrPjAxYlwNbWabmIyKc5FWbyisKqe9LDi2sbBEidg==
Received: from PH0PR08MB7955.namprd08.prod.outlook.com (2603:10b6:510:11a::17)
 by SA1PR08MB7037.namprd08.prod.outlook.com (2603:10b6:806:1ab::6) with
 Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.7159.13; Wed, 3 Jan
 2024 08:47:58 +0000
Received: from PH0PR08MB7955.namprd08.prod.outlook.com
 ([fe80::5049:9abf:ad65:9974]) by PH0PR08MB7955.namprd08.prod.outlook.com
 ([fe80::5049:9abf:ad65:9974%3]) with mapi id 15.20.7159.013; Wed, 3 Jan 2024
 08:47:58 +0000
From: Srinivasulu Thanneeru <sthanneeru@micron.com>
To: "Huang, Ying" <ying.huang@intel.com>
CC: gregory.price <gregory.price@memverge.com>, Srinivasulu Opensrc
	<sthanneeru.opensrc@micron.com>, "linux-cxl@vger.kernel.org"
	<linux-cxl@vger.kernel.org>, "linux-mm@kvack.org" <linux-mm@kvack.org>,
	"aneesh.kumar@linux.ibm.com" <aneesh.kumar@linux.ibm.com>,
	"dan.j.williams@intel.com" <dan.j.williams@intel.com>, "mhocko@suse.com"
	<mhocko@suse.com>, "tj@kernel.org" <tj@kernel.org>, "john@jagalactic.com"
	<john@jagalactic.com>, Eishan Mirakhur <emirakhur@micron.com>, Vinicius
 Tavares Petrucci <vtavarespetr@micron.com>, Ravis OpenSrc
	<Ravis.OpenSrc@micron.com>, "Jonathan.Cameron@huawei.com"
	<Jonathan.Cameron@huawei.com>, "linux-kernel@vger.kernel.org"
	<linux-kernel@vger.kernel.org>, Johannes Weiner <hannes@cmpxchg.org>, Wei Xu
	<weixugc@google.com>
Subject: RE: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
Thread-Topic: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
Thread-Index: AQHaLe1WCWEmLbBSRk2O5Sdey42WeLCpzLPHgADTuACAA/H6xIAZGhOAgAAO84SAABl24IAADebegAACPiA=
Date: Wed, 3 Jan 2024 08:47:57 +0000
Message-ID: <PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
	<87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZXyQIJOim1+tE0Qr@memverge.com>
	<87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com>
In-Reply-To: <87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach: 
X-MS-TNEF-Correlator: 
msip_labels: MSIP_Label_6fdea275-d6f3-438f-b8d8-013cab2023d3_ActionId=e613c07d-f699-4fa0-baf6-de8be7204408;MSIP_Label_6fdea275-d6f3-438f-b8d8-013cab2023d3_ContentBits=0;MSIP_Label_6fdea275-d6f3-438f-b8d8-013cab2023d3_Enabled=true;MSIP_Label_6fdea275-d6f3-438f-b8d8-013cab2023d3_Method=Privileged;MSIP_Label_6fdea275-d6f3-438f-b8d8-013cab2023d3_Name=Public;MSIP_Label_6fdea275-d6f3-438f-b8d8-013cab2023d3_SetDate=2024-01-03T08:40:17Z;MSIP_Label_6fdea275-d6f3-438f-b8d8-013cab2023d3_SiteId=f38a5ecd-2813-4862-b11b-ac1d563c806f;
authentication-results: dkim=none (message not signed)
 header.d=none;dmarc=none action=none header.from=micron.com;
x-ms-publictraffictype: Email
x-ms-traffictypediagnostic: PH0PR08MB7955:EE_|SA1PR08MB7037:EE_
x-ms-office365-filtering-correlation-id: 10486dff-c85e-4e7d-d593-08dc0c38af60
x-ld-processed: f38a5ecd-2813-4862-b11b-ac1d563c806f,ExtAddr
x-ms-exchange-senderadcheck: 1
x-ms-exchange-antispam-relay: 0
x-microsoft-antispam: BCL:0;
x-microsoft-antispam-message-info: n7TFjNhhXtHjZ01LKBy41yEOuJ25kUParIstsChmAg+3A3ct7wOOLVXiOWtHKI25MW8v5jpRvZq9ynRsj5B7RzxKwW7NJWoThsMTJReMmyN98/Rlq4zG/Tc/3TBxQDoMJshF51eOpeMA1d3i+q4Nb7enNTYfrWoIBEor6JpAbkm/W92CPY7mVKKAo72/et6J7xFSFGB4+J0LjzODKW0ZoElSF0JxT/HV98jXE6DtC0ueTjXHZx4AzY7YQ7eaVw6bxptqs4birrW9Czy3oKCkAzXl7mwGFhlpBl3DaurmVnAZ/vkFC5FSp0TzMe4s5C57o8LfHUvdqr6yJbTArYm66YwJ8jhLEUbNL9VAxFg3KpO4ejHXS4zYiN883E0/D7MBuWhPQsLlNYd5yHjzfVYZM9/Q/f4MyjBiAUpcbO/AC/o9wIfNUT5q34+TQ3DEJ7DA7VjUxTg+UV+hduLsXaqho9D6Qxf5caP2Y+SQ/+Yihfk5Vcs1CoLWXnUB6btsjGGuLVj/9be18tqfzywTOohyf9BPwpDIqJuIEK2P91vjLBe4ZZvtUkLsIe1u6J6z+Due8TBlejffF5NdrHPE6JWlZHR7fZlHs32Qhlz9lllcN3rm/Cpe6vZC7FREkVXrzaFJDsr3V0WqGFbrafuKy9K5WA==
x-forefront-antispam-report: CIP:255.255.255.255;CTRY:;LANG:en;SCL:1;SRV:;IPV:NLI;SFV:NSPM;H:PH0PR08MB7955.namprd08.prod.outlook.com;PTR:;CAT:NONE;SFS:(13230031)(366004)(396003)(346002)(376002)(136003)(39860400002)(230273577357003)(230173577357003)(230922051799003)(451199024)(64100799003)(186009)(1800799012)(7416002)(2906002)(5660300002)(41300700001)(478600001)(86362001)(966005)(122000001)(38070700009)(38100700002)(33656002)(53546011)(83380400001)(7696005)(6506007)(9686003)(26005)(45080400002)(71200400001)(52536014)(8676002)(8936002)(4326008)(66946007)(76116006)(316002)(66556008)(66476007)(66446008)(64756008)(6916009)(54906003)(55016003)(66899024);DIR:OUT;SFP:1101;
x-ms-exchange-antispam-messagedata-chunkcount: 1
x-ms-exchange-antispam-messagedata-0: =?us-ascii?Q?BbblkOtCN8FComOX3V9WdhuOZoA1BAyeinBOxMkKsflwx+RgAPVFgC2qnU+O?=
 =?us-ascii?Q?k+9F1/XlivEKAUpeP091V46h2R3lQSlF3niE1aLX0+qn71Hfna02RqpIBr0x?=
 =?us-ascii?Q?20qexyoMgWcITUCusoYJcmnkuWIq18VBwH+7rBWoYTA3KihegIFWZkJ3VVIE?=
 =?us-ascii?Q?GOnoEBV/vX4MELIn0P10HfnMtlkduikFIA6DwzpB+fZyGcQDOv3ZT/s9VOjl?=
 =?us-ascii?Q?njc/+ftawCCFdbGXsrNg0NIUGF7rl99nI7JjJiRm0nxxiOPU9kTNjT0tavHt?=
 =?us-ascii?Q?O7mS01rRvXn730Kd/nslwfpFYqDFuNYojc1a0kLzsQIDcShfUpLSArE5eXL+?=
 =?us-ascii?Q?VP7HjRi/8H3heCIfzzbGUOXiQCwDH18MYq9cVV7+CeJbu+nbE/kRJSrnWt5z?=
 =?us-ascii?Q?06/zI4C0xWMW2PLoJCx5XEls2MXzuIl7l44L4HFWbRmqlBBQUWCEyVFtUv7Z?=
 =?us-ascii?Q?9chcfMU0vjqnDH2rKb3Z5tKR8L2jvYAjgLEOy+q7lI1BpCE2Y61aTiOk9mdy?=
 =?us-ascii?Q?54A03BOu07k5O24OTKtTsi6BA/iu+JkvZPkSTpzPWK3iQ3XQIolOI2O2iyC4?=
 =?us-ascii?Q?AOuJEEbwdU2jRdqCqAOofQxNwJPS9jIEqW6izYZEgbAflB1JoLRCF3qZcuyM?=
 =?us-ascii?Q?NdH2lQeFOkES2KOF0pVPa2U9FIl4BTt8sNDGvVnmYjxk6GxWdYN8TmI8MpuB?=
 =?us-ascii?Q?YMT3CnxZwbtsGADVO2NImlVTYmNspl+9+KDm6gWYIlJ1asMnFVsz7p84zLPy?=
 =?us-ascii?Q?8OMJYww3oMvWLtYW86fBUYz0jB4NRuGvSe5YeZa/uXJv9QXz0v+oBtK+zeFO?=
 =?us-ascii?Q?A+fNWhMv4BDjIKjESzOrfk70kRU3TND2Tt2hCJn2fFPK+D30pDblrSsosbu2?=
 =?us-ascii?Q?O46GD+twrpf5/jvt5w5i7PwmPQOFYo70z7VkEhOhz7FhfW/XBJ/nz/GwhOC4?=
 =?us-ascii?Q?o9AP3Md3IMFcV59fsOXONvNobvYgYOXeSIxzfwNYj1uOUQ6ZHLkv/F41bxOm?=
 =?us-ascii?Q?3pVRdxrCztYACndZ6vQQIAMpV/p4yOkc1E2G+uAMUlTB/yEh53Pk81DVoc8i?=
 =?us-ascii?Q?2OLnqjHhKYp3nqjTi1ZMVosAh17iYr6X/Ukr0p57qtjggwlhFnADGhqShV/D?=
 =?us-ascii?Q?guJeQwCmV1lJYGYSKtTzmhKS4+txRFzM1ejJSC65J6FW+u7ue2LfpAEDyDpb?=
 =?us-ascii?Q?RG3EYnf8l/OsI51tq9dmhwfUO1SoVBGT3xjo85hh0Lu3LplpGKN6HkQKJ3KH?=
 =?us-ascii?Q?wI6xpYWx9ck2AikzL2S4uQ433FzdCSax6QKtgTZQtroe/neMYD45vtL2NM9Y?=
 =?us-ascii?Q?CHDSlCJeZpmcwMgwwg1ZEJKDTueYJlvgjVREmoENfrjhBOwA6ZiSY4eFsvFW?=
 =?us-ascii?Q?XY2sObk/dzdhk2wQTMCI/GTC2h7KcE7rXfFOFd5TUvb0N4SpzycMne6gNESA?=
 =?us-ascii?Q?j2ZhgQ62n41qFzEoPz+DuDQl/tSCZRznj5rZBwYR2mK5RbO8D2IVhYumKfbX?=
 =?us-ascii?Q?/GWoRfdVux/9L64ofsKdnlWAkgxMjiGBE46TE8azh45wUDlnGSDco6Jgq+Fl?=
 =?us-ascii?Q?lDhlC+sQ5nIbysu2909CQk3FdoMgSAnefhlY/iGK?=
Content-Type: text/plain; charset="us-ascii"
Content-Transfer-Encoding: quoted-printable
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
X-OriginatorOrg: micron.com
X-MS-Exchange-CrossTenant-AuthAs: Internal
X-MS-Exchange-CrossTenant-AuthSource: PH0PR08MB7955.namprd08.prod.outlook.com
X-MS-Exchange-CrossTenant-Network-Message-Id: 10486dff-c85e-4e7d-d593-08dc0c38af60
X-MS-Exchange-CrossTenant-originalarrivaltime: 03 Jan 2024 08:47:57.9629
 (UTC)
X-MS-Exchange-CrossTenant-fromentityheader: Hosted
X-MS-Exchange-CrossTenant-id: f38a5ecd-2813-4862-b11b-ac1d563c806f
X-MS-Exchange-CrossTenant-mailboxtype: HOSTED
X-MS-Exchange-CrossTenant-userprincipalname: I2r0iPMTDICvM0MvrFOjwQRtceRFtBE9PZq2sXVJ4ePZS5MQy4XNSE6VqC8stDm7ULK8477trrV5lw0Qz38MhQ==
X-MS-Exchange-Transport-CrossTenantHeadersStamped: SA1PR08MB7037



> -----Original Message-----
> From: Huang, Ying <ying.huang@intel.com>
> Sent: Wednesday, January 3, 2024 2:00 PM
> To: Srinivasulu Thanneeru <sthanneeru@micron.com>
> Cc: gregory.price <gregory.price@memverge.com>; Srinivasulu Opensrc
> <sthanneeru.opensrc@micron.com>; linux-cxl@vger.kernel.org; linux-
> mm@kvack.org; aneesh.kumar@linux.ibm.com; dan.j.williams@intel.com;
> mhocko@suse.com; tj@kernel.org; john@jagalactic.com; Eishan Mirakhur
> <emirakhur@micron.com>; Vinicius Tavares Petrucci
> <vtavarespetr@micron.com>; Ravis OpenSrc <Ravis.OpenSrc@micron.com>;
> Jonathan.Cameron@huawei.com; linux-kernel@vger.kernel.org; Johannes
> Weiner <hannes@cmpxchg.org>; Wei Xu <weixugc@google.com>
> Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory
> tiers
>
> CAUTION: EXTERNAL EMAIL. Do not click links or open attachments unless
> you recognize the sender and were expecting this message.
>
>
> Srinivasulu Thanneeru <sthanneeru@micron.com> writes:
>
> > Micron Confidential
> >
> >
> >
> > Micron Confidential
> >> -----Original Message-----
> >> From: Huang, Ying <ying.huang@intel.com>
> >> Sent: Wednesday, January 3, 2024 11:38 AM
> >> To: Srinivasulu Thanneeru <sthanneeru@micron.com>
> >> Cc: gregory.price <gregory.price@memverge.com>; Srinivasulu Opensrc
> >> <sthanneeru.opensrc@micron.com>; linux-cxl@vger.kernel.org; linux-
> >> mm@kvack.org; aneesh.kumar@linux.ibm.com;
> dan.j.williams@intel.com;
> >> mhocko@suse.com; tj@kernel.org; john@jagalactic.com; Eishan Mirakhur
> >> <emirakhur@micron.com>; Vinicius Tavares Petrucci
> >> <vtavarespetr@micron.com>; Ravis OpenSrc
> <Ravis.OpenSrc@micron.com>;
> >> Jonathan.Cameron@huawei.com; linux-kernel@vger.kernel.org; Johannes
> >> Weiner <hannes@cmpxchg.org>; Wei Xu <weixugc@google.com>
> >> Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between
> memory
> >> tiers
> >>
> >> CAUTION: EXTERNAL EMAIL. Do not click links or open attachments unless
> >> you recognize the sender and were expecting this message.
> >>
> >>
> >> Srinivasulu Thanneeru <sthanneeru@micron.com> writes:
> >>
> >> > Micron Confidential
> >> >
> >> > Hi Huang, Ying,
> >> >
> >> > My apologies for wrong mail reply format, my mail client settings go=
t
> >> changed on my PC.
> >> > Please find comments bellow inline.
> >> >
> >> > Regards,
> >> > Srini
> >> >
> >> >
> >> > Micron Confidential
> >> >> -----Original Message-----
> >> >> From: Huang, Ying <ying.huang@intel.com>
> >> >> Sent: Monday, December 18, 2023 11:26 AM
> >> >> To: gregory.price <gregory.price@memverge.com>
> >> >> Cc: Srinivasulu Opensrc <sthanneeru.opensrc@micron.com>; linux-
> >> >> cxl@vger.kernel.org; linux-mm@kvack.org; Srinivasulu Thanneeru
> >> >> <sthanneeru@micron.com>; aneesh.kumar@linux.ibm.com;
> >> >> dan.j.williams@intel.com; mhocko@suse.com; tj@kernel.org;
> >> >> john@jagalactic.com; Eishan Mirakhur <emirakhur@micron.com>;
> Vinicius
> >> >> Tavares Petrucci <vtavarespetr@micron.com>; Ravis OpenSrc
> >> >> <Ravis.OpenSrc@micron.com>; Jonathan.Cameron@huawei.com;
> linux-
> >> >> kernel@vger.kernel.org; Johannes Weiner <hannes@cmpxchg.org>; Wei
> Xu
> >> >> <weixugc@google.com>
> >> >> Subject: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory
> >> tiers
> >> >>
> >> >> CAUTION: EXTERNAL EMAIL. Do not click links or open attachments
> unless
> >> >> you recognize the sender and were expecting this message.
> >> >>
> >> >>
> >> >> Gregory Price <gregory.price@memverge.com> writes:
> >> >>
> >> >> > On Fri, Dec 15, 2023 at 01:02:59PM +0800, Huang, Ying wrote:
> >> >> >> <sthanneeru.opensrc@micron.com> writes:
> >> >> >>
> >> >> >> > =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
> >> >> >> > Version Notes:
> >> >> >> >
> >> >> >> > V2 : Changed interface to memtier_override from adistance_offs=
et.
> >> >> >> > memtier_override was recommended by
> >> >> >> > 1. John Groves <john@jagalactic.com>
> >> >> >> > 2. Ravi Shankar <ravis.opensrc@micron.com>
> >> >> >> > 3. Brice Goglin <Brice.Goglin@inria.fr>
> >> >> >>
> >> >> >> It appears that you ignored my comments for V1 as follows ...
> >> >> >>
> >> >> >>
> >> >>
> >>
> https://lore.k/
> %2F&data=3D05%7C02%7Csthanneeru%40micron.com%7Ce9e04d25ea7540100
> cf308dc0c366eb1%7Cf38a5ecd28134862b11bac1d563c806f%7C0%7C0%7C63
> 8398675187014390%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMD
> AiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C
> &sdata=3Dk6J1wxcuHTwR9eoD9Yz137bkn6wt1L9zpf5YaOjoIqA%3D&reserved=3D0
> >>
> %2F&data=3D05%7C02%7Csthanneeru%40micron.com%7C3e5d38eb47be463c2
> >>
> 95c08dc0c229d22%7Cf38a5ecd28134862b11bac1d563c806f%7C0%7C0%7C63
> >>
> 8398590664228240%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMD
> >>
> AiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C
> >>
> &sdata=3D7fPxb1YYR2tZ0v2FB1vlXnMJFcI%2Fr9HT2%2BUD1MNUd%2FI%3D&re
> >> served=3D0
> >> >> ernel.org%2Flkml%2F87o7f62vur.fsf%40yhuang6-
> >> >>
> >>
> desk2.ccr.corp.intel.com%2F&data=3D05%7C02%7Csthanneeru%40micron.com
> >> >>
> >>
> %7C5e614e5f028342b6b59c08dbff8e3e37%7Cf38a5ecd28134862b11bac1d56
> >> >>
> >>
> 3c806f%7C0%7C0%7C638384758666895965%7CUnknown%7CTWFpbGZsb3d
> >> >>
> >>
> 8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3
> >> >>
> >>
> D%7C3000%7C%7C%7C&sdata=3DOpMkYCar%2Fv8uHb7AvXbmaNltnXeTvcNUTi
> >> >> bLhwV12Fg%3D&reserved=3D0
> >> >
> >> > Thank you, Huang, Ying for pointing to this.
> >> >
> >>
> https://lpc.ev/
> %2F&data=3D05%7C02%7Csthanneeru%40micron.com%7Ce9e04d25ea7540100
> cf308dc0c366eb1%7Cf38a5ecd28134862b11bac1d563c806f%7C0%7C0%7C63
> 8398675187014390%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMD
> AiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C
> &sdata=3D%2F0AW8RYpTIa7%2FiScnkzmmTeAE9TYqjsuWWjTuxBPptk%3D&rese
> rved=3D0
> >>
> ents%2Fevent%2F16%2Fcontributions%2F1209%2Fattachments%2F1042%2F1
> >>
> 995%2FLive%2520In%2520a%2520World%2520With%2520Multiple%2520Me
> >>
> mory%2520Types.pdf&data=3D05%7C02%7Csthanneeru%40micron.com%7C3e
> >>
> 5d38eb47be463c295c08dc0c229d22%7Cf38a5ecd28134862b11bac1d563c806
> >>
> f%7C0%7C0%7C638398590664228240%7CUnknown%7CTWFpbGZsb3d8eyJW
> >>
> IjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3
> >>
> 000%7C%7C%7C&sdata=3D1fGraxff7%2F1hNaE0an0xEudSKSUvaF3HgClMkmdC7
> >> n8%3D&reserved=3D0
> >> >
> >> > In the presentation above, the adistance_offsets are per memtype.
> >> > We believe that adistance_offset per node is more suitable and flexi=
ble.
> >> > since we can change it per node. If we keep adistance_offset per
> memtype,
> >> > then we cannot change it for a specific node of a given memtype.
> >> >
> >> >> >>
> >> >>
> >>
> https://lore.k/
> %2F&data=3D05%7C02%7Csthanneeru%40micron.com%7Ce9e04d25ea7540100
> cf308dc0c366eb1%7Cf38a5ecd28134862b11bac1d563c806f%7C0%7C0%7C63
> 8398675187014390%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMD
> AiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C
> &sdata=3Dk6J1wxcuHTwR9eoD9Yz137bkn6wt1L9zpf5YaOjoIqA%3D&reserved=3D0
> >>
> %2F&data=3D05%7C02%7Csthanneeru%40micron.com%7C3e5d38eb47be463c2
> >>
> 95c08dc0c229d22%7Cf38a5ecd28134862b11bac1d563c806f%7C0%7C0%7C63
> >>
> 8398590664228240%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMD
> >>
> AiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C
> >>
> &sdata=3D7fPxb1YYR2tZ0v2FB1vlXnMJFcI%2Fr9HT2%2BUD1MNUd%2FI%3D&re
> >> served=3D0
> >> >> ernel.org%2Flkml%2F87jzpt2ft5.fsf%40yhuang6-
> >> >>
> >>
> desk2.ccr.corp.intel.com%2F&data=3D05%7C02%7Csthanneeru%40micron.com
> >> >>
> >>
> %7C5e614e5f028342b6b59c08dbff8e3e37%7Cf38a5ecd28134862b11bac1d56
> >> >>
> >>
> 3c806f%7C0%7C0%7C638384758666895965%7CUnknown%7CTWFpbGZsb3d
> >> >>
> >>
> 8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3
> >> >>
> >>
> D%7C3000%7C%7C%7C&sdata=3DO0%2B6T%2FgU0TicCEYBac%2FAyjOLwAeouh
> >> >> D%2BcMI%2BflOsI1M%3D&reserved=3D0
> >> >
> >> > Yes, memory_type would be grouping the related memories together as
> >> single tier.
> >> > We should also have a flexibility to move nodes between tiers, to
> address
> >> the issues.
> >> > described in use cases above.
> >>
> >> We don't pursue absolute flexibility.  We add necessary flexibility
> >> only.  Why do you need this kind of flexibility?  Can you provide some
> >> use cases where memory_type based "adistance_offset" doesn't work?
> >
> > - /sys/devices/virtual/memory_type/memory_type/ adistance_offset
> > memory_type based "adistance_offset will provide a way to move all node=
s
> of same memory_type (e.g. all cxl nodes)
> > to different tier.
>
> We will not put the CXL nodes with different performance metrics in one
> memory_type.  If so, do you still need to move one of them?

>From  https://lpc.events/event/16/contributions/1209/attachments/1042/1995/=
Live%20In%20a%20World%20With%20Multiple%20Memory%20Types.pdf
abstract_distance_offset: override by users to deal with firmware issue.

say firmware can configure the cxl node into wrong tiers, similar to that i=
t may also configure all cxl nodes into single memtype, hence all these nod=
es can fall into a single wrong tier.
In this case, per node adistance_offset would be good to have ?

--
Srini
> > Whereas /sys/devices/system/node/node2/memtier_override provide a
> way migrate a node from one tier to another.
> > Considering a case where we would like to move two cxl nodes into two
> different tiers in future.
> > So, I thought it would be good to have flexibility at node level instea=
d of at
> memory_type.
>
> --
> Best Regards,
> Huang, Ying

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from mgamail.intel.com (mgamail.intel.com [192.198.163.11])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 58F1633EE;
	Tue,  9 Jan 2024 03:43:25 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=none dis=none) header.from=intel.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=intel.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=intel.com header.i=@intel.com header.b="i2U4OK4A"
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple;
  d=intel.com; i=@intel.com; q=dns/txt; s=Intel;
  t=1704771806; x=1736307806;
  h=from:to:cc:subject:in-reply-to:references:date:
   message-id:mime-version;
  bh=EXGALg+04GjIg7VHmOoodLCutmjxuq5kzaEUQbcbKOQ=;
  b=i2U4OK4AWF4jDzopy9a6L83jkXF73pBoJlGBP5YVSVek8R95HXeSbxwr
   UJwEZnHEEggC9wmORgOwh1QhMgAMuQIV7trO2Ekiba1HOg1Z2JN/sbIaS
   aovjtMfAqOcr3Q2SZ1tAOLCkxNFRXDQUNSUAvPv+ABpSI5OPs1Idei3Fr
   ZEUey4tnVqkL0NfxASU0gA9JoWy76lA/nUvzBBrP/B3Fz6EYdsdTrp73c
   zypIj5jEcC8SoFD8APNTFP0ucm2teGFPlPgzeS0LGkmwKf2pHW4WmX8Gm
   0yg/i64gkCQsbPbWtJfcH564qVBK7lYxBoVJWkjgGTHg4/NrNakODrHeM
   Q==;
X-IronPort-AV: E=McAfee;i="6600,9927,10947"; a="4833825"
X-IronPort-AV: E=Sophos;i="6.04,181,1695711600"; 
   d="scan'208";a="4833825"
Received: from fmsmga003.fm.intel.com ([10.253.24.29])
  by fmvoesa105.fm.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 08 Jan 2024 19:43:25 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=McAfee;i="6600,9927,10947"; a="872099709"
X-IronPort-AV: E=Sophos;i="6.04,181,1695711600"; 
   d="scan'208";a="872099709"
Received: from yhuang6-desk2.sh.intel.com (HELO yhuang6-desk2.ccr.corp.intel.com) ([10.238.208.55])
  by fmsmga003-auth.fm.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 08 Jan 2024 19:43:09 -0800
From: "Huang, Ying" <ying.huang@intel.com>
To: Gregory Price <gregory.price@memverge.com>
Cc: Srinivasulu Thanneeru <sthanneeru@micron.com>,  Srinivasulu Opensrc
 <sthanneeru.opensrc@micron.com>,  "linux-cxl@vger.kernel.org"
 <linux-cxl@vger.kernel.org>,  "linux-mm@kvack.org" <linux-mm@kvack.org>,
  "aneesh.kumar@linux.ibm.com" <aneesh.kumar@linux.ibm.com>,
  "dan.j.williams@intel.com" <dan.j.williams@intel.com>,  "mhocko@suse.com"
 <mhocko@suse.com>,  "tj@kernel.org" <tj@kernel.org>,
  "john@jagalactic.com" <john@jagalactic.com>,  Eishan Mirakhur
 <emirakhur@micron.com>,  "Vinicius Tavares Petrucci"
 <vtavarespetr@micron.com>,  Ravis OpenSrc <Ravis.OpenSrc@micron.com>,
  "Jonathan.Cameron@huawei.com" <Jonathan.Cameron@huawei.com>,
  "linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>,  Johannes
 Weiner <hannes@cmpxchg.org>,  Wei Xu <weixugc@google.com>,  Hao Xiang
 <hao.xiang@bytedance.com>,  "Ho-Ren (Jack) Chuang"
 <horenchuang@bytedance.com>
Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
In-Reply-To: <ZZwrIoP9+ey7rp3C@memverge.com> (Gregory Price's message of "Mon,
	8 Jan 2024 12:04:34 -0500")
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
	<87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZXyQIJOim1+tE0Qr@memverge.com>
	<87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87wmspbpma.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZZwrIoP9+ey7rp3C@memverge.com>
Date: Tue, 09 Jan 2024 11:41:11 +0800
Message-ID: <87o7dv897s.fsf@yhuang6-desk2.ccr.corp.intel.com>
User-Agent: Gnus/5.13 (Gnus v5.13)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Type: text/plain; charset=ascii

Gregory Price <gregory.price@memverge.com> writes:

> On Thu, Jan 04, 2024 at 02:05:01PM +0800, Huang, Ying wrote:
>> >
>> > From  https://lpc.events/event/16/contributions/1209/attachments/1042/1995/Live%20In%20a%20World%20With%20Multiple%20Memory%20Types.pdf
>> > abstract_distance_offset: override by users to deal with firmware issue.
>> >
>> > say firmware can configure the cxl node into wrong tiers, similar to
>> > that it may also configure all cxl nodes into single memtype, hence
>> > all these nodes can fall into a single wrong tier.
>> > In this case, per node adistance_offset would be good to have ?
>> 
>> I think that it's better to fix the error firmware if possible.  And
>> these are only theoretical, not practical issues.  Do you have some
>> practical issues?
>> 
>> I understand that users may want to move nodes between memory tiers for
>> different policy choices.  For that, memory_type based adistance_offset
>> should be good.
>> 
>
> There's actually an affirmative case to change memory tiering to allow
> either movement of nodes between tiers, or at least base placement on
> HMAT information. Preferably, membership would be changable to allow
> hotplug/DCD to be managed (there's no guarantee that the memory passed
> through will always be what HMAT says on initial boot).

IIUC, from Jonathan Cameron as below, the performance of memory
shouldn't change even for DCD devices.

https://lore.kernel.org/linux-mm/20231103141636.000007e4@Huawei.com/

It's possible to change the performance of a NUMA node changed, if we
hot-remove a memory device, then hot-add another different memory
device.  It's hoped that the CDAT changes too.

So, all in all, HMAT + CDAT can help us to put the memory device in
appropriate memory tiers.  Now, we have HMAT support in upstream.  We
will working on CDAT support.

--
Best Regards,
Huang, Ying

> https://lore.kernel.org/linux-cxl/CAAYibXjZ0HSCqMrzXGv62cMLncS_81R3e1uNV5Fu4CPm0zAtYw@mail.gmail.com/
>
> This group wants to enable passing CXL memory through to KVM/QEMU
> (i.e. host CXL expander memory passed through to the guest), and
> allow the guest to apply memory tiering.
>
> There are multiple issues with this, presently:
>
> 1. The QEMU CXL virtual device is not and probably never will be
>    performant enough to be a commodity class virtualization.  The
>    reason is that the virtual CXL device is built off the I/O
>    virtualization stack, which treats memory accesses as I/O accesses.
>
>    KVM also seems incompatible with the design of the CXL memory device
>    in general, but this problem may or may not be a blocker.
>
>    As a result, access to virtual CXL memory device leads to QEMU
>    crawling to a halt - and this is unlikely to change.
>
>    There is presently no good way forward to create a performant virtual
>    CXL device in QEMU.  This means the memory tiering component in the
>    kernel is functionally useless for virtual CXL memory, because...
>
> 2. When passing memory through as an explicit NUMA node, but not as
>    part of a CXL memory device, the nodes are lumped together in the
>    DRAM tier.
>
> None of this has to do with firmware.
>
> Memory-type is an awful way of denoting membership of a tier, but we
> have HMAT information that can be passed through via QEMU:
>
> -object memory-backend-ram,size=4G,id=ram-node0 \
> -object memory-backend-ram,size=4G,id=ram-node1 \
> -numa node,nodeid=0,cpus=0-4,memdev=ram-node0 \
> -numa node,initiator=0,nodeid=1,memdev=ram-node1 \
> -numa hmat-lb,initiator=0,target=0,hierarchy=memory,data-type=access-latency,latency=10 \
> -numa hmat-lb,initiator=0,target=0,hierarchy=memory,data-type=access-bandwidth,bandwidth=10485760 \
> -numa hmat-lb,initiator=0,target=1,hierarchy=memory,data-type=access-latency,latency=20 \
> -numa hmat-lb,initiator=0,target=1,hierarchy=memory,data-type=access-bandwidth,bandwidth=5242880
>
> Not only would it be nice if we could change tier membership based on
> this data, it's realistically the only way to allow guests to accomplish
> memory tiering w/ KVM/QEMU and CXL memory passed through to the guest.
>
> ~Gregory

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from NAM10-MW2-obe.outbound.protection.outlook.com (mail-mw2nam10on2054.outbound.protection.outlook.com [40.107.94.54])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id D7EDB53E2A;
	Mon,  8 Jan 2024 17:04:46 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=none dis=none) header.from=memverge.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=memverge.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (1024-bit key) header.d=memverge.com header.i=@memverge.com header.b="f6hOR0Rw"
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=i9rWEoMAPvxmhRSlxDSPrczOYWZ2C4pU6KaX5BnNtce2eBzMdzdwz8x9VRTbb1QifOxbttlBRE4Yq2baNZF3I6MX37CbZh8VCdvGEm1xilN9v9RQfRF2v9AaaaNpo3J9yCpDl8L4BEGGpYafaOZ4xtrXszBZ7nG7UEJlIKFa36FiFl56ARqx+T01ndy/+I/KeWX5zz4BPH02kJZiOxABfqkPnl1Dncoks3NmFnS8LG5pM4yzuKLOZQjALtJSHBK9klQQvcuBUX3dr05aRqX2JvUHaxKfZIrMXBKleGJOjh95CFMA+v5ivqmb7kRm6pKrDb3j8QNy4Ua24hSVwfR/DA==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-AntiSpam-MessageData-ChunkCount:X-MS-Exchange-AntiSpam-MessageData-0:X-MS-Exchange-AntiSpam-MessageData-1;
 bh=VEoSsfRbWtj26Q2RQKpLHi1B5ndwjI52C/k9+njXgXk=;
 b=eJx2gKxNGydorKH63Jxr+O1YXh8Lvgv9TKPRUAQc963tDyqy3eGUPtGyBeRKA6hyCetZTcNOSuf7G1I3wJwvB8THB5Rrm92D7cN9ezZ4FhAZuEPC1elm9Sfiwi9dWxzbf5N0GygZSWDx1mExzrmFhfOqd/KsagW42GlbqZ/XN96+1zfVWGZQi1oC2bz8SQF4Qf5qXvMuPgtjhkAdD/dPgJKtIX/+h7Hz58buG115eZrEGgnPszyZQEUVwcnLOopa7Ug07ptL0fIpIqKqJgGHsBNiFaVZBXcLHGgZydNf6JmLGzSjggN95Krkj43dwSy6JHpI9/evuLYtpiAGKHIQpA==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass
 smtp.mailfrom=memverge.com; dmarc=pass action=none header.from=memverge.com;
 dkim=pass header.d=memverge.com; arc=none
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=memverge.com;
 s=selector2;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=VEoSsfRbWtj26Q2RQKpLHi1B5ndwjI52C/k9+njXgXk=;
 b=f6hOR0RwY4U56q2yo7akLmbmvYzkfBZalIMfEIaQh79aHjNDUzfVWLOdVFk5v3uEQwIpdKIoxt0TibhX2PXfX4FDAmPY2W9EIkjR7hSWNrkG1ag/7V/bdIjn6DQfMzTgFFa44WUPOd+cxDWFWdhKnsQBaLo9JF9WqHgk0mpS9zA=
Authentication-Results: dkim=none (message not signed)
 header.d=none;dmarc=none action=none header.from=memverge.com;
Received: from SJ0PR17MB5512.namprd17.prod.outlook.com (2603:10b6:a03:394::19)
 by DM8PR17MB4918.namprd17.prod.outlook.com (2603:10b6:8:3c::20) with
 Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.7159.23; Mon, 8 Jan
 2024 17:04:43 +0000
Received: from SJ0PR17MB5512.namprd17.prod.outlook.com
 ([fe80::7a04:dc86:2799:2f15]) by SJ0PR17MB5512.namprd17.prod.outlook.com
 ([fe80::7a04:dc86:2799:2f15%5]) with mapi id 15.20.7159.020; Mon, 8 Jan 2024
 17:04:43 +0000
Date: Mon, 8 Jan 2024 12:04:34 -0500
From: Gregory Price <gregory.price@memverge.com>
To: "Huang, Ying" <ying.huang@intel.com>
Cc: Srinivasulu Thanneeru <sthanneeru@micron.com>,
	Srinivasulu Opensrc <sthanneeru.opensrc@micron.com>,
	"linux-cxl@vger.kernel.org" <linux-cxl@vger.kernel.org>,
	"linux-mm@kvack.org" <linux-mm@kvack.org>,
	"aneesh.kumar@linux.ibm.com" <aneesh.kumar@linux.ibm.com>,
	"dan.j.williams@intel.com" <dan.j.williams@intel.com>,
	"mhocko@suse.com" <mhocko@suse.com>,
	"tj@kernel.org" <tj@kernel.org>,
	"john@jagalactic.com" <john@jagalactic.com>,
	Eishan Mirakhur <emirakhur@micron.com>,
	Vinicius Tavares Petrucci <vtavarespetr@micron.com>,
	Ravis OpenSrc <Ravis.OpenSrc@micron.com>,
	"Jonathan.Cameron@huawei.com" <Jonathan.Cameron@huawei.com>,
	"linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>,
	Johannes Weiner <hannes@cmpxchg.org>, Wei Xu <weixugc@google.com>,
	Hao Xiang <hao.xiang@bytedance.com>,
	"Ho-Ren (Jack) Chuang" <horenchuang@bytedance.com>
Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
Message-ID: <ZZwrIoP9+ey7rp3C@memverge.com>
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
 <87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
 <ZXyQIJOim1+tE0Qr@memverge.com>
 <87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
 <PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
 <PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com>
 <PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87wmspbpma.fsf@yhuang6-desk2.ccr.corp.intel.com>
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <87wmspbpma.fsf@yhuang6-desk2.ccr.corp.intel.com>
X-ClientProxiedBy: BY3PR10CA0007.namprd10.prod.outlook.com
 (2603:10b6:a03:255::12) To SJ0PR17MB5512.namprd17.prod.outlook.com
 (2603:10b6:a03:394::19)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
X-MS-PublicTrafficType: Email
X-MS-TrafficTypeDiagnostic: SJ0PR17MB5512:EE_|DM8PR17MB4918:EE_
X-MS-Office365-Filtering-Correlation-Id: 2514978e-f88d-45c2-72ec-08dc106be8c9
X-MS-Exchange-SenderADCheck: 1
X-MS-Exchange-AntiSpam-Relay: 0
X-Microsoft-Antispam: BCL:0;
X-Microsoft-Antispam-Message-Info: 2yxa03Sz0wt/hwnN3qHVA9UtoaKdXetsK/RygeK/QuqjU0lI51EBkCvMW/tZbUUaPh2QiFb1Qp7oNNWCA+gLI4FvsTwyo90pSpxAeZIKy417yTmTCBXwpVvkNBgUZm/hPy02tWC6wLmf8GM7JMh6wSSV/Ilv0ZClvBb3GfH95shyg8O3i3sXyo3u4TCnzGy7sJxyj2vZA4+5EsLDlrmoVhRvRob/HMqOPROhuEIXcmlcyacrpyl/PwZxWejUmCtjpuzw+H7RSjWBJXFEFny5ps/Sc7N4b6B3lFVTQXuNsT9FlMSlw8l80FBCgZTIWuNOv1vJDrbyEgMn1SNWPHOebezbztlREiBXbaw6+WS4IwHaWpSPmD2aKd/a63H78f1hIYG6CA7iFT9rIDkvN0L1vCXjanXYEUx9flYvjChlGHTXcSyxChSTLuB+hRCCMJ63nXklJYOEQzNm/ce9lgqJYcuU4ZC9AqFOfMgi3wlI99xPRI2kpviPqYJZ/eJ8Y1yyzomkAxeFLC7+kEcaQCh+QBwm0Pin8B/F3WvJz68EwLNHVSLBHZ2bHdS4rgEQFyTgAd1UvQ3VztjfeG8cnVDF5QLCgC0JmNejqLCwa3RPFh8=
X-Forefront-Antispam-Report: CIP:255.255.255.255;CTRY:;LANG:en;SCL:1;SRV:;IPV:NLI;SFV:NSPM;H:SJ0PR17MB5512.namprd17.prod.outlook.com;PTR:;CAT:NONE;SFS:(13230031)(39840400004)(136003)(376002)(396003)(346002)(366004)(230922051799003)(64100799003)(1800799012)(186009)(451199024)(38100700002)(7416002)(41300700001)(2906002)(6916009)(5660300002)(54906003)(6486002)(44832011)(36756003)(86362001)(6666004)(6506007)(6512007)(316002)(8676002)(8936002)(4326008)(66946007)(66476007)(66556008)(83380400001)(966005)(26005)(478600001)(2616005)(66899024)(67856001);DIR:OUT;SFP:1101;
X-MS-Exchange-AntiSpam-MessageData-ChunkCount: 1
X-MS-Exchange-AntiSpam-MessageData-0: =?us-ascii?Q?D9wFwcSVZg+zID1cfbn9mAap174Ik85HiXOI92X4RCGvjYSIT+SyVexZLEt7?=
 =?us-ascii?Q?P2lypAGc0WWg0njkc51kRMbztMDjHQhOmBpeF52qlh1IVkPvpg9Mzot+q9c+?=
 =?us-ascii?Q?+uPvlCROm0CTJbFEilFWZtCJvdU+hWbb825xob0gN/4DUUSP84f9NTlqMn4Y?=
 =?us-ascii?Q?heCEcp6ah0jgafGbzzwZ9iziMN6pgjBDG0611fGLdfLqvdhSZotPy148umzx?=
 =?us-ascii?Q?cfMV5SOAsLeylipG0JfHTP92cEJGelFo+dEk7ZJ11H1OKYOfrTw9KttGgaP6?=
 =?us-ascii?Q?td4kQNAX0sa+wSSZgq/WVfK7f6nvTPqAbzlEIThH7cPChy5QYfX96UOm0ZPP?=
 =?us-ascii?Q?fWENK2rJwfh2GmakaU9uiqVEB0YRQ09hnIhz6QT0bqbR2pOSHw2ccRbDQgoV?=
 =?us-ascii?Q?TRt1nKvvAAqAFZh/nyDQpkndEXekxbaFvNYiHfOxr67/Vli1hh8MDy5UNxqD?=
 =?us-ascii?Q?8czyPbLJojmFkypDblzPqKZmdCbslGNp77ruTgoBUqpLbUFQwlyuhfM3xtdQ?=
 =?us-ascii?Q?Hr1Jv9LpHpOcJ1ZmoYqlK5J76bcU+nKgZApU4Ve02VbudxpVt4bAJhEtCmXi?=
 =?us-ascii?Q?IMfSzRcHNHg1sArWkKiJqCnzeWK8nlAn0mV/LI44yh2268/DREku0JUMKp5c?=
 =?us-ascii?Q?D4KPlMPFHRcPVPXFbRJuBAqRV+BIVWEClr/3H6t8PBCO79FboIiWO0gX1ZGL?=
 =?us-ascii?Q?bDz3UTwhLw8bLpWHOXih3Q3fWf9ttH+yDTzh0OmpnNddfoMbhY1rDmk8ojyi?=
 =?us-ascii?Q?ANHcnk6sdD1xPAPGYs0WOD3Bft55JiO0fvTZI/kBH/z2XDnKQ7Dm7Rgkq4rC?=
 =?us-ascii?Q?L6+m6G8RYYfR4dCFXPLfmeScoYC2lEG3cnInAwlBSD5PQKYOXNLUFHUaH9vy?=
 =?us-ascii?Q?2ZMnSGeEaEW9g6HQTOdM8/YI1EVLPwlCRwFnZqhYVN8EogVY1IPB10lT5ZUZ?=
 =?us-ascii?Q?r3cXW1JE94MFl8I1yU0zEdfUNwwC5wx64b0wXYUbeiJAllTgHzAgkPq0NdIH?=
 =?us-ascii?Q?khKxyYEQ2WMqcDtmTgtm2l/LDZVTJdNemu6Ht9EgLMUyI0kLAiMYAVn4GuYh?=
 =?us-ascii?Q?1qs54PA2pEN4EhDKdwKfyydG49cCsOi/g+TMPBV2Ue9UNLIuh8zqIRk28SQ6?=
 =?us-ascii?Q?qMzlDCU71SOkjxuT1l56YB5Sa4gIlZTA9uGoPczFiapZc9cNXOZwXUYqhp80?=
 =?us-ascii?Q?ywQ+zvnoCNZjla3IBx0VreVOTNal+03mzvqrMYZ/hFsrjcITMCccOF4wSAN5?=
 =?us-ascii?Q?EIC6bLUki3uO+fXMUMe8ZNRLvmBdWkQeceFJPwVbjOHXYRxRi+5wtvzE1fUE?=
 =?us-ascii?Q?45jQdxh+F2+Dgg2lyNO4K0kpCcVRlC8x10t9A17hmrn1TbcFUmL3bADcemgu?=
 =?us-ascii?Q?5M+2cIdRxiRQSz1H31tA1xhKAK4v6acJEmnHftuhNWfEFW6CDsvaAdlrkLgQ?=
 =?us-ascii?Q?dizEhgl+cH/RTnBsHww7gIs0frMSs9LQh3yQPkzovfhOfXpGgcbNl+aRtxz/?=
 =?us-ascii?Q?SU9nbIyORm6Sg/f05HGV2qcQSc+oS2pQD30fTfCNkt/z26+e7taD+N5LpFt7?=
 =?us-ascii?Q?vGCBGuEq0dHpkGVvYxp6tUjzidQZ+foczSL0+DoYxGwBftKSwNZu8K98tnIX?=
 =?us-ascii?Q?6Q=3D=3D?=
X-OriginatorOrg: memverge.com
X-MS-Exchange-CrossTenant-Network-Message-Id: 2514978e-f88d-45c2-72ec-08dc106be8c9
X-MS-Exchange-CrossTenant-AuthSource: SJ0PR17MB5512.namprd17.prod.outlook.com
X-MS-Exchange-CrossTenant-AuthAs: Internal
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 08 Jan 2024 17:04:43.4143
 (UTC)
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-CrossTenant-Id: 5c90cb59-37e7-4c81-9c07-00473d5fb682
X-MS-Exchange-CrossTenant-MailboxType: HOSTED
X-MS-Exchange-CrossTenant-UserPrincipalName: 5HebD+YOq+L7dOXn4dnxvi9lkWrXru4NTtmBipAFE/9x+iVkrrSIffcOzrX+dAg/cD8nTYVS+4UILTNPFLClUz67c9xrmbLJWHsvltWeZ60=
X-MS-Exchange-Transport-CrossTenantHeadersStamped: DM8PR17MB4918

On Thu, Jan 04, 2024 at 02:05:01PM +0800, Huang, Ying wrote:
> >
> > From  https://lpc.events/event/16/contributions/1209/attachments/1042/1995/Live%20In%20a%20World%20With%20Multiple%20Memory%20Types.pdf
> > abstract_distance_offset: override by users to deal with firmware issue.
> >
> > say firmware can configure the cxl node into wrong tiers, similar to
> > that it may also configure all cxl nodes into single memtype, hence
> > all these nodes can fall into a single wrong tier.
> > In this case, per node adistance_offset would be good to have ?
> 
> I think that it's better to fix the error firmware if possible.  And
> these are only theoretical, not practical issues.  Do you have some
> practical issues?
> 
> I understand that users may want to move nodes between memory tiers for
> different policy choices.  For that, memory_type based adistance_offset
> should be good.
> 

There's actually an affirmative case to change memory tiering to allow
either movement of nodes between tiers, or at least base placement on
HMAT information. Preferably, membership would be changable to allow
hotplug/DCD to be managed (there's no guarantee that the memory passed
through will always be what HMAT says on initial boot).

https://lore.kernel.org/linux-cxl/CAAYibXjZ0HSCqMrzXGv62cMLncS_81R3e1uNV5Fu4CPm0zAtYw@mail.gmail.com/

This group wants to enable passing CXL memory through to KVM/QEMU
(i.e. host CXL expander memory passed through to the guest), and
allow the guest to apply memory tiering.

There are multiple issues with this, presently:

1. The QEMU CXL virtual device is not and probably never will be
   performant enough to be a commodity class virtualization.  The
   reason is that the virtual CXL device is built off the I/O
   virtualization stack, which treats memory accesses as I/O accesses.

   KVM also seems incompatible with the design of the CXL memory device
   in general, but this problem may or may not be a blocker.

   As a result, access to virtual CXL memory device leads to QEMU
   crawling to a halt - and this is unlikely to change.

   There is presently no good way forward to create a performant virtual
   CXL device in QEMU.  This means the memory tiering component in the
   kernel is functionally useless for virtual CXL memory, because...

2. When passing memory through as an explicit NUMA node, but not as
   part of a CXL memory device, the nodes are lumped together in the
   DRAM tier.

None of this has to do with firmware.

Memory-type is an awful way of denoting membership of a tier, but we
have HMAT information that can be passed through via QEMU:

-object memory-backend-ram,size=4G,id=ram-node0 \
-object memory-backend-ram,size=4G,id=ram-node1 \
-numa node,nodeid=0,cpus=0-4,memdev=ram-node0 \
-numa node,initiator=0,nodeid=1,memdev=ram-node1 \
-numa hmat-lb,initiator=0,target=0,hierarchy=memory,data-type=access-latency,latency=10 \
-numa hmat-lb,initiator=0,target=0,hierarchy=memory,data-type=access-bandwidth,bandwidth=10485760 \
-numa hmat-lb,initiator=0,target=1,hierarchy=memory,data-type=access-latency,latency=20 \
-numa hmat-lb,initiator=0,target=1,hierarchy=memory,data-type=access-bandwidth,bandwidth=5242880

Not only would it be nice if we could change tier membership based on
this data, it's realistically the only way to allow guests to accomplish
memory tiering w/ KVM/QEMU and CXL memory passed through to the guest.

~Gregory

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from mgamail.intel.com (mgamail.intel.com [198.175.65.10])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id D2186DF6C;
	Wed, 10 Jan 2024 06:08:47 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=none dis=none) header.from=intel.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=intel.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=intel.com header.i=@intel.com header.b="grS0AZGh"
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple;
  d=intel.com; i=@intel.com; q=dns/txt; s=Intel;
  t=1704866928; x=1736402928;
  h=from:to:cc:subject:in-reply-to:references:date:
   message-id:mime-version;
  bh=xCUpG7MPuTydGqWkJiwHDdaFqNDHXSJYG5vfi+6flw4=;
  b=grS0AZGhNq8soDcw6nbog9S8KeGUMle8P2BED5TJf+QI7Bbv4pwyINI+
   AhFVbeljHYndWyjl2eZYZMbEHvn55vyagcRpzfcOxLmLdpxmoBRa/Yzxk
   PIjaIdnXJRm+/EJC7iRPQW8e1BtE55jqP8vQOp5lxEHQe21YhmRYq+HU9
   p401qReKBNpTcWfe1MvRheh0Yn4JCcNNoIaY3y0eHzAwVUkF1xRkzUgln
   lHPJVyAQWCRh3XWT8Py2Nwfwawwx8Q7SO7uP3DkXq6sWAxfoRM0OZd4jU
   ZoAOhHXI35eHwkTQjAsXGxKoX9IVTYB4SkXTGJ3qp904K18/c3HRt2rOd
   A==;
X-IronPort-AV: E=McAfee;i="6600,9927,10947"; a="11765306"
X-IronPort-AV: E=Sophos;i="6.04,184,1695711600"; 
   d="scan'208";a="11765306"
Received: from fmsmga004.fm.intel.com ([10.253.24.48])
  by orvoesa102.jf.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 09 Jan 2024 22:08:47 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=McAfee;i="6600,9927,10947"; a="852435366"
X-IronPort-AV: E=Sophos;i="6.04,184,1695711600"; 
   d="scan'208";a="852435366"
Received: from yhuang6-desk2.sh.intel.com (HELO yhuang6-desk2.ccr.corp.intel.com) ([10.238.208.55])
  by fmsmga004-auth.fm.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 09 Jan 2024 22:08:42 -0800
From: "Huang, Ying" <ying.huang@intel.com>
To: Jonathan Cameron <Jonathan.Cameron@Huawei.com>
Cc: Gregory Price <gregory.price@memverge.com>,  Srinivasulu Thanneeru
 <sthanneeru@micron.com>,  Srinivasulu Opensrc
 <sthanneeru.opensrc@micron.com>,  "linux-cxl@vger.kernel.org"
 <linux-cxl@vger.kernel.org>,  "linux-mm@kvack.org" <linux-mm@kvack.org>,
  "aneesh.kumar@linux.ibm.com" <aneesh.kumar@linux.ibm.com>,
  "dan.j.williams@intel.com" <dan.j.williams@intel.com>,  "mhocko@suse.com"
 <mhocko@suse.com>,  "tj@kernel.org" <tj@kernel.org>,
  "john@jagalactic.com" <john@jagalactic.com>,  Eishan Mirakhur
 <emirakhur@micron.com>,  Vinicius Tavares Petrucci
 <vtavarespetr@micron.com>,  Ravis OpenSrc <Ravis.OpenSrc@micron.com>,
  "linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>,  "Johannes
 Weiner" <hannes@cmpxchg.org>,  Wei Xu <weixugc@google.com>,  Hao Xiang
 <hao.xiang@bytedance.com>,  "Ho-Ren (Jack) Chuang"
 <horenchuang@bytedance.com>
Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
In-Reply-To: <20240109155049.00003f13@Huawei.com> (Jonathan Cameron's message
	of "Tue, 9 Jan 2024 15:50:49 +0000")
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
	<87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZXyQIJOim1+tE0Qr@memverge.com>
	<87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87wmspbpma.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZZwrIoP9+ey7rp3C@memverge.com>
	<87o7dv897s.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<20240109155049.00003f13@Huawei.com>
Date: Wed, 10 Jan 2024 14:06:44 +0800
Message-ID: <874jfl90y3.fsf@yhuang6-desk2.ccr.corp.intel.com>
User-Agent: Gnus/5.13 (Gnus v5.13)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Type: text/plain; charset=ascii

Jonathan Cameron <Jonathan.Cameron@Huawei.com> writes:

> On Tue, 09 Jan 2024 11:41:11 +0800
> "Huang, Ying" <ying.huang@intel.com> wrote:
>
>> Gregory Price <gregory.price@memverge.com> writes:
>> 
>> > On Thu, Jan 04, 2024 at 02:05:01PM +0800, Huang, Ying wrote:  
>> >> >
>> >> > From  https://lpc.events/event/16/contributions/1209/attachments/1042/1995/Live%20In%20a%20World%20With%20Multiple%20Memory%20Types.pdf
>> >> > abstract_distance_offset: override by users to deal with firmware issue.
>> >> >
>> >> > say firmware can configure the cxl node into wrong tiers, similar to
>> >> > that it may also configure all cxl nodes into single memtype, hence
>> >> > all these nodes can fall into a single wrong tier.
>> >> > In this case, per node adistance_offset would be good to have ?  
>> >> 
>> >> I think that it's better to fix the error firmware if possible.  And
>> >> these are only theoretical, not practical issues.  Do you have some
>> >> practical issues?
>> >> 
>> >> I understand that users may want to move nodes between memory tiers for
>> >> different policy choices.  For that, memory_type based adistance_offset
>> >> should be good.
>> >>   
>> >
>> > There's actually an affirmative case to change memory tiering to allow
>> > either movement of nodes between tiers, or at least base placement on
>> > HMAT information. Preferably, membership would be changable to allow
>> > hotplug/DCD to be managed (there's no guarantee that the memory passed
>> > through will always be what HMAT says on initial boot).  
>> 
>> IIUC, from Jonathan Cameron as below, the performance of memory
>> shouldn't change even for DCD devices.
>> 
>> https://lore.kernel.org/linux-mm/20231103141636.000007e4@Huawei.com/
>> 
>> It's possible to change the performance of a NUMA node changed, if we
>> hot-remove a memory device, then hot-add another different memory
>> device.  It's hoped that the CDAT changes too.
>
> Not supported, but ACPI has _HMA methods to in theory allow changing
> HMAT values based on firmware notifications...  So we 'could' make
> it work for HMAT based description.
>
> Ultimately my current thinking is we'll end up emulating CXL type3
> devices (hiding topology complexity) and you can update CDAT but
> IIRC that is only meant to be for degraded situations - so if you
> want multiple performance regions, CDAT should describe them form the start.

Thank you very much for input!  So, to support degraded performance, we
will need to move a NUMA node between memory tiers.  And, per my
understanding, we should do that in kernel.

>> 
>> So, all in all, HMAT + CDAT can help us to put the memory device in
>> appropriate memory tiers.  Now, we have HMAT support in upstream.  We
>> will working on CDAT support.
>> 

--
Best Regards,
Huang, Ying

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from NAM04-BN8-obe.outbound.protection.outlook.com (mail-bn8nam04on2071.outbound.protection.outlook.com [40.107.100.71])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 9BA9A3C060;
	Tue,  9 Jan 2024 17:59:34 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=none dis=none) header.from=memverge.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=memverge.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (1024-bit key) header.d=memverge.com header.i=@memverge.com header.b="jdmNhfEG"
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=Qe1usf59KUTxzzKmsKdUJ7jw4+OyQgt1tyoxcvFd9fx+WtGzRj58/x1M+KbYk6Ekd+laFOhmFh193gjyJrCL6AEENBKrEWh/KWSFkRmrB3SqlRRVhw/KlwW4M//uDo1nPqqdNFZz5n/tuw9HGhh+va9rMi1RTGuO036Gxre2Pma+Vw1umgYLPFWuuDpPqILH8LTK98mfVF9uudbH9uPhd1Q7x/ZnqZVZ1wH64FV4yZNma7YMd0AWj8NH5neUeWUFVcSqXTRt/vT3t/xKLNdG/d/C4VhXgEn+Zxb/A/eIcdHaf8967YGPXf0Lw3UgfEJVId3JSo3dhEJV1yEKTBiB1A==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-AntiSpam-MessageData-ChunkCount:X-MS-Exchange-AntiSpam-MessageData-0:X-MS-Exchange-AntiSpam-MessageData-1;
 bh=QAjw8+Pl+ElblBN6Rrx18mNcttVZa5dtvaWcsS4/0UE=;
 b=KHl/pqr42ErlfA3lfhDLkvJgx1EwH6JnzqzNEIN/gTM0ILM/L/GIal2lKTzQZTPaj6TdoQd1DldbYCE+znN6A8e3gJK0xxygSNEHRQ5UTG/PheN7eJsBZmlGquwRpX6/URRn0n9uVoSqvg7qqJmZYVnAlJjD6CR+Oleqq0GvtorMXw75KM+oVWUzlmMhr/rGF0w7DbYZUXgWV5g21bdETM4D2FiLAUID9chKA/YnG4RbC1OR1HTC/Yp9/vlcV9UPg3+6aChmw1WGAtnvonk0mayBE8Smb2PSdCqCXAzVizkClITMG6NlZnQPdYp1fVQ1SSHzFuTIRVMPjdVeQAYS1w==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass
 smtp.mailfrom=memverge.com; dmarc=pass action=none header.from=memverge.com;
 dkim=pass header.d=memverge.com; arc=none
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=memverge.com;
 s=selector2;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=QAjw8+Pl+ElblBN6Rrx18mNcttVZa5dtvaWcsS4/0UE=;
 b=jdmNhfEGltuzdSFQi8g0AgTz+qROwCqA/MCHf2+fSdHcpWULGfSaNqPtMH75bAjvkSE9vauHhimLBej8dXY+J84VLQPVrP29y7XHGOHqvEg0jh9aaul2jerf2GegWRcdmfnG5mEpXxD/yIgUipb4r5t2FwaCk32LCcZW20TsP1A=
Authentication-Results: dkim=none (message not signed)
 header.d=none;dmarc=none action=none header.from=memverge.com;
Received: from SJ0PR17MB5512.namprd17.prod.outlook.com (2603:10b6:a03:394::19)
 by MW4PR17MB4434.namprd17.prod.outlook.com (2603:10b6:303:73::24) with
 Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.7159.23; Tue, 9 Jan
 2024 17:59:30 +0000
Received: from SJ0PR17MB5512.namprd17.prod.outlook.com
 ([fe80::7a04:dc86:2799:2f15]) by SJ0PR17MB5512.namprd17.prod.outlook.com
 ([fe80::7a04:dc86:2799:2f15%5]) with mapi id 15.20.7159.020; Tue, 9 Jan 2024
 17:59:30 +0000
Date: Tue, 9 Jan 2024 12:59:19 -0500
From: Gregory Price <gregory.price@memverge.com>
To: Jonathan Cameron <Jonathan.Cameron@huawei.com>
Cc: "Huang, Ying" <ying.huang@intel.com>,
	Srinivasulu Thanneeru <sthanneeru@micron.com>,
	Srinivasulu Opensrc <sthanneeru.opensrc@micron.com>,
	"linux-cxl@vger.kernel.org" <linux-cxl@vger.kernel.org>,
	"linux-mm@kvack.org" <linux-mm@kvack.org>,
	"aneesh.kumar@linux.ibm.com" <aneesh.kumar@linux.ibm.com>,
	"dan.j.williams@intel.com" <dan.j.williams@intel.com>,
	"mhocko@suse.com" <mhocko@suse.com>,
	"tj@kernel.org" <tj@kernel.org>,
	"john@jagalactic.com" <john@jagalactic.com>,
	Eishan Mirakhur <emirakhur@micron.com>,
	Vinicius Tavares Petrucci <vtavarespetr@micron.com>,
	Ravis OpenSrc <Ravis.OpenSrc@micron.com>,
	"linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>,
	Johannes Weiner <hannes@cmpxchg.org>, Wei Xu <weixugc@google.com>,
	Hao Xiang <hao.xiang@bytedance.com>,
	"Ho-Ren (Jack) Chuang" <horenchuang@bytedance.com>
Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
Message-ID: <ZZ2Jd7/7rFD0o5S3@memverge.com>
References: <87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
 <PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
 <PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com>
 <PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87wmspbpma.fsf@yhuang6-desk2.ccr.corp.intel.com>
 <ZZwrIoP9+ey7rp3C@memverge.com>
 <87o7dv897s.fsf@yhuang6-desk2.ccr.corp.intel.com>
 <20240109155049.00003f13@Huawei.com>
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <20240109155049.00003f13@Huawei.com>
X-ClientProxiedBy: BY5PR13CA0034.namprd13.prod.outlook.com
 (2603:10b6:a03:180::47) To SJ0PR17MB5512.namprd17.prod.outlook.com
 (2603:10b6:a03:394::19)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
X-MS-PublicTrafficType: Email
X-MS-TrafficTypeDiagnostic: SJ0PR17MB5512:EE_|MW4PR17MB4434:EE_
X-MS-Office365-Filtering-Correlation-Id: d4976895-2d91-45ff-e6c7-08dc113cba7a
X-MS-Exchange-SenderADCheck: 1
X-MS-Exchange-AntiSpam-Relay: 0
X-Microsoft-Antispam: BCL:0;
X-Microsoft-Antispam-Message-Info: iN5jZyAvUDaAUVlFb8Au9f4BpiE7WIMo/rfiPaG2mnMQ769re2a23x3M/A+xG6X4BsLMZ2RExLLSASxvQGP2fZ9ayqnpDyB7qEMIBce8XOOYYofsg02MGL07b3gAAqLgsg97AaVErjB1g8hR7M58sPsay72toaPWynPip7ACU9ZUrEdoXR8suwuVAaYUWF1oO94faJg7CcNL149ErGodeTE7FD1aJ69Kd9YFOriXW10k0Pzib/puXHNQ1hI2YDhaX8CK45/CICqDb7zuQIDNVNF+EXnJN80+5dxvzcRWbHfcHZ+1ySv2u369w8Cjvo7VOJLlOeYTk79eoYpjVDos5bZrMhAfQDXR7Lrd81+3eRJUQgOsXUhmt57hg2Tita2lsickoi14znBao0/O55K0ZdBrGJYwzyedgJr7V7LZ9dL6sAruOIxCzIzL0FRrFdlIZhCkG2RUX6QvIgbgItvYCkRju5mhU0EJdu+uTH8QmoODMHjGU/Y/PYSMjxB9Id5n+WpoEEWIXRapi7xuxcHb0wnl96Qh1l8vWQ09SP6YjY0=
X-Forefront-Antispam-Report: CIP:255.255.255.255;CTRY:;LANG:en;SCL:1;SRV:;IPV:NLI;SFV:NSPM;H:SJ0PR17MB5512.namprd17.prod.outlook.com;PTR:;CAT:NONE;SFS:(13230031)(346002)(39850400004)(376002)(366004)(136003)(396003)(230922051799003)(451199024)(1800799012)(64100799003)(186009)(7416002)(5660300002)(478600001)(966005)(6666004)(6512007)(6486002)(6506007)(86362001)(8936002)(36756003)(41300700001)(66946007)(8676002)(66556008)(2616005)(66476007)(316002)(54906003)(6916009)(38100700002)(83380400001)(26005)(4326008)(44832011)(2906002);DIR:OUT;SFP:1101;
X-MS-Exchange-AntiSpam-MessageData-ChunkCount: 1
X-MS-Exchange-AntiSpam-MessageData-0: =?us-ascii?Q?cUBRSKXzcbV3pVdbHwaIp/7apsDl/uadP26K03gnu+uTv+APQRM0e8Xe5Kq7?=
 =?us-ascii?Q?qbNwuUSJjWg+PAZlW1mWiCvDJfinHwpUcGZQ76clsfKBloyT8V0l3tMYXqY6?=
 =?us-ascii?Q?qh46Eenatd9ivc2RA9C7bdcYLRlWheyhvipi/JRH+JBKwVP/Liw/h1eL7x+i?=
 =?us-ascii?Q?I2lg9gddnU5M/jYMfYB5CcBxFScQKKPXmzL80M8z41FhowJFWO+RKKTVMCXK?=
 =?us-ascii?Q?d+W9v4Y//vH90YPukeyyQ+CMK/RW09OhcCL/5NzNr53pwEv3JQN1P8OWXmCn?=
 =?us-ascii?Q?K6fZx7YRikbUW2Nwy8oJERe7Mxr0MHwQcCyi/UTLepAmT8vYbHlvH/2dzzQ4?=
 =?us-ascii?Q?zyH221ybJLF0QOahfX1LgVCn/SUp+c8SmQ69v+iSD80502AcSSTlGCfC1JIe?=
 =?us-ascii?Q?Vbr++PC2RwrQhULrzWuvyiCBdQ+bt99L/2wBjB20ZXIZYhQ2yuWUIRlixRnF?=
 =?us-ascii?Q?ETFsb29rEbMgYYS2/GnHPAHg8glqiquq68qzWh2jPdhRRGmZQ38ZszUGy+JH?=
 =?us-ascii?Q?dJ0RSW3bkrTTNT7baVXI+T1dYEOv7+3O4t/H1SRQzZoms+emeVlmLjtMhf83?=
 =?us-ascii?Q?Ku4tMpKtkXVtbbpED/AgVwrSARfX6l64S+AWn6lDaJyEOyXbJyIDhFafRXm3?=
 =?us-ascii?Q?LQWtuiVV4kd1Gwf035BCK98FtSphx3iH/wjFb8seRtF7tE1ZAJ296vJMpBtN?=
 =?us-ascii?Q?VD4X9oetF2COm5PmcW41+GAqahPQiyU7xNbAbg2ENh0SMHNQW8+8uV0CfEN6?=
 =?us-ascii?Q?7k70aMVPp0trFCY5OH9kSCvLMuyzPCuZXLzBzQCJnaBcIpSiDrfnE5sGfzS2?=
 =?us-ascii?Q?zRLnApjWnZYhK028wHV48MLM44sukt5VVBU1x78RG6NxplsZfH8RUkhtr5Jn?=
 =?us-ascii?Q?YxjwArL4VEqdXrjFdtAEr/xDfga4jyxSwlKLyVxWs8VF1onIBobzX/eAaH/F?=
 =?us-ascii?Q?FYD/czIURBsozu+8oM0QZ/dl6egPm8B8c2WoVdysRpFXdZNHaqk14lRfrB5X?=
 =?us-ascii?Q?XT1QblB4V0mJkjaJlN3I9NCfKU0hRluzFKH/c9DxThLSiSDc2CyEVB10RkDO?=
 =?us-ascii?Q?wh1ldi/7zc2bNUw9pcRz/ACaE2LrlMhl0gZU8uUudKTomMqABRstylavXUc9?=
 =?us-ascii?Q?N4fjDuFWrbtQTz3o5tohjSWKbOV5LDLHJlnTWeZP5Pn6K0e4qQUbv+S3ldMZ?=
 =?us-ascii?Q?eLAdmInkrUaCt3lqAAWgD3Oltn9c5B4tjKKr5hllASYqvUlMkJRVmfehEgFA?=
 =?us-ascii?Q?CaP15btpRRhlVqg9SJ0Rm9vZZY3xL4S6ionlgf+09Y6jdILMnuGBHk64PXdk?=
 =?us-ascii?Q?NstJ7kFDLHl+JuUEzXnQowRW5wFe/v9/nuqAXpL91y0JiAjg2bidFb/g2UcI?=
 =?us-ascii?Q?/2bYat7dYd9kfHQkBFSgUs9+qS2lwoGDHGYa8HOg6ofQh+5r8+Lg1zszb+61?=
 =?us-ascii?Q?y7UV+U5qb22vymHHGMLU2IwhLBklMbgX9XySqBsUL3i1p/ASKPOhWogV7iO/?=
 =?us-ascii?Q?8/wYYY5fimq/PnuHei573jcyTUPNjVir/9zu9girqLeBoSpvJlDmmN/wlmhp?=
 =?us-ascii?Q?0FRTke8bGSDEbqmOxaUUXHtSZfBSZ7vAHPNrx+sDt5vA2inTbch7ZCvJUsiT?=
 =?us-ascii?Q?Ig=3D=3D?=
X-OriginatorOrg: memverge.com
X-MS-Exchange-CrossTenant-Network-Message-Id: d4976895-2d91-45ff-e6c7-08dc113cba7a
X-MS-Exchange-CrossTenant-AuthSource: SJ0PR17MB5512.namprd17.prod.outlook.com
X-MS-Exchange-CrossTenant-AuthAs: Internal
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 09 Jan 2024 17:59:30.6244
 (UTC)
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-CrossTenant-Id: 5c90cb59-37e7-4c81-9c07-00473d5fb682
X-MS-Exchange-CrossTenant-MailboxType: HOSTED
X-MS-Exchange-CrossTenant-UserPrincipalName: H28jusB0ICSdlAcV0x5Bq1GaAicB7JG0y1P6hrOoDmp0PzWtcJaf2YeVL5yvl4SQFagS/vMh+B80A5zwS7+dkb+Iis+BFSlGc4HipcYS9AY=
X-MS-Exchange-Transport-CrossTenantHeadersStamped: MW4PR17MB4434

On Tue, Jan 09, 2024 at 03:50:49PM +0000, Jonathan Cameron wrote:
> On Tue, 09 Jan 2024 11:41:11 +0800
> "Huang, Ying" <ying.huang@intel.com> wrote:
> > Gregory Price <gregory.price@memverge.com> writes:
> > > On Thu, Jan 04, 2024 at 02:05:01PM +0800, Huang, Ying wrote:  
> > It's possible to change the performance of a NUMA node changed, if we
> > hot-remove a memory device, then hot-add another different memory
> > device.  It's hoped that the CDAT changes too.
> 
> Not supported, but ACPI has _HMA methods to in theory allow changing
> HMAT values based on firmware notifications...  So we 'could' make
> it work for HMAT based description.
> 
> Ultimately my current thinking is we'll end up emulating CXL type3
> devices (hiding topology complexity) and you can update CDAT but
> IIRC that is only meant to be for degraded situations - so if you
> want multiple performance regions, CDAT should describe them form the start.
> 

That was my thought.  I don't think it's particularly *realistic* for
HMAT/CDAT values to change at runtime, but I can imagine a case where
it could be valuable.

> > > https://lore.kernel.org/linux-cxl/CAAYibXjZ0HSCqMrzXGv62cMLncS_81R3e1uNV5Fu4CPm0zAtYw@mail.gmail.com/
> > >
> > > This group wants to enable passing CXL memory through to KVM/QEMU
> > > (i.e. host CXL expander memory passed through to the guest), and
> > > allow the guest to apply memory tiering.
> > >
> > > There are multiple issues with this, presently:
> > >
> > > 1. The QEMU CXL virtual device is not and probably never will be
> > >    performant enough to be a commodity class virtualization.
> 
> I'd flex that a bit - we will end up with a solution for virtualization but
> it isn't the emulation that is there today because it's not possible to
> emulate some of the topology in a peformant manner (interleaving with sub
> page granularity / interleaving at all (to a lesser degree)). There are
> ways to do better than we are today, but they start to look like
> software dissagregated memory setups (think lots of page faults in the host).
>

Agreed, the emulated device as-is can't be the virtualization device,
but it doesn't mean it can't be the basis for it.

My thought is, if you want to pass host CXL *memory* through to the
guest, you don't actually care to pass CXL *control* through to the
guest.  That control lies pretty squarely with the host/hypervisor.

So, at least in theory, you can just cut the type3 device out of the
QEMU configuration entirely and just pass it through as a distinct numa
node with specific hmat qualities.

Barring that, if we must go through the type3 device, the question is
how difficult would it be to just make a stripped down type3 device
to provide the informational components, but hack off anything
topology/interleave related? Then you just do direct passthrough as you
described below.

qemu/kvm would report errors if you tried to touch the naughty bits.

The second question is... is that device "compliant" or does it need
super special handling from the kernel driver :D?  If what i described
is not "compliant", then it's probably a bad idea, and KVM/QEMU should
just hide the CXL device entirely from the guest (for this use case)
and just pass the memory through as a numa node.

Which gets us back to: The memory-tiering component needs a way to
place nodes in different tiers based on HMAT/CDAT/User Whim. All three
of those seem like totally valid ways to go about it.

> > >
> > > 2. When passing memory through as an explicit NUMA node, but not as
> > >    part of a CXL memory device, the nodes are lumped together in the
> > >    DRAM tier.
> > >
> > > None of this has to do with firmware.
> > >
> > > Memory-type is an awful way of denoting membership of a tier, but we
> > > have HMAT information that can be passed through via QEMU:
> > >
> > > -object memory-backend-ram,size=4G,id=ram-node0 \
> > > -object memory-backend-ram,size=4G,id=ram-node1 \
> > > -numa node,nodeid=0,cpus=0-4,memdev=ram-node0 \
> > > -numa node,initiator=0,nodeid=1,memdev=ram-node1 \
> > > -numa hmat-lb,initiator=0,target=0,hierarchy=memory,data-type=access-latency,latency=10 \
> > > -numa hmat-lb,initiator=0,target=0,hierarchy=memory,data-type=access-bandwidth,bandwidth=10485760 \
> > > -numa hmat-lb,initiator=0,target=1,hierarchy=memory,data-type=access-latency,latency=20 \
> > > -numa hmat-lb,initiator=0,target=1,hierarchy=memory,data-type=access-bandwidth,bandwidth=5242880
> > >
> > > Not only would it be nice if we could change tier membership based on
> > > this data, it's realistically the only way to allow guests to accomplish
> > > memory tiering w/ KVM/QEMU and CXL memory passed through to the guest.
> 
> This I fully agree with.  There will be systems with a bunch of normal DDR with different
> access characteristics irrespective of CXL. + likely HMAT solutions will be used
> before we get anything more complex in place for CXL.
> 

Had not even considered this, but that's completely accurate as well.

And more discretely: What of devices that don't provide HMAT/CDAT? That
isn't necessarily a violation of any standard.  There probably could be
a release valve for us to still make those devices useful.

The concern I have with not implementing a movement mechanism *at all*
is that a one-size-fits-all initial-placement heuristic feels gross
when we're, at least ideologically, moving toward "software defined memory".

Personally I think the movement mechanism is a good idea that gets folks
where they're going sooner, and it doesn't hurt anything by existing. We
can change the initial placement mechanism too.

</2cents>

~Gregory

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from NAM11-DM6-obe.outbound.protection.outlook.com (mail-dm6nam11on2068.outbound.protection.outlook.com [40.107.223.68])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 9928739FF2;
	Tue,  9 Jan 2024 17:34:33 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=none dis=none) header.from=memverge.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=memverge.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (1024-bit key) header.d=memverge.com header.i=@memverge.com header.b="UL4FxFcw"
ARC-Seal: i=1; a=rsa-sha256; s=arcselector9901; d=microsoft.com; cv=none;
 b=POYMTdYb8hFknrjVmvPlX6puFWQrQxG1AA5X/Hq878aRrV8FHsgNueG7BQlkRGmnCrAckTqFqygYE5RZeYtftN3xG7Jq3Qu2KHEAp6bLHWiO5oXWhaNapQ59ldtiabP3O34zsyfYjF4mKSpMe7hITEJUgKPqi7se7N9rUgctWu2QHaggSoQM/bIvfnir4AyV21K/LY5W35NNI35hsH7U8vReSMCRZ6q1DMLXMibqC5TMQgM3apjjzVSh0sphNyqmC4S3Hq+ngCEMkrFVoOwIZ78IvWNbgP7uTLVGrNot/DTsgRPDtsLTW544CSlvmPFTyTRshFjQb4hwIdOeC+8jIg==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=microsoft.com;
 s=arcselector9901;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-AntiSpam-MessageData-ChunkCount:X-MS-Exchange-AntiSpam-MessageData-0:X-MS-Exchange-AntiSpam-MessageData-1;
 bh=MjOuvY7UBb25gmCYkb2hCJsWlb7DInLEbKRdAfFxVqw=;
 b=FWdwrER5qXiUPad/uX89h62EtuNZroVxm/XiOZU2d6YBuP42Yyq606rWkJzOufBq3sr1MOPCLgTTYpFR3s/QlPO+o+kUOWMr9Ky4sEMDP5NOIF0FfvouktWtBzIIIRLFX3fi+VpW73unuGK3KvFTSHe0ugsIrz4hHdUVg/+gDM9uulmVn5WT6soWEv1Q++7h2vsfDwTToX3MgVKgJT8kE3ZJHmkmq/7bNqBCF3W1NDwRCSV3fOzsJvpdrz5EOtv0nISmPjF6pErf4/DCjg1PIoCwQL+86apSdo6jwYQiO2iWbjsQFaPNenG2PTboIoVuRwqh7e5/6bkVM5ElTFZJAQ==
ARC-Authentication-Results: i=1; mx.microsoft.com 1; spf=pass
 smtp.mailfrom=memverge.com; dmarc=pass action=none header.from=memverge.com;
 dkim=pass header.d=memverge.com; arc=none
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=memverge.com;
 s=selector2;
 h=From:Date:Subject:Message-ID:Content-Type:MIME-Version:X-MS-Exchange-SenderADCheck;
 bh=MjOuvY7UBb25gmCYkb2hCJsWlb7DInLEbKRdAfFxVqw=;
 b=UL4FxFcw6JUsh4sR+i4GSe6gUiWFJtizBt9TUof+6Csb8iTHmdZFtzNyYfulPPtACuSEMjzixYY0MbooBwN1gXCiS2UdPh7p8QZMVcWPiXAwJ+gMKZ4B8v7wSwiRlhrdp36jZoYSpBrgjT1foZitmrj+7dPoj7u9AB0gOTt0QLE=
Authentication-Results: dkim=none (message not signed)
 header.d=none;dmarc=none action=none header.from=memverge.com;
Received: from SJ0PR17MB5512.namprd17.prod.outlook.com (2603:10b6:a03:394::19)
 by SJ0PR17MB4631.namprd17.prod.outlook.com (2603:10b6:a03:374::9) with
 Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384) id 15.20.7159.23; Tue, 9 Jan
 2024 17:34:28 +0000
Received: from SJ0PR17MB5512.namprd17.prod.outlook.com
 ([fe80::7a04:dc86:2799:2f15]) by SJ0PR17MB5512.namprd17.prod.outlook.com
 ([fe80::7a04:dc86:2799:2f15%5]) with mapi id 15.20.7159.020; Tue, 9 Jan 2024
 17:34:28 +0000
Date: Tue, 9 Jan 2024 12:34:24 -0500
From: Gregory Price <gregory.price@memverge.com>
To: "Huang, Ying" <ying.huang@intel.com>
Cc: Srinivasulu Thanneeru <sthanneeru@micron.com>,
	Srinivasulu Opensrc <sthanneeru.opensrc@micron.com>,
	"linux-cxl@vger.kernel.org" <linux-cxl@vger.kernel.org>,
	"linux-mm@kvack.org" <linux-mm@kvack.org>,
	"aneesh.kumar@linux.ibm.com" <aneesh.kumar@linux.ibm.com>,
	"dan.j.williams@intel.com" <dan.j.williams@intel.com>,
	"mhocko@suse.com" <mhocko@suse.com>,
	"tj@kernel.org" <tj@kernel.org>,
	"john@jagalactic.com" <john@jagalactic.com>,
	Eishan Mirakhur <emirakhur@micron.com>,
	Vinicius Tavares Petrucci <vtavarespetr@micron.com>,
	Ravis OpenSrc <Ravis.OpenSrc@micron.com>,
	"Jonathan.Cameron@huawei.com" <Jonathan.Cameron@huawei.com>,
	"linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>,
	Johannes Weiner <hannes@cmpxchg.org>, Wei Xu <weixugc@google.com>,
	Hao Xiang <hao.xiang@bytedance.com>,
	"Ho-Ren (Jack) Chuang" <horenchuang@bytedance.com>
Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
Message-ID: <ZZ2DoPT8LzNzXyme@memverge.com>
References: <ZXyQIJOim1+tE0Qr@memverge.com>
 <87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
 <PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
 <PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com>
 <PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87wmspbpma.fsf@yhuang6-desk2.ccr.corp.intel.com>
 <ZZwrIoP9+ey7rp3C@memverge.com>
 <87o7dv897s.fsf@yhuang6-desk2.ccr.corp.intel.com>
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline
In-Reply-To: <87o7dv897s.fsf@yhuang6-desk2.ccr.corp.intel.com>
X-ClientProxiedBy: BYAPR08CA0005.namprd08.prod.outlook.com
 (2603:10b6:a03:100::18) To SJ0PR17MB5512.namprd17.prod.outlook.com
 (2603:10b6:a03:394::19)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
X-MS-PublicTrafficType: Email
X-MS-TrafficTypeDiagnostic: SJ0PR17MB5512:EE_|SJ0PR17MB4631:EE_
X-MS-Office365-Filtering-Correlation-Id: 718b7cbf-197d-487b-216d-08dc11393b38
X-MS-Exchange-SenderADCheck: 1
X-MS-Exchange-AntiSpam-Relay: 0
X-Microsoft-Antispam: BCL:0;
X-Microsoft-Antispam-Message-Info: vZN28pkpuhmJ4jyNt5W6DAjrXyczgwEA2sZLpzpgh45G77HTw/Tho90wKnxx6d1cJOMtP9cMdj+OflGEgfhLa0CLpsTPu6aI+av4fzkdY5fx30lrhPiHKGyHNN1HYXdV8hJj2sW3/rS53yK0dQJvs644ZP5YICzN//m0jL2ARhrrkXS2n7fCHAidIMRqsvVEmwQMMMDk6vl/b6sPSDglZg04QbnjrRD2CD6Au4hwEEmItQwDET36TVJxNHWnCuTzhL6XWK1DMk2bN493qRjtcoT5T1DSNYePIUjIzjCM0kc6lEKGye3Z3VrAEcCIDtDCeJxg0wZDH0VzRisGKzwhiO9FdOiwNFweiyVkvWW3paZegLQHCCpWLRh0FQPO7v//CTGZ7quGxOMvFVboyQrY+6TmvcWNsNYZXebrmoQzJYtbjTWIq7fnItfRLVTwdeMdtoS//7gcV7vTA3Y9RJzaJ9Ms3of5TAZ1TgKkK6KJqagxAIxVEhx4PwUI08hgYSaRJadvFxcKgiDCzL0W04+dKW+3yXyp3ssiPJyOUyiCDeE=
X-Forefront-Antispam-Report: CIP:255.255.255.255;CTRY:;LANG:en;SCL:1;SRV:;IPV:NLI;SFV:NSPM;H:SJ0PR17MB5512.namprd17.prod.outlook.com;PTR:;CAT:NONE;SFS:(13230031)(376002)(396003)(346002)(366004)(39840400004)(136003)(230922051799003)(186009)(451199024)(64100799003)(1800799012)(66946007)(66556008)(66476007)(316002)(4326008)(8676002)(8936002)(478600001)(26005)(66899024)(2616005)(83380400001)(966005)(2906002)(5660300002)(7416002)(41300700001)(38100700002)(6916009)(86362001)(6666004)(6506007)(6512007)(6486002)(54906003)(44832011)(36756003);DIR:OUT;SFP:1101;
X-MS-Exchange-AntiSpam-MessageData-ChunkCount: 1
X-MS-Exchange-AntiSpam-MessageData-0: =?us-ascii?Q?l593e5e8+m1zaNVUffG5jI/KfHq6r1572WN1s9IflGSmrSrRy5rP6tO/49oI?=
 =?us-ascii?Q?mOEVph1Mkmz4a0P0tj13iHXtcuXj5lb/4X/7AjhNP9fqhDALxGdX96I7kBKg?=
 =?us-ascii?Q?l+XL31VVGQKqNuMLBVCO35I+CqL8hc3M5dfMY5Uu4DGk0OIdmYbR8jXmIuWk?=
 =?us-ascii?Q?+Y1/Ymg5YXRJlRb2a1XIu0M7GZhhr1l55yYwADPTbkJevzqwGPfvZbzxikF2?=
 =?us-ascii?Q?c6jccY62zrKK/DTHg77O5HBv2Kz08G1K6W015XI3nPknEsxVZwn36BDwjQxT?=
 =?us-ascii?Q?yqRbXxTNwuXzcflwptJME6Kp7tsqvsRRFv6r6yJy3OQj65HDFZoLfn2qWahV?=
 =?us-ascii?Q?G4fvmnOIRTYMkNMU03kbIOJH8OhfYyqNgaGZ3Fs4nhOUWDY/DYVXIynPsEAs?=
 =?us-ascii?Q?Q++ixbqr3x0qt9fFxYrhpMZFkrrzl1NxmGnsBvmgAbvCwCD8i4q2jLSbaZvJ?=
 =?us-ascii?Q?4zwBrheIJZqbFX6N2xJrU0CRUy1U93X+DcCCIi7xJQY7gXuNKB/3N8ommdvj?=
 =?us-ascii?Q?zzWznvhUqhN0X3HrynY6FG26tauqeQ58AVYh7lC2XhLO+oEbweIbM5DjGQBT?=
 =?us-ascii?Q?cLO7Ce/CnZWieVcS1q+sPrrqBBhASkLBnfrM7FVMkcwejxYTOu5KaHI0YTlN?=
 =?us-ascii?Q?VN4EEcebs6zSequ0d7vRn0jZ6rBNhaq41vKQ3JjIrd92FiDqh5d4Moqa6sbj?=
 =?us-ascii?Q?UQ+YRbkeT0qB+BY9N4oZg47z6PKCP8putfa+7SKf/cxQQHwVLEnnMoIbqzEu?=
 =?us-ascii?Q?nrwAWaJv7JBNTLFExLTi/5alejnKr3N33g1nQ4vXQIymEsl8pKWFPc+4NQAF?=
 =?us-ascii?Q?mKPVwNCrq1ryKodSKXhX+2dxbOC9fiK1UuaAD6Hl/y8Ir9kAQYFmE2Stqyde?=
 =?us-ascii?Q?5wM8YJTqed75g7vD4MMO4nZIrPbHjDwkHSeOIEdN8r3+keu93Ek4gS4yBzXP?=
 =?us-ascii?Q?XbJT8XLMnDYdSusGGdmLLDwo1Pk0QsbX6ZrTVvFg3SqakBecLhq4xwnmpYfa?=
 =?us-ascii?Q?Corg1kJLAibFH92yu0solxep/ve3Q/2l9twAjOS7vNS27Tq9fOuMgwph5KYP?=
 =?us-ascii?Q?2iH6XqfSIJEZS4PCDRUydJmK8VzKd0yCpq1YWumlVjqdVbcXne1+pTTZT7Gy?=
 =?us-ascii?Q?4WfEKIsMINRnvzOjTqpjGUMam2vSEb6LxOj9csQy5OvGb8t1oQ5RtnY9DDOh?=
 =?us-ascii?Q?aJQ9D7MPt/M71Cp4ysQpya++mabqFepT3zmgAIgqMzketMKwNqTpOCJTRKny?=
 =?us-ascii?Q?ltnFnBJ6iEZETK8WKmZdnIt3BYbKoeif3Opy4IKBrF/ikv04dR6NABvE+n6Y?=
 =?us-ascii?Q?jDevoyw0IvvX1zayrNoqNOlG0WzjKl0ul+JMjPd4inkbVYgBiKwF1w8fbCDR?=
 =?us-ascii?Q?vd1qHKJnYmHUqMIVtSb6z3Lphe+jfm1woio0vKG5GLsepmJuQdXKX9HkwNL1?=
 =?us-ascii?Q?1RhgA1YxK02+c+yAc8/HoJchOwCglbPfEB0SZLW4J4aunHBHtqjipTsOhld0?=
 =?us-ascii?Q?5w2/NNCv0Yw8QicKWC+5yKT/ApjNigwIvUkeMrng78vRAwOnQwk7AruwfjP+?=
 =?us-ascii?Q?83WT5nVfcppv7znJuLt+Qgr0mdwKXRLI1lQgMvSdto//QUrftuIuqodbOkfk?=
 =?us-ascii?Q?0A=3D=3D?=
X-OriginatorOrg: memverge.com
X-MS-Exchange-CrossTenant-Network-Message-Id: 718b7cbf-197d-487b-216d-08dc11393b38
X-MS-Exchange-CrossTenant-AuthSource: SJ0PR17MB5512.namprd17.prod.outlook.com
X-MS-Exchange-CrossTenant-AuthAs: Internal
X-MS-Exchange-CrossTenant-OriginalArrivalTime: 09 Jan 2024 17:34:28.6214
 (UTC)
X-MS-Exchange-CrossTenant-FromEntityHeader: Hosted
X-MS-Exchange-CrossTenant-Id: 5c90cb59-37e7-4c81-9c07-00473d5fb682
X-MS-Exchange-CrossTenant-MailboxType: HOSTED
X-MS-Exchange-CrossTenant-UserPrincipalName: fR8uuaP79JKAtxBuJRB4y3jcxxaISCpbvaMuGflvYAbGH9CPNtEW5bOyZgp78TsiiiHKuq6sPep+PkTqTSm+TNAFTTLPHFWBZsZ7ORsE/54=
X-MS-Exchange-Transport-CrossTenantHeadersStamped: SJ0PR17MB4631

On Tue, Jan 09, 2024 at 11:41:11AM +0800, Huang, Ying wrote:
> Gregory Price <gregory.price@memverge.com> writes:
> 
> > On Thu, Jan 04, 2024 at 02:05:01PM +0800, Huang, Ying wrote:
> >> >
> >> > From  https://lpc.events/event/16/contributions/1209/attachments/1042/1995/Live%20In%20a%20World%20With%20Multiple%20Memory%20Types.pdf
> >> > abstract_distance_offset: override by users to deal with firmware issue.
> >> >
> >> > say firmware can configure the cxl node into wrong tiers, similar to
> >> > that it may also configure all cxl nodes into single memtype, hence
> >> > all these nodes can fall into a single wrong tier.
> >> > In this case, per node adistance_offset would be good to have ?
> >> 
> >> I think that it's better to fix the error firmware if possible.  And
> >> these are only theoretical, not practical issues.  Do you have some
> >> practical issues?
> >> 
> >> I understand that users may want to move nodes between memory tiers for
> >> different policy choices.  For that, memory_type based adistance_offset
> >> should be good.
> >> 
> >
> > There's actually an affirmative case to change memory tiering to allow
> > either movement of nodes between tiers, or at least base placement on
> > HMAT information. Preferably, membership would be changable to allow
> > hotplug/DCD to be managed (there's no guarantee that the memory passed
> > through will always be what HMAT says on initial boot).
> 
> IIUC, from Jonathan Cameron as below, the performance of memory
> shouldn't change even for DCD devices.
> 
> https://lore.kernel.org/linux-mm/20231103141636.000007e4@Huawei.com/
> 
> It's possible to change the performance of a NUMA node changed, if we
> hot-remove a memory device, then hot-add another different memory
> device.  It's hoped that the CDAT changes too.
> 
> So, all in all, HMAT + CDAT can help us to put the memory device in
> appropriate memory tiers.  Now, we have HMAT support in upstream.  We
> will working on CDAT support.

That should be sufficient assuming the `-numa hmat-lb` setting in QEMU
does the right thing.  I suppose we also need to figure out a way to set
CDAT information for a memory device that isn't related to CXL (from the
perspective of the guest).  I'll take a look if I get cycles.

~Gregory

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from frasgout.his.huawei.com (frasgout.his.huawei.com [185.176.79.56])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id B010439AD6;
	Tue,  9 Jan 2024 15:50:55 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=quarantine dis=none) header.from=Huawei.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=huawei.com
Received: from mail.maildlp.com (unknown [172.18.186.31])
	by frasgout.his.huawei.com (SkyGuard) with ESMTP id 4T8b1t50QWz6D8y4;
	Tue,  9 Jan 2024 23:48:34 +0800 (CST)
Received: from lhrpeml500005.china.huawei.com (unknown [7.191.163.240])
	by mail.maildlp.com (Postfix) with ESMTPS id EEAEB1400D4;
	Tue,  9 Jan 2024 23:50:51 +0800 (CST)
Received: from localhost (10.202.227.76) by lhrpeml500005.china.huawei.com
 (7.191.163.240) with Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256) id 15.1.2507.35; Tue, 9 Jan
 2024 15:50:51 +0000
Date: Tue, 9 Jan 2024 15:50:49 +0000
From: Jonathan Cameron <Jonathan.Cameron@Huawei.com>
To: "Huang, Ying" <ying.huang@intel.com>
CC: Gregory Price <gregory.price@memverge.com>, Srinivasulu Thanneeru
	<sthanneeru@micron.com>, Srinivasulu Opensrc <sthanneeru.opensrc@micron.com>,
	"linux-cxl@vger.kernel.org" <linux-cxl@vger.kernel.org>, "linux-mm@kvack.org"
	<linux-mm@kvack.org>, "aneesh.kumar@linux.ibm.com"
	<aneesh.kumar@linux.ibm.com>, "dan.j.williams@intel.com"
	<dan.j.williams@intel.com>, "mhocko@suse.com" <mhocko@suse.com>,
	"tj@kernel.org" <tj@kernel.org>, "john@jagalactic.com" <john@jagalactic.com>,
	Eishan Mirakhur <emirakhur@micron.com>, "Vinicius Tavares Petrucci"
	<vtavarespetr@micron.com>, Ravis OpenSrc <Ravis.OpenSrc@micron.com>,
	"linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>, Johannes
 Weiner <hannes@cmpxchg.org>, "Wei Xu" <weixugc@google.com>, Hao Xiang
	<hao.xiang@bytedance.com>, "Ho-Ren (Jack) Chuang" <horenchuang@bytedance.com>
Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory
 tiers
Message-ID: <20240109155049.00003f13@Huawei.com>
In-Reply-To: <87o7dv897s.fsf@yhuang6-desk2.ccr.corp.intel.com>
References: <20231213175329.594-1-sthanneeru.opensrc@micron.com>
	<87cyv8qcqk.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZXyQIJOim1+tE0Qr@memverge.com>
	<87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87wmspbpma.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZZwrIoP9+ey7rp3C@memverge.com>
	<87o7dv897s.fsf@yhuang6-desk2.ccr.corp.intel.com>
Organization: Huawei Technologies Research and Development (UK) Ltd.
X-Mailer: Claws Mail 4.1.0 (GTK 3.24.33; x86_64-w64-mingw32)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Type: text/plain; charset="US-ASCII"
Content-Transfer-Encoding: 7bit
X-ClientProxiedBy: lhrpeml500006.china.huawei.com (7.191.161.198) To
 lhrpeml500005.china.huawei.com (7.191.163.240)

On Tue, 09 Jan 2024 11:41:11 +0800
"Huang, Ying" <ying.huang@intel.com> wrote:

> Gregory Price <gregory.price@memverge.com> writes:
> 
> > On Thu, Jan 04, 2024 at 02:05:01PM +0800, Huang, Ying wrote:  
> >> >
> >> > From  https://lpc.events/event/16/contributions/1209/attachments/1042/1995/Live%20In%20a%20World%20With%20Multiple%20Memory%20Types.pdf
> >> > abstract_distance_offset: override by users to deal with firmware issue.
> >> >
> >> > say firmware can configure the cxl node into wrong tiers, similar to
> >> > that it may also configure all cxl nodes into single memtype, hence
> >> > all these nodes can fall into a single wrong tier.
> >> > In this case, per node adistance_offset would be good to have ?  
> >> 
> >> I think that it's better to fix the error firmware if possible.  And
> >> these are only theoretical, not practical issues.  Do you have some
> >> practical issues?
> >> 
> >> I understand that users may want to move nodes between memory tiers for
> >> different policy choices.  For that, memory_type based adistance_offset
> >> should be good.
> >>   
> >
> > There's actually an affirmative case to change memory tiering to allow
> > either movement of nodes between tiers, or at least base placement on
> > HMAT information. Preferably, membership would be changable to allow
> > hotplug/DCD to be managed (there's no guarantee that the memory passed
> > through will always be what HMAT says on initial boot).  
> 
> IIUC, from Jonathan Cameron as below, the performance of memory
> shouldn't change even for DCD devices.
> 
> https://lore.kernel.org/linux-mm/20231103141636.000007e4@Huawei.com/
> 
> It's possible to change the performance of a NUMA node changed, if we
> hot-remove a memory device, then hot-add another different memory
> device.  It's hoped that the CDAT changes too.

Not supported, but ACPI has _HMA methods to in theory allow changing
HMAT values based on firmware notifications...  So we 'could' make
it work for HMAT based description.

Ultimately my current thinking is we'll end up emulating CXL type3
devices (hiding topology complexity) and you can update CDAT but
IIRC that is only meant to be for degraded situations - so if you
want multiple performance regions, CDAT should describe them form the start.

> 
> So, all in all, HMAT + CDAT can help us to put the memory device in
> appropriate memory tiers.  Now, we have HMAT support in upstream.  We
> will working on CDAT support.
> 
> --
> Best Regards,
> Huang, Ying
> 
> > https://lore.kernel.org/linux-cxl/CAAYibXjZ0HSCqMrzXGv62cMLncS_81R3e1uNV5Fu4CPm0zAtYw@mail.gmail.com/
> >
> > This group wants to enable passing CXL memory through to KVM/QEMU
> > (i.e. host CXL expander memory passed through to the guest), and
> > allow the guest to apply memory tiering.
> >
> > There are multiple issues with this, presently:
> >
> > 1. The QEMU CXL virtual device is not and probably never will be
> >    performant enough to be a commodity class virtualization.

I'd flex that a bit - we will end up with a solution for virtualization but
it isn't the emulation that is there today because it's not possible to
emulate some of the topology in a peformant manner (interleaving with sub
page granularity / interleaving at all (to a lesser degree)). There are
ways to do better than we are today, but they start to look like
software dissagregated memory setups (think lots of page faults in the host).

> >  The
> >    reason is that the virtual CXL device is built off the I/O
> >    virtualization stack, which treats memory accesses as I/O accesses.

That will remain true for complex emulation, but it needn't always be
the case. 
I'm not 100% sure we can make it work but my current thinking is:

When decoders are set up: Check if there is any interleaving going on.
  interleaving happening: Current functionally correct path.
  no interleaving: More conventional memory access path.

> >
> >    KVM also seems incompatible with the design of the CXL memory device
> >    in general, but this problem may or may not be a blocker.

That's true if we are doing fine grained routing but as above we can
probably avoid that.

> >
> >    As a result, access to virtual CXL memory device leads to QEMU
> >    crawling to a halt - and this is unlikely to change.

In general yes, but hopefully not for carefully configured cases (the
simple one of direct connect single device, no host interleaving for example).

> >
> >    There is presently no good way forward to create a performant virtual
> >    CXL device in QEMU.  This means the memory tiering component in the
> >    kernel is functionally useless for virtual CXL memory, because...

Agreed - nothing there yet and I don't think the question of CXL virtualization
in general is anywhere near solved...  Maybe emulating a CXL device doesn't
make sense, maybe we end up extending virtio-mem instead.
Needs some PoC work to flesh this out. (it's about number 3 on my list of
stuff to look at this year)

> >
> > 2. When passing memory through as an explicit NUMA node, but not as
> >    part of a CXL memory device, the nodes are lumped together in the
> >    DRAM tier.
> >
> > None of this has to do with firmware.
> >
> > Memory-type is an awful way of denoting membership of a tier, but we
> > have HMAT information that can be passed through via QEMU:
> >
> > -object memory-backend-ram,size=4G,id=ram-node0 \
> > -object memory-backend-ram,size=4G,id=ram-node1 \
> > -numa node,nodeid=0,cpus=0-4,memdev=ram-node0 \
> > -numa node,initiator=0,nodeid=1,memdev=ram-node1 \
> > -numa hmat-lb,initiator=0,target=0,hierarchy=memory,data-type=access-latency,latency=10 \
> > -numa hmat-lb,initiator=0,target=0,hierarchy=memory,data-type=access-bandwidth,bandwidth=10485760 \
> > -numa hmat-lb,initiator=0,target=1,hierarchy=memory,data-type=access-latency,latency=20 \
> > -numa hmat-lb,initiator=0,target=1,hierarchy=memory,data-type=access-bandwidth,bandwidth=5242880
> >
> > Not only would it be nice if we could change tier membership based on
> > this data, it's realistically the only way to allow guests to accomplish
> > memory tiering w/ KVM/QEMU and CXL memory passed through to the guest.

This I fully agree with.  There will be systems with a bunch of normal DDR with different
access characteristics irrespective of CXL. + likely HMAT solutions will be used
before we get anything more complex in place for CXL.

Jonathan

p.s. I'd love to see _HMA handling implemented in the kernel.. Would trail blaze what
we will probably need to do for fiddly CXL cases where performance degrades on old devices
etc.

> >
> > ~Gregory  
> 


From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from frasgout.his.huawei.com (frasgout.his.huawei.com [185.176.79.56])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 4EF2C4A9B8;
	Wed, 10 Jan 2024 14:18:25 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=quarantine dis=none) header.from=Huawei.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=huawei.com
Received: from mail.maildlp.com (unknown [172.18.186.216])
	by frasgout.his.huawei.com (SkyGuard) with ESMTP id 4T98wg0GTRz67g6l;
	Wed, 10 Jan 2024 22:16:03 +0800 (CST)
Received: from lhrpeml500005.china.huawei.com (unknown [7.191.163.240])
	by mail.maildlp.com (Postfix) with ESMTPS id E63FD140736;
	Wed, 10 Jan 2024 22:18:22 +0800 (CST)
Received: from localhost (10.202.227.76) by lhrpeml500005.china.huawei.com
 (7.191.163.240) with Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256) id 15.1.2507.35; Wed, 10 Jan
 2024 14:18:22 +0000
Date: Wed, 10 Jan 2024 14:18:21 +0000
From: Jonathan Cameron <Jonathan.Cameron@Huawei.com>
To: Hao Xiang <hao.xiang@bytedance.com>
CC: Gregory Price <gregory.price@memverge.com>, "Huang, Ying"
	<ying.huang@intel.com>, Srinivasulu Thanneeru <sthanneeru@micron.com>,
	Srinivasulu Opensrc <sthanneeru.opensrc@micron.com>,
	"linux-cxl@vger.kernel.org" <linux-cxl@vger.kernel.org>, "linux-mm@kvack.org"
	<linux-mm@kvack.org>, "aneesh.kumar@linux.ibm.com"
	<aneesh.kumar@linux.ibm.com>, "dan.j.williams@intel.com"
	<dan.j.williams@intel.com>, "mhocko@suse.com" <mhocko@suse.com>,
	"tj@kernel.org" <tj@kernel.org>, "john@jagalactic.com" <john@jagalactic.com>,
	Eishan Mirakhur <emirakhur@micron.com>, "Vinicius Tavares Petrucci"
	<vtavarespetr@micron.com>, Ravis OpenSrc <Ravis.OpenSrc@micron.com>,
	"linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>, Johannes
 Weiner <hannes@cmpxchg.org>, "Wei Xu" <weixugc@google.com>, "Ho-Ren (Jack)
 Chuang" <horenchuang@bytedance.com>
Subject: Re: [External] Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration
 between memory tiers
Message-ID: <20240110141821.0000370d@Huawei.com>
In-Reply-To: <CAAYibXhe81ez06tP5K7zGkX9P=Ot+DcSysVyDvh13aSEDD63aA@mail.gmail.com>
References: <87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87wmspbpma.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZZwrIoP9+ey7rp3C@memverge.com>
	<87o7dv897s.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<20240109155049.00003f13@Huawei.com>
	<ZZ2Jd7/7rFD0o5S3@memverge.com>
	<CAAYibXhe81ez06tP5K7zGkX9P=Ot+DcSysVyDvh13aSEDD63aA@mail.gmail.com>
Organization: Huawei Technologies Research and Development (UK) Ltd.
X-Mailer: Claws Mail 4.1.0 (GTK 3.24.33; x86_64-w64-mingw32)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Type: text/plain; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable
X-ClientProxiedBy: lhrpeml100001.china.huawei.com (7.191.160.183) To
 lhrpeml500005.china.huawei.com (7.191.163.240)

On Tue, 9 Jan 2024 16:28:15 -0800
Hao Xiang <hao.xiang@bytedance.com> wrote:

> On Tue, Jan 9, 2024 at 9:59=E2=80=AFAM Gregory Price <gregory.price@memve=
rge.com> wrote:
> >
> > On Tue, Jan 09, 2024 at 03:50:49PM +0000, Jonathan Cameron wrote: =20
> > > On Tue, 09 Jan 2024 11:41:11 +0800
> > > "Huang, Ying" <ying.huang@intel.com> wrote: =20
> > > > Gregory Price <gregory.price@memverge.com> writes: =20
> > > > > On Thu, Jan 04, 2024 at 02:05:01PM +0800, Huang, Ying wrote: =20
> > > > It's possible to change the performance of a NUMA node changed, if =
we
> > > > hot-remove a memory device, then hot-add another different memory
> > > > device.  It's hoped that the CDAT changes too. =20
> > >
> > > Not supported, but ACPI has _HMA methods to in theory allow changing
> > > HMAT values based on firmware notifications...  So we 'could' make
> > > it work for HMAT based description.
> > >
> > > Ultimately my current thinking is we'll end up emulating CXL type3
> > > devices (hiding topology complexity) and you can update CDAT but
> > > IIRC that is only meant to be for degraded situations - so if you
> > > want multiple performance regions, CDAT should describe them form the=
 start.
> > > =20
> >
> > That was my thought.  I don't think it's particularly *realistic* for
> > HMAT/CDAT values to change at runtime, but I can imagine a case where
> > it could be valuable.
> > =20
> > > > > https://lore.kernel.org/linux-cxl/CAAYibXjZ0HSCqMrzXGv62cMLncS_81=
R3e1uNV5Fu4CPm0zAtYw@mail.gmail.com/
> > > > >
> > > > > This group wants to enable passing CXL memory through to KVM/QEMU
> > > > > (i.e. host CXL expander memory passed through to the guest), and
> > > > > allow the guest to apply memory tiering.
> > > > >
> > > > > There are multiple issues with this, presently:
> > > > >
> > > > > 1. The QEMU CXL virtual device is not and probably never will be
> > > > >    performant enough to be a commodity class virtualization. =20
> > >
> > > I'd flex that a bit - we will end up with a solution for virtualizati=
on but
> > > it isn't the emulation that is there today because it's not possible =
to
> > > emulate some of the topology in a peformant manner (interleaving with=
 sub
> > > page granularity / interleaving at all (to a lesser degree)). There a=
re
> > > ways to do better than we are today, but they start to look like
> > > software dissagregated memory setups (think lots of page faults in th=
e host).
> > > =20
> >
> > Agreed, the emulated device as-is can't be the virtualization device,
> > but it doesn't mean it can't be the basis for it.
> >
> > My thought is, if you want to pass host CXL *memory* through to the
> > guest, you don't actually care to pass CXL *control* through to the
> > guest.  That control lies pretty squarely with the host/hypervisor.
> >
> > So, at least in theory, you can just cut the type3 device out of the
> > QEMU configuration entirely and just pass it through as a distinct numa
> > node with specific hmat qualities.
> >
> > Barring that, if we must go through the type3 device, the question is
> > how difficult would it be to just make a stripped down type3 device
> > to provide the informational components, but hack off anything
> > topology/interleave related? Then you just do direct passthrough as you
> > described below.
> >
> > qemu/kvm would report errors if you tried to touch the naughty bits.
> >
> > The second question is... is that device "compliant" or does it need
> > super special handling from the kernel driver :D?  If what i described
> > is not "compliant", then it's probably a bad idea, and KVM/QEMU should
> > just hide the CXL device entirely from the guest (for this use case)
> > and just pass the memory through as a numa node.
> >
> > Which gets us back to: The memory-tiering component needs a way to
> > place nodes in different tiers based on HMAT/CDAT/User Whim. All three
> > of those seem like totally valid ways to go about it.
> > =20
> > > > >
> > > > > 2. When passing memory through as an explicit NUMA node, but not =
as
> > > > >    part of a CXL memory device, the nodes are lumped together in =
the
> > > > >    DRAM tier.
> > > > >
> > > > > None of this has to do with firmware.
> > > > >
> > > > > Memory-type is an awful way of denoting membership of a tier, but=
 we
> > > > > have HMAT information that can be passed through via QEMU:
> > > > >
> > > > > -object memory-backend-ram,size=3D4G,id=3Dram-node0 \
> > > > > -object memory-backend-ram,size=3D4G,id=3Dram-node1 \
> > > > > -numa node,nodeid=3D0,cpus=3D0-4,memdev=3Dram-node0 \
> > > > > -numa node,initiator=3D0,nodeid=3D1,memdev=3Dram-node1 \
> > > > > -numa hmat-lb,initiator=3D0,target=3D0,hierarchy=3Dmemory,data-ty=
pe=3Daccess-latency,latency=3D10 \
> > > > > -numa hmat-lb,initiator=3D0,target=3D0,hierarchy=3Dmemory,data-ty=
pe=3Daccess-bandwidth,bandwidth=3D10485760 \
> > > > > -numa hmat-lb,initiator=3D0,target=3D1,hierarchy=3Dmemory,data-ty=
pe=3Daccess-latency,latency=3D20 \
> > > > > -numa hmat-lb,initiator=3D0,target=3D1,hierarchy=3Dmemory,data-ty=
pe=3Daccess-bandwidth,bandwidth=3D5242880
> > > > >
> > > > > Not only would it be nice if we could change tier membership base=
d on
> > > > > this data, it's realistically the only way to allow guests to acc=
omplish
> > > > > memory tiering w/ KVM/QEMU and CXL memory passed through to the g=
uest. =20
> > >
> > > This I fully agree with.  There will be systems with a bunch of norma=
l DDR with different
> > > access characteristics irrespective of CXL. + likely HMAT solutions w=
ill be used
> > > before we get anything more complex in place for CXL.
> > > =20
> >
> > Had not even considered this, but that's completely accurate as well.
> >
> > And more discretely: What of devices that don't provide HMAT/CDAT? That
> > isn't necessarily a violation of any standard.  There probably could be
> > a release valve for us to still make those devices useful.
> >
> > The concern I have with not implementing a movement mechanism *at all*
> > is that a one-size-fits-all initial-placement heuristic feels gross
> > when we're, at least ideologically, moving toward "software defined mem=
ory".
> >
> > Personally I think the movement mechanism is a good idea that gets folks
> > where they're going sooner, and it doesn't hurt anything by existing. We
> > can change the initial placement mechanism too. =20
>=20
> I think providing users a way to "FIX" the memory tiering is a backup
> option. Given that DDRs with different access characteristics provide
> the relevant CDAT/HMAT information, the kernel should be able to
> correctly establish memory tiering on boot.

Include hotplug and I'll be happier!  I know that's messy though.

> Current memory tiering code has
> 1) memory_tier_init() to iterate through all boot onlined memory
> nodes. All nodes are assumed to be fast tier (adistance
> MEMTIER_ADISTANCE_DRAM is used).
> 2) dev_dax_kmem_probe to iterate through all devdax controlled memory
> nodes. This is the place the kernel reads the memory attributes from
> HMAT and recognizes the memory nodes into the correct tier (devdax
> controlled CXL, pmem, etc).
> If we want DDRs with different memory characteristics to be put into
> the correct tier (as in the guest VM memory tiering case), we probably
> need a third path to iterate the boot onlined memory nodes and also be
> able to read their memory attributes. I don't think we can do that in
> 1) because the ACPI subsystem is not yet initialized.

Can we move it later in general?  Or drag HMAT parsing earlier?
ACPI table availability is pretty early, it's just that we don't bother
with HMAT because nothing early uses it.
IIRC SRAT parsing occurs way before memory_tier_init() will be called.

Jonathan



>=20
> >
> > </2cents>
> >
> > ~Gregory =20


From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from frasgout.his.huawei.com (frasgout.his.huawei.com [185.176.79.56])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id A8E064A9A1;
	Wed, 10 Jan 2024 14:11:35 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=quarantine dis=none) header.from=Huawei.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=huawei.com
Received: from mail.maildlp.com (unknown [172.18.186.31])
	by frasgout.his.huawei.com (SkyGuard) with ESMTP id 4T98mS4mQzz6K97H;
	Wed, 10 Jan 2024 22:08:56 +0800 (CST)
Received: from lhrpeml500005.china.huawei.com (unknown [7.191.163.240])
	by mail.maildlp.com (Postfix) with ESMTPS id 90357140B2F;
	Wed, 10 Jan 2024 22:11:32 +0800 (CST)
Received: from localhost (10.202.227.76) by lhrpeml500005.china.huawei.com
 (7.191.163.240) with Microsoft SMTP Server (version=TLS1_2,
 cipher=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256) id 15.1.2507.35; Wed, 10 Jan
 2024 14:11:31 +0000
Date: Wed, 10 Jan 2024 14:11:30 +0000
From: Jonathan Cameron <Jonathan.Cameron@Huawei.com>
To: Gregory Price <gregory.price@memverge.com>
CC: "Huang, Ying" <ying.huang@intel.com>, Srinivasulu Thanneeru
	<sthanneeru@micron.com>, Srinivasulu Opensrc <sthanneeru.opensrc@micron.com>,
	"linux-cxl@vger.kernel.org" <linux-cxl@vger.kernel.org>, "linux-mm@kvack.org"
	<linux-mm@kvack.org>, "aneesh.kumar@linux.ibm.com"
	<aneesh.kumar@linux.ibm.com>, "dan.j.williams@intel.com"
	<dan.j.williams@intel.com>, "mhocko@suse.com" <mhocko@suse.com>,
	"tj@kernel.org" <tj@kernel.org>, "john@jagalactic.com" <john@jagalactic.com>,
	Eishan Mirakhur <emirakhur@micron.com>, "Vinicius Tavares Petrucci"
	<vtavarespetr@micron.com>, Ravis OpenSrc <Ravis.OpenSrc@micron.com>,
	"linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>, Johannes
 Weiner <hannes@cmpxchg.org>, "Wei Xu" <weixugc@google.com>, Hao Xiang
	<hao.xiang@bytedance.com>, "Ho-Ren (Jack) Chuang" <horenchuang@bytedance.com>
Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory
 tiers
Message-ID: <20240110141130.0000035c@Huawei.com>
In-Reply-To: <ZZ2Jd7/7rFD0o5S3@memverge.com>
References: <87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87wmspbpma.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZZwrIoP9+ey7rp3C@memverge.com>
	<87o7dv897s.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<20240109155049.00003f13@Huawei.com>
	<ZZ2Jd7/7rFD0o5S3@memverge.com>
Organization: Huawei Technologies Research and Development (UK) Ltd.
X-Mailer: Claws Mail 4.1.0 (GTK 3.24.33; x86_64-w64-mingw32)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Type: text/plain; charset="US-ASCII"
Content-Transfer-Encoding: 7bit
X-ClientProxiedBy: lhrpeml100001.china.huawei.com (7.191.160.183) To
 lhrpeml500005.china.huawei.com (7.191.163.240)

On Tue, 9 Jan 2024 12:59:19 -0500
Gregory Price <gregory.price@memverge.com> wrote:

> On Tue, Jan 09, 2024 at 03:50:49PM +0000, Jonathan Cameron wrote:
> > On Tue, 09 Jan 2024 11:41:11 +0800
> > "Huang, Ying" <ying.huang@intel.com> wrote:  
> > > Gregory Price <gregory.price@memverge.com> writes:  
> > > > On Thu, Jan 04, 2024 at 02:05:01PM +0800, Huang, Ying wrote:    
> > > It's possible to change the performance of a NUMA node changed, if we
> > > hot-remove a memory device, then hot-add another different memory
> > > device.  It's hoped that the CDAT changes too.  
> > 
> > Not supported, but ACPI has _HMA methods to in theory allow changing
> > HMAT values based on firmware notifications...  So we 'could' make
> > it work for HMAT based description.
> > 
> > Ultimately my current thinking is we'll end up emulating CXL type3
> > devices (hiding topology complexity) and you can update CDAT but
> > IIRC that is only meant to be for degraded situations - so if you
> > want multiple performance regions, CDAT should describe them form the start.
> >   
> 
> That was my thought.  I don't think it's particularly *realistic* for
> HMAT/CDAT values to change at runtime, but I can imagine a case where
> it could be valuable.

For now I'm thinking we might spit that CDAT info via a tracepoint if
it happens, but given it's degraded perf only maybe we don't care.

HMAT is more interesting because it may be used by a firmware first
model to paper over some weird hardware being hotplugged, or for giggles
a hypervisor moving memory around under the hood (think powering down
whole DRAM controllers etc).

Anyhow, that's highly speculative and whoever cares about it can
make it work! :)

> 
> > > > https://lore.kernel.org/linux-cxl/CAAYibXjZ0HSCqMrzXGv62cMLncS_81R3e1uNV5Fu4CPm0zAtYw@mail.gmail.com/
> > > >
> > > > This group wants to enable passing CXL memory through to KVM/QEMU
> > > > (i.e. host CXL expander memory passed through to the guest), and
> > > > allow the guest to apply memory tiering.
> > > >
> > > > There are multiple issues with this, presently:
> > > >
> > > > 1. The QEMU CXL virtual device is not and probably never will be
> > > >    performant enough to be a commodity class virtualization.  
> > 
> > I'd flex that a bit - we will end up with a solution for virtualization but
> > it isn't the emulation that is there today because it's not possible to
> > emulate some of the topology in a peformant manner (interleaving with sub
> > page granularity / interleaving at all (to a lesser degree)). There are
> > ways to do better than we are today, but they start to look like
> > software dissagregated memory setups (think lots of page faults in the host).
> >  
> 
> Agreed, the emulated device as-is can't be the virtualization device,
> but it doesn't mean it can't be the basis for it.
> 
> My thought is, if you want to pass host CXL *memory* through to the
> guest, you don't actually care to pass CXL *control* through to the
> guest.  That control lies pretty squarely with the host/hypervisor.
> 
> So, at least in theory, you can just cut the type3 device out of the
> QEMU configuration entirely and just pass it through as a distinct numa
> node with specific hmat qualities.
> 
> Barring that, if we must go through the type3 device, the question is
> how difficult would it be to just make a stripped down type3 device
> to provide the informational components, but hack off anything
> topology/interleave related? Then you just do direct passthrough as you
> described below.

Not stripped down as such, just lock the decoders as if a firmware had
configured it (in reality the config will be really really simple).
The kernel stack handles that fine today.  The only dynamic bit
would be the DC related part.  Not sure our lockdown support in the
emulated device is complete (some of it is there but might have missed
some registers).

> 
> qemu/kvm would report errors if you tried to touch the naughty bits.

Might do that a temporary step along way to enabling thing but given
CXL assumes that the host firmware 'might' have configured everything and
locked it (kernel may be booting out of CXL memory for instance) it should
'just work' without needing this.
 
> The second question is... is that device "compliant" or does it need
> super special handling from the kernel driver :D?  If what i described
> is not "compliant", then it's probably a bad idea, and KVM/QEMU should
> just hide the CXL device entirely from the guest (for this use case)
> and just pass the memory through as a numa node.
Would need to be compliant or very nearly so - I can see we might advertise
no interleave support even though not setting any of the interleave address
bits is technically a spec violation.  However, don't think we need to
do that because of decoder locking.  We advertise interleave options but
don't allow current setting to be changed.

If someone manually resets the bus they are on their own though :(
(that will clear the lock registers as it's the same as removing power).

> 
> Which gets us back to: The memory-tiering component needs a way to
> place nodes in different tiers based on HMAT/CDAT/User Whim. All three
> of those seem like totally valid ways to go about it.
> 
> > > >
> > > > 2. When passing memory through as an explicit NUMA node, but not as
> > > >    part of a CXL memory device, the nodes are lumped together in the
> > > >    DRAM tier.
> > > >
> > > > None of this has to do with firmware.
> > > >
> > > > Memory-type is an awful way of denoting membership of a tier, but we
> > > > have HMAT information that can be passed through via QEMU:
> > > >
> > > > -object memory-backend-ram,size=4G,id=ram-node0 \
> > > > -object memory-backend-ram,size=4G,id=ram-node1 \
> > > > -numa node,nodeid=0,cpus=0-4,memdev=ram-node0 \
> > > > -numa node,initiator=0,nodeid=1,memdev=ram-node1 \
> > > > -numa hmat-lb,initiator=0,target=0,hierarchy=memory,data-type=access-latency,latency=10 \
> > > > -numa hmat-lb,initiator=0,target=0,hierarchy=memory,data-type=access-bandwidth,bandwidth=10485760 \
> > > > -numa hmat-lb,initiator=0,target=1,hierarchy=memory,data-type=access-latency,latency=20 \
> > > > -numa hmat-lb,initiator=0,target=1,hierarchy=memory,data-type=access-bandwidth,bandwidth=5242880
> > > >
> > > > Not only would it be nice if we could change tier membership based on
> > > > this data, it's realistically the only way to allow guests to accomplish
> > > > memory tiering w/ KVM/QEMU and CXL memory passed through to the guest.  
> > 
> > This I fully agree with.  There will be systems with a bunch of normal DDR with different
> > access characteristics irrespective of CXL. + likely HMAT solutions will be used
> > before we get anything more complex in place for CXL.
> >   
> 
> Had not even considered this, but that's completely accurate as well.
> 
> And more discretely: What of devices that don't provide HMAT/CDAT? That
> isn't necessarily a violation of any standard.  There probably could be
> a release valve for us to still make those devices useful.

I'd argue any such device needs some driver support. Release valve is they
provide the info from that driver, just like the CDAT solution is doing.

If they don't then meh, their system is borked so they'll will add it
fairly quickly!

> 
> The concern I have with not implementing a movement mechanism *at all*
> is that a one-size-fits-all initial-placement heuristic feels gross
> when we're, at least ideologically, moving toward "software defined memory".
> 
> Personally I think the movement mechanism is a good idea that gets folks
> where they're going sooner, and it doesn't hurt anything by existing. We
> can change the initial placement mechanism too.

I've no problem with a movement mechanism. Hopefully in the long run it
never gets used though! Maybe in short term it's out of tree code.

Jonathan

> 
> </2cents>
> 
> ~Gregory


From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from mgamail.intel.com (mgamail.intel.com [192.198.163.7])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 8FD1DDF55;
	Wed, 10 Jan 2024 05:49:41 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=none dis=none) header.from=intel.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=intel.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=intel.com header.i=@intel.com header.b="lgtNCpkG"
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple;
  d=intel.com; i=@intel.com; q=dns/txt; s=Intel;
  t=1704865782; x=1736401782;
  h=from:to:cc:subject:in-reply-to:references:date:
   message-id:mime-version;
  bh=dhn8lW2PQSKTBB+E/1ToBYW7OfpllNpuAWbFrFkAQOg=;
  b=lgtNCpkG4mjofaJjaPwyikr0NtD2dAAu4KSLxj6OeuqRbnjbLG8feWvK
   AcOu3ftLJ5sHyEzVyXWe3GaaHra6hRErL74sd0e0LXIRf0633IWqHTT/X
   CcmBZR3CN1LWuEXRLz+yTyJF3xTlB6qOmnWgpsRTmYDxf6EtCo+irULHl
   VSDNGr/f1zzuQI7VorG0cK5aHdW9Pn6/AlTBOShBGnNGmv0n3GXMY/y2I
   LHMIo6cnzMrk+Zf2IGwexXkkOhITvbtGQkrkmOsZvvRO3p09SFnjEYV68
   6NHwDEAsNXk7WZIRZrzj2kWmDIhiEYpNbp1u7W/k80CnRLrlxnHu2MmAQ
   A==;
X-IronPort-AV: E=McAfee;i="6600,9927,10947"; a="19914845"
X-IronPort-AV: E=Sophos;i="6.04,184,1695711600"; 
   d="scan'208";a="19914845"
Received: from fmsmga002.fm.intel.com ([10.253.24.26])
  by fmvoesa101.fm.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 09 Jan 2024 21:49:41 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=McAfee;i="6600,9927,10947"; a="901022216"
X-IronPort-AV: E=Sophos;i="6.04,184,1695711600"; 
   d="scan'208";a="901022216"
Received: from yhuang6-desk2.sh.intel.com (HELO yhuang6-desk2.ccr.corp.intel.com) ([10.238.208.55])
  by fmsmga002-auth.fm.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 09 Jan 2024 21:49:35 -0800
From: "Huang, Ying" <ying.huang@intel.com>
To: Gregory Price <gregory.price@memverge.com>
Cc: Jonathan Cameron <Jonathan.Cameron@huawei.com>,  Srinivasulu Thanneeru
 <sthanneeru@micron.com>,  Srinivasulu Opensrc
 <sthanneeru.opensrc@micron.com>,  "linux-cxl@vger.kernel.org"
 <linux-cxl@vger.kernel.org>,  "linux-mm@kvack.org" <linux-mm@kvack.org>,
  "aneesh.kumar@linux.ibm.com" <aneesh.kumar@linux.ibm.com>,
  "dan.j.williams@intel.com" <dan.j.williams@intel.com>,  "mhocko@suse.com"
 <mhocko@suse.com>,  "tj@kernel.org" <tj@kernel.org>,
  "john@jagalactic.com" <john@jagalactic.com>,  Eishan Mirakhur
 <emirakhur@micron.com>,  Vinicius Tavares Petrucci
 <vtavarespetr@micron.com>,  Ravis OpenSrc <Ravis.OpenSrc@micron.com>,
  "linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>,  "Johannes
 Weiner" <hannes@cmpxchg.org>,  Wei Xu <weixugc@google.com>,  Hao Xiang
 <hao.xiang@bytedance.com>,  "Ho-Ren (Jack) Chuang"
 <horenchuang@bytedance.com>
Subject: Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration between memory tiers
In-Reply-To: <ZZ2Jd7/7rFD0o5S3@memverge.com> (Gregory Price's message of "Tue,
	9 Jan 2024 12:59:19 -0500")
References: <87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87wmspbpma.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZZwrIoP9+ey7rp3C@memverge.com>
	<87o7dv897s.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<20240109155049.00003f13@Huawei.com> <ZZ2Jd7/7rFD0o5S3@memverge.com>
Date: Wed, 10 Jan 2024 13:47:38 +0800
Message-ID: <87bk9t91tx.fsf@yhuang6-desk2.ccr.corp.intel.com>
User-Agent: Gnus/5.13 (Gnus v5.13)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Type: text/plain; charset=ascii

Gregory Price <gregory.price@memverge.com> writes:

> On Tue, Jan 09, 2024 at 03:50:49PM +0000, Jonathan Cameron wrote:
>> On Tue, 09 Jan 2024 11:41:11 +0800
>> "Huang, Ying" <ying.huang@intel.com> wrote:
>> > Gregory Price <gregory.price@memverge.com> writes:
>> > > On Thu, Jan 04, 2024 at 02:05:01PM +0800, Huang, Ying wrote:  
>> > It's possible to change the performance of a NUMA node changed, if we
>> > hot-remove a memory device, then hot-add another different memory
>> > device.  It's hoped that the CDAT changes too.
>> 
>> Not supported, but ACPI has _HMA methods to in theory allow changing
>> HMAT values based on firmware notifications...  So we 'could' make
>> it work for HMAT based description.
>> 
>> Ultimately my current thinking is we'll end up emulating CXL type3
>> devices (hiding topology complexity) and you can update CDAT but
>> IIRC that is only meant to be for degraded situations - so if you
>> want multiple performance regions, CDAT should describe them form the start.
>> 
>
> That was my thought.  I don't think it's particularly *realistic* for
> HMAT/CDAT values to change at runtime, but I can imagine a case where
> it could be valuable.
>
>> > > https://lore.kernel.org/linux-cxl/CAAYibXjZ0HSCqMrzXGv62cMLncS_81R3e1uNV5Fu4CPm0zAtYw@mail.gmail.com/
>> > >
>> > > This group wants to enable passing CXL memory through to KVM/QEMU
>> > > (i.e. host CXL expander memory passed through to the guest), and
>> > > allow the guest to apply memory tiering.
>> > >
>> > > There are multiple issues with this, presently:
>> > >
>> > > 1. The QEMU CXL virtual device is not and probably never will be
>> > >    performant enough to be a commodity class virtualization.
>> 
>> I'd flex that a bit - we will end up with a solution for virtualization but
>> it isn't the emulation that is there today because it's not possible to
>> emulate some of the topology in a peformant manner (interleaving with sub
>> page granularity / interleaving at all (to a lesser degree)). There are
>> ways to do better than we are today, but they start to look like
>> software dissagregated memory setups (think lots of page faults in the host).
>>
>
> Agreed, the emulated device as-is can't be the virtualization device,
> but it doesn't mean it can't be the basis for it.
>
> My thought is, if you want to pass host CXL *memory* through to the
> guest, you don't actually care to pass CXL *control* through to the
> guest.  That control lies pretty squarely with the host/hypervisor.
>
> So, at least in theory, you can just cut the type3 device out of the
> QEMU configuration entirely and just pass it through as a distinct numa
> node with specific hmat qualities.
>
> Barring that, if we must go through the type3 device, the question is
> how difficult would it be to just make a stripped down type3 device
> to provide the informational components, but hack off anything
> topology/interleave related? Then you just do direct passthrough as you
> described below.
>
> qemu/kvm would report errors if you tried to touch the naughty bits.
>
> The second question is... is that device "compliant" or does it need
> super special handling from the kernel driver :D?  If what i described
> is not "compliant", then it's probably a bad idea, and KVM/QEMU should
> just hide the CXL device entirely from the guest (for this use case)
> and just pass the memory through as a numa node.
>
> Which gets us back to: The memory-tiering component needs a way to
> place nodes in different tiers based on HMAT/CDAT/User Whim. All three
> of those seem like totally valid ways to go about it.
>
>> > >
>> > > 2. When passing memory through as an explicit NUMA node, but not as
>> > >    part of a CXL memory device, the nodes are lumped together in the
>> > >    DRAM tier.
>> > >
>> > > None of this has to do with firmware.
>> > >
>> > > Memory-type is an awful way of denoting membership of a tier, but we
>> > > have HMAT information that can be passed through via QEMU:
>> > >
>> > > -object memory-backend-ram,size=4G,id=ram-node0 \
>> > > -object memory-backend-ram,size=4G,id=ram-node1 \
>> > > -numa node,nodeid=0,cpus=0-4,memdev=ram-node0 \
>> > > -numa node,initiator=0,nodeid=1,memdev=ram-node1 \
>> > > -numa hmat-lb,initiator=0,target=0,hierarchy=memory,data-type=access-latency,latency=10 \
>> > > -numa hmat-lb,initiator=0,target=0,hierarchy=memory,data-type=access-bandwidth,bandwidth=10485760 \
>> > > -numa hmat-lb,initiator=0,target=1,hierarchy=memory,data-type=access-latency,latency=20 \
>> > > -numa hmat-lb,initiator=0,target=1,hierarchy=memory,data-type=access-bandwidth,bandwidth=5242880
>> > >
>> > > Not only would it be nice if we could change tier membership based on
>> > > this data, it's realistically the only way to allow guests to accomplish
>> > > memory tiering w/ KVM/QEMU and CXL memory passed through to the guest.
>> 
>> This I fully agree with.  There will be systems with a bunch of normal DDR with different
>> access characteristics irrespective of CXL. + likely HMAT solutions will be used
>> before we get anything more complex in place for CXL.
>> 
>
> Had not even considered this, but that's completely accurate as well.
>
> And more discretely: What of devices that don't provide HMAT/CDAT? That
> isn't necessarily a violation of any standard.  There probably could be
> a release valve for us to still make those devices useful.
>
> The concern I have with not implementing a movement mechanism *at all*
> is that a one-size-fits-all initial-placement heuristic feels gross
> when we're, at least ideologically, moving toward "software defined memory".
>
> Personally I think the movement mechanism is a good idea that gets folks
> where they're going sooner, and it doesn't hurt anything by existing. We
> can change the initial placement mechanism too.
>
> </2cents>

It's the last resort to provide hardware information from user space.
We should try to avoid that if possible.

Per my understanding, per-memory-type abstract distance overriding is to
apply specific policy.  While, per-memory-node abstract distance
overriding is to provide missing hardware information.

--
Best Regards,
Huang, Ying

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from mail-ed1-f52.google.com (mail-ed1-f52.google.com [209.85.208.52])
	(using TLSv1.2 with cipher ECDHE-RSA-AES128-GCM-SHA256 (128/128 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 1F635391
	for <linux-cxl@vger.kernel.org>; Wed, 10 Jan 2024 00:28:27 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=quarantine dis=none) header.from=bytedance.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=bytedance.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=bytedance.com header.i=@bytedance.com header.b="Ih6ynWsw"
Received: by mail-ed1-f52.google.com with SMTP id 4fb4d7f45d1cf-5534dcfdd61so6357456a12.0
        for <linux-cxl@vger.kernel.org>; Tue, 09 Jan 2024 16:28:27 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=bytedance.com; s=google; t=1704846506; x=1705451306; darn=vger.kernel.org;
        h=content-transfer-encoding:cc:to:subject:message-id:date:from
         :in-reply-to:references:mime-version:from:to:cc:subject:date
         :message-id:reply-to;
        bh=H4pmETOHyhvCYkpQt+yPZYyBaRugInkKS3WBUZ/57JU=;
        b=Ih6ynWswwXifDAJ/KsQxFVz0MsHg6hbzWPq4fttFD+o1yDbcEm5IwzHHH3UlXVMK8O
         2CodG+8CpGSvF7YrTzb9HB3EyuvAiTcP8zugWzCRCzeyPygDLzMyaXvRD6zJT94xYqEO
         R/UGyAyz5lyFMUFUmi9TDMYBed/pxfS01hs5oA+ELooW8LXFaL6tGLdvuj41azmPucFy
         2yt95EaV3rrLCXQGbpgS468nuVSNixvi6Kq9ajh7PmuRITgiQe8k5BEZBKiEEjmEe0d8
         e671uQ66+PNk9jLSjwNGkxDHVRaAkQfnPBR8F77Z040fPCIY91cGM7GvM5vWaGS4Qw8c
         H/jg==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20230601; t=1704846506; x=1705451306;
        h=content-transfer-encoding:cc:to:subject:message-id:date:from
         :in-reply-to:references:mime-version:x-gm-message-state:from:to:cc
         :subject:date:message-id:reply-to;
        bh=H4pmETOHyhvCYkpQt+yPZYyBaRugInkKS3WBUZ/57JU=;
        b=FbS3MA2s0yGIoRinV1lvprcyqHgD1zR73k8DmB1WjDUZgvsCKUGtvX8Xy4KdkvUQZf
         Wu+1Dd4YysbS9kDRZbczDVtPWNoW38Px6vx2yB6rcOnHMQG2zLgH3oh9KTFSUw8ndoPZ
         J79FnhKl1P9HWO0yqmbZiOCN7mjJPZUclivc8Pf8bL9fsVlnHDI3rBsJKlqkiJKZ9gGF
         +dfUIpJ+7y4kjp9d8CebcFh3aKNHTDuUn7bWDKXDXOGWRpAH5srXJAUPVXXdr1NkcoGw
         McgD29TWOroYaRa4bECGAY9w5pm4hPb+xdQbb5MNAYMEJp2T3Jl3+B3UHF627L9tuD1I
         fQoQ==
X-Gm-Message-State: AOJu0YzNA7cghYwyKCeWtLfgT/szTkEzHR7OS92+JAfGReL00HJhOI8q
	ycaWmnN0GAYGo4M2dTR5guisl9mpKsqJ5rVBXmY7UZL6YmY+/g==
X-Google-Smtp-Source: AGHT+IEn5QFPnpdbTlRy8zQfT/RyATV6pAFg6InDKMm2y7syoVXBkmePPkCqoJPOzTHgZl3vPqXyduVqupZ7sYtIL7U=
X-Received: by 2002:a50:f615:0:b0:554:8c9d:c3ff with SMTP id
 c21-20020a50f615000000b005548c9dc3ffmr299258edn.29.1704846506388; Tue, 09 Jan
 2024 16:28:26 -0800 (PST)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
References: <87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
 <PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com> <PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com> <PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87wmspbpma.fsf@yhuang6-desk2.ccr.corp.intel.com> <ZZwrIoP9+ey7rp3C@memverge.com>
 <87o7dv897s.fsf@yhuang6-desk2.ccr.corp.intel.com> <20240109155049.00003f13@Huawei.com>
 <ZZ2Jd7/7rFD0o5S3@memverge.com>
In-Reply-To: <ZZ2Jd7/7rFD0o5S3@memverge.com>
From: Hao Xiang <hao.xiang@bytedance.com>
Date: Tue, 9 Jan 2024 16:28:15 -0800
Message-ID: <CAAYibXhe81ez06tP5K7zGkX9P=Ot+DcSysVyDvh13aSEDD63aA@mail.gmail.com>
Subject: Re: [External] Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration
 between memory tiers
To: Gregory Price <gregory.price@memverge.com>
Cc: Jonathan Cameron <Jonathan.Cameron@huawei.com>, "Huang, Ying" <ying.huang@intel.com>, 
	Srinivasulu Thanneeru <sthanneeru@micron.com>, Srinivasulu Opensrc <sthanneeru.opensrc@micron.com>, 
	"linux-cxl@vger.kernel.org" <linux-cxl@vger.kernel.org>, "linux-mm@kvack.org" <linux-mm@kvack.org>, 
	"aneesh.kumar@linux.ibm.com" <aneesh.kumar@linux.ibm.com>, 
	"dan.j.williams@intel.com" <dan.j.williams@intel.com>, "mhocko@suse.com" <mhocko@suse.com>, 
	"tj@kernel.org" <tj@kernel.org>, "john@jagalactic.com" <john@jagalactic.com>, 
	Eishan Mirakhur <emirakhur@micron.com>, Vinicius Tavares Petrucci <vtavarespetr@micron.com>, 
	Ravis OpenSrc <Ravis.OpenSrc@micron.com>, 
	"linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>, Johannes Weiner <hannes@cmpxchg.org>, 
	Wei Xu <weixugc@google.com>, "Ho-Ren (Jack) Chuang" <horenchuang@bytedance.com>
Content-Type: text/plain; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

On Tue, Jan 9, 2024 at 9:59=E2=80=AFAM Gregory Price <gregory.price@memverg=
e.com> wrote:
>
> On Tue, Jan 09, 2024 at 03:50:49PM +0000, Jonathan Cameron wrote:
> > On Tue, 09 Jan 2024 11:41:11 +0800
> > "Huang, Ying" <ying.huang@intel.com> wrote:
> > > Gregory Price <gregory.price@memverge.com> writes:
> > > > On Thu, Jan 04, 2024 at 02:05:01PM +0800, Huang, Ying wrote:
> > > It's possible to change the performance of a NUMA node changed, if we
> > > hot-remove a memory device, then hot-add another different memory
> > > device.  It's hoped that the CDAT changes too.
> >
> > Not supported, but ACPI has _HMA methods to in theory allow changing
> > HMAT values based on firmware notifications...  So we 'could' make
> > it work for HMAT based description.
> >
> > Ultimately my current thinking is we'll end up emulating CXL type3
> > devices (hiding topology complexity) and you can update CDAT but
> > IIRC that is only meant to be for degraded situations - so if you
> > want multiple performance regions, CDAT should describe them form the s=
tart.
> >
>
> That was my thought.  I don't think it's particularly *realistic* for
> HMAT/CDAT values to change at runtime, but I can imagine a case where
> it could be valuable.
>
> > > > https://lore.kernel.org/linux-cxl/CAAYibXjZ0HSCqMrzXGv62cMLncS_81R3=
e1uNV5Fu4CPm0zAtYw@mail.gmail.com/
> > > >
> > > > This group wants to enable passing CXL memory through to KVM/QEMU
> > > > (i.e. host CXL expander memory passed through to the guest), and
> > > > allow the guest to apply memory tiering.
> > > >
> > > > There are multiple issues with this, presently:
> > > >
> > > > 1. The QEMU CXL virtual device is not and probably never will be
> > > >    performant enough to be a commodity class virtualization.
> >
> > I'd flex that a bit - we will end up with a solution for virtualization=
 but
> > it isn't the emulation that is there today because it's not possible to
> > emulate some of the topology in a peformant manner (interleaving with s=
ub
> > page granularity / interleaving at all (to a lesser degree)). There are
> > ways to do better than we are today, but they start to look like
> > software dissagregated memory setups (think lots of page faults in the =
host).
> >
>
> Agreed, the emulated device as-is can't be the virtualization device,
> but it doesn't mean it can't be the basis for it.
>
> My thought is, if you want to pass host CXL *memory* through to the
> guest, you don't actually care to pass CXL *control* through to the
> guest.  That control lies pretty squarely with the host/hypervisor.
>
> So, at least in theory, you can just cut the type3 device out of the
> QEMU configuration entirely and just pass it through as a distinct numa
> node with specific hmat qualities.
>
> Barring that, if we must go through the type3 device, the question is
> how difficult would it be to just make a stripped down type3 device
> to provide the informational components, but hack off anything
> topology/interleave related? Then you just do direct passthrough as you
> described below.
>
> qemu/kvm would report errors if you tried to touch the naughty bits.
>
> The second question is... is that device "compliant" or does it need
> super special handling from the kernel driver :D?  If what i described
> is not "compliant", then it's probably a bad idea, and KVM/QEMU should
> just hide the CXL device entirely from the guest (for this use case)
> and just pass the memory through as a numa node.
>
> Which gets us back to: The memory-tiering component needs a way to
> place nodes in different tiers based on HMAT/CDAT/User Whim. All three
> of those seem like totally valid ways to go about it.
>
> > > >
> > > > 2. When passing memory through as an explicit NUMA node, but not as
> > > >    part of a CXL memory device, the nodes are lumped together in th=
e
> > > >    DRAM tier.
> > > >
> > > > None of this has to do with firmware.
> > > >
> > > > Memory-type is an awful way of denoting membership of a tier, but w=
e
> > > > have HMAT information that can be passed through via QEMU:
> > > >
> > > > -object memory-backend-ram,size=3D4G,id=3Dram-node0 \
> > > > -object memory-backend-ram,size=3D4G,id=3Dram-node1 \
> > > > -numa node,nodeid=3D0,cpus=3D0-4,memdev=3Dram-node0 \
> > > > -numa node,initiator=3D0,nodeid=3D1,memdev=3Dram-node1 \
> > > > -numa hmat-lb,initiator=3D0,target=3D0,hierarchy=3Dmemory,data-type=
=3Daccess-latency,latency=3D10 \
> > > > -numa hmat-lb,initiator=3D0,target=3D0,hierarchy=3Dmemory,data-type=
=3Daccess-bandwidth,bandwidth=3D10485760 \
> > > > -numa hmat-lb,initiator=3D0,target=3D1,hierarchy=3Dmemory,data-type=
=3Daccess-latency,latency=3D20 \
> > > > -numa hmat-lb,initiator=3D0,target=3D1,hierarchy=3Dmemory,data-type=
=3Daccess-bandwidth,bandwidth=3D5242880
> > > >
> > > > Not only would it be nice if we could change tier membership based =
on
> > > > this data, it's realistically the only way to allow guests to accom=
plish
> > > > memory tiering w/ KVM/QEMU and CXL memory passed through to the gue=
st.
> >
> > This I fully agree with.  There will be systems with a bunch of normal =
DDR with different
> > access characteristics irrespective of CXL. + likely HMAT solutions wil=
l be used
> > before we get anything more complex in place for CXL.
> >
>
> Had not even considered this, but that's completely accurate as well.
>
> And more discretely: What of devices that don't provide HMAT/CDAT? That
> isn't necessarily a violation of any standard.  There probably could be
> a release valve for us to still make those devices useful.
>
> The concern I have with not implementing a movement mechanism *at all*
> is that a one-size-fits-all initial-placement heuristic feels gross
> when we're, at least ideologically, moving toward "software defined memor=
y".
>
> Personally I think the movement mechanism is a good idea that gets folks
> where they're going sooner, and it doesn't hurt anything by existing. We
> can change the initial placement mechanism too.

I think providing users a way to "FIX" the memory tiering is a backup
option. Given that DDRs with different access characteristics provide
the relevant CDAT/HMAT information, the kernel should be able to
correctly establish memory tiering on boot.
Current memory tiering code has
1) memory_tier_init() to iterate through all boot onlined memory
nodes. All nodes are assumed to be fast tier (adistance
MEMTIER_ADISTANCE_DRAM is used).
2) dev_dax_kmem_probe to iterate through all devdax controlled memory
nodes. This is the place the kernel reads the memory attributes from
HMAT and recognizes the memory nodes into the correct tier (devdax
controlled CXL, pmem, etc).
If we want DDRs with different memory characteristics to be put into
the correct tier (as in the guest VM memory tiering case), we probably
need a third path to iterate the boot onlined memory nodes and also be
able to read their memory attributes. I don't think we can do that in
1) because the ACPI subsystem is not yet initialized.

>
> </2cents>
>
> ~Gregory

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from mgamail.intel.com (mgamail.intel.com [134.134.136.100])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 1A6BC381B7;
	Fri, 12 Jan 2024 07:02:15 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=none dis=none) header.from=intel.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=intel.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=intel.com header.i=@intel.com header.b="TfZRTwGC"
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple;
  d=intel.com; i=@intel.com; q=dns/txt; s=Intel;
  t=1705042936; x=1736578936;
  h=from:to:cc:subject:in-reply-to:references:date:
   message-id:mime-version:content-transfer-encoding;
  bh=OSuL1hJdmHek9yEXuog1b29OXiHJirwFDLGzpcTvJXo=;
  b=TfZRTwGCltPTUz0IkhbH8fiPsDeTXuxNoDoVMBMIm691mQs2rOODRXvE
   G9lQ7TY1QvzPA8Wfo1FgqIJHh/HSMdhYSa+BadVOjMGpbE9RuT4vusQcD
   TDu61EnESLrhQ/ui2Bk9VN1xbu70MN82EHJHblZMS5tHQdYBAztNHC4Bf
   34JrYxfBb5Cml654b6Ubir4TYLlNw2fCj/HPxksQetRIvXGmacRrh5fG7
   Fzay8j1hirinKNr4/6HMM8UlTnLF2cQHRomcMlpvTS6/uav+Gu12lqFQg
   a+uR6F0hMgiKEkK5aa/z1KsAPRDKRvINRiP7f7G7sqCdQ5ya+dyWo/AC4
   Q==;
X-IronPort-AV: E=McAfee;i="6600,9927,10950"; a="465483924"
X-IronPort-AV: E=Sophos;i="6.04,188,1695711600"; 
   d="scan'208";a="465483924"
Received: from orsmga006.jf.intel.com ([10.7.209.51])
  by orsmga105.jf.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 11 Jan 2024 23:02:15 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=McAfee;i="6600,9927,10950"; a="759049624"
X-IronPort-AV: E=Sophos;i="6.04,188,1695711600"; 
   d="scan'208";a="759049624"
Received: from yhuang6-desk2.sh.intel.com (HELO yhuang6-desk2.ccr.corp.intel.com) ([10.238.208.55])
  by orsmga006-auth.jf.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 11 Jan 2024 23:02:10 -0800
From: "Huang, Ying" <ying.huang@intel.com>
To: Hao Xiang <hao.xiang@bytedance.com>,  "aneesh.kumar@linux.ibm.com"
 <aneesh.kumar@linux.ibm.com>
Cc: Jonathan Cameron <Jonathan.Cameron@huawei.com>,  Gregory Price
 <gregory.price@memverge.com>,  Srinivasulu Thanneeru
 <sthanneeru@micron.com>,  Srinivasulu Opensrc
 <sthanneeru.opensrc@micron.com>,  "linux-cxl@vger.kernel.org"
 <linux-cxl@vger.kernel.org>,  "linux-mm@kvack.org" <linux-mm@kvack.org>,
  "dan.j.williams@intel.com" <dan.j.williams@intel.com>,  "mhocko@suse.com"
 <mhocko@suse.com>,  "tj@kernel.org" <tj@kernel.org>,
  "john@jagalactic.com" <john@jagalactic.com>,  Eishan Mirakhur
 <emirakhur@micron.com>,  Vinicius Tavares Petrucci
 <vtavarespetr@micron.com>,  Ravis OpenSrc <Ravis.OpenSrc@micron.com>,
  "linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>,  Johannes
 Weiner <hannes@cmpxchg.org>,  Wei Xu <weixugc@google.com>,  "Ho-Ren (Jack)
 Chuang" <horenchuang@bytedance.com>
Subject: Re: [External] Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration
 between memory tiers
In-Reply-To: <CAAYibXgwqY6Og_4NqGGEni=2Xgx=DPxaMc3GdBUE6FREKVCq8w@mail.gmail.com>
	(Hao Xiang's message of "Wed, 10 Jan 2024 11:29:14 -0800")
References: <87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87wmspbpma.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZZwrIoP9+ey7rp3C@memverge.com>
	<87o7dv897s.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<20240109155049.00003f13@Huawei.com> <ZZ2Jd7/7rFD0o5S3@memverge.com>
	<CAAYibXhe81ez06tP5K7zGkX9P=Ot+DcSysVyDvh13aSEDD63aA@mail.gmail.com>
	<20240110141821.0000370d@Huawei.com>
	<CAAYibXgwqY6Og_4NqGGEni=2Xgx=DPxaMc3GdBUE6FREKVCq8w@mail.gmail.com>
Date: Fri, 12 Jan 2024 15:00:12 +0800
Message-ID: <87il3z2g03.fsf@yhuang6-desk2.ccr.corp.intel.com>
User-Agent: Gnus/5.13 (Gnus v5.13)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

Hao Xiang <hao.xiang@bytedance.com> writes:

> On Wed, Jan 10, 2024 at 6:18=E2=80=AFAM Jonathan Cameron
> <Jonathan.Cameron@huawei.com> wrote:
>>
>> On Tue, 9 Jan 2024 16:28:15 -0800
>> Hao Xiang <hao.xiang@bytedance.com> wrote:
>>
>> > On Tue, Jan 9, 2024 at 9:59=E2=80=AFAM Gregory Price <gregory.price@me=
mverge.com> wrote:
>> > >
>> > > On Tue, Jan 09, 2024 at 03:50:49PM +0000, Jonathan Cameron wrote:
>> > > > On Tue, 09 Jan 2024 11:41:11 +0800
>> > > > "Huang, Ying" <ying.huang@intel.com> wrote:
>> > > > > Gregory Price <gregory.price@memverge.com> writes:
>> > > > > > On Thu, Jan 04, 2024 at 02:05:01PM +0800, Huang, Ying wrote:
>> > > > > It's possible to change the performance of a NUMA node changed, =
if we
>> > > > > hot-remove a memory device, then hot-add another different memory
>> > > > > device.  It's hoped that the CDAT changes too.
>> > > >
>> > > > Not supported, but ACPI has _HMA methods to in theory allow changi=
ng
>> > > > HMAT values based on firmware notifications...  So we 'could' make
>> > > > it work for HMAT based description.
>> > > >
>> > > > Ultimately my current thinking is we'll end up emulating CXL type3
>> > > > devices (hiding topology complexity) and you can update CDAT but
>> > > > IIRC that is only meant to be for degraded situations - so if you
>> > > > want multiple performance regions, CDAT should describe them form =
the start.
>> > > >
>> > >
>> > > That was my thought.  I don't think it's particularly *realistic* for
>> > > HMAT/CDAT values to change at runtime, but I can imagine a case where
>> > > it could be valuable.
>> > >
>> > > > > > https://lore.kernel.org/linux-cxl/CAAYibXjZ0HSCqMrzXGv62cMLncS=
_81R3e1uNV5Fu4CPm0zAtYw@mail.gmail.com/
>> > > > > >
>> > > > > > This group wants to enable passing CXL memory through to KVM/Q=
EMU
>> > > > > > (i.e. host CXL expander memory passed through to the guest), a=
nd
>> > > > > > allow the guest to apply memory tiering.
>> > > > > >
>> > > > > > There are multiple issues with this, presently:
>> > > > > >
>> > > > > > 1. The QEMU CXL virtual device is not and probably never will =
be
>> > > > > >    performant enough to be a commodity class virtualization.
>> > > >
>> > > > I'd flex that a bit - we will end up with a solution for virtualiz=
ation but
>> > > > it isn't the emulation that is there today because it's not possib=
le to
>> > > > emulate some of the topology in a peformant manner (interleaving w=
ith sub
>> > > > page granularity / interleaving at all (to a lesser degree)). Ther=
e are
>> > > > ways to do better than we are today, but they start to look like
>> > > > software dissagregated memory setups (think lots of page faults in=
 the host).
>> > > >
>> > >
>> > > Agreed, the emulated device as-is can't be the virtualization device,
>> > > but it doesn't mean it can't be the basis for it.
>> > >
>> > > My thought is, if you want to pass host CXL *memory* through to the
>> > > guest, you don't actually care to pass CXL *control* through to the
>> > > guest.  That control lies pretty squarely with the host/hypervisor.
>> > >
>> > > So, at least in theory, you can just cut the type3 device out of the
>> > > QEMU configuration entirely and just pass it through as a distinct n=
uma
>> > > node with specific hmat qualities.
>> > >
>> > > Barring that, if we must go through the type3 device, the question is
>> > > how difficult would it be to just make a stripped down type3 device
>> > > to provide the informational components, but hack off anything
>> > > topology/interleave related? Then you just do direct passthrough as =
you
>> > > described below.
>> > >
>> > > qemu/kvm would report errors if you tried to touch the naughty bits.
>> > >
>> > > The second question is... is that device "compliant" or does it need
>> > > super special handling from the kernel driver :D?  If what i describ=
ed
>> > > is not "compliant", then it's probably a bad idea, and KVM/QEMU shou=
ld
>> > > just hide the CXL device entirely from the guest (for this use case)
>> > > and just pass the memory through as a numa node.
>> > >
>> > > Which gets us back to: The memory-tiering component needs a way to
>> > > place nodes in different tiers based on HMAT/CDAT/User Whim. All thr=
ee
>> > > of those seem like totally valid ways to go about it.
>> > >
>> > > > > >
>> > > > > > 2. When passing memory through as an explicit NUMA node, but n=
ot as
>> > > > > >    part of a CXL memory device, the nodes are lumped together =
in the
>> > > > > >    DRAM tier.
>> > > > > >
>> > > > > > None of this has to do with firmware.
>> > > > > >
>> > > > > > Memory-type is an awful way of denoting membership of a tier, =
but we
>> > > > > > have HMAT information that can be passed through via QEMU:
>> > > > > >
>> > > > > > -object memory-backend-ram,size=3D4G,id=3Dram-node0 \
>> > > > > > -object memory-backend-ram,size=3D4G,id=3Dram-node1 \
>> > > > > > -numa node,nodeid=3D0,cpus=3D0-4,memdev=3Dram-node0 \
>> > > > > > -numa node,initiator=3D0,nodeid=3D1,memdev=3Dram-node1 \
>> > > > > > -numa hmat-lb,initiator=3D0,target=3D0,hierarchy=3Dmemory,data=
-type=3Daccess-latency,latency=3D10 \
>> > > > > > -numa hmat-lb,initiator=3D0,target=3D0,hierarchy=3Dmemory,data=
-type=3Daccess-bandwidth,bandwidth=3D10485760 \
>> > > > > > -numa hmat-lb,initiator=3D0,target=3D1,hierarchy=3Dmemory,data=
-type=3Daccess-latency,latency=3D20 \
>> > > > > > -numa hmat-lb,initiator=3D0,target=3D1,hierarchy=3Dmemory,data=
-type=3Daccess-bandwidth,bandwidth=3D5242880
>> > > > > >
>> > > > > > Not only would it be nice if we could change tier membership b=
ased on
>> > > > > > this data, it's realistically the only way to allow guests to =
accomplish
>> > > > > > memory tiering w/ KVM/QEMU and CXL memory passed through to th=
e guest.
>> > > >
>> > > > This I fully agree with.  There will be systems with a bunch of no=
rmal DDR with different
>> > > > access characteristics irrespective of CXL. + likely HMAT solution=
s will be used
>> > > > before we get anything more complex in place for CXL.
>> > > >
>> > >
>> > > Had not even considered this, but that's completely accurate as well.
>> > >
>> > > And more discretely: What of devices that don't provide HMAT/CDAT? T=
hat
>> > > isn't necessarily a violation of any standard.  There probably could=
 be
>> > > a release valve for us to still make those devices useful.
>> > >
>> > > The concern I have with not implementing a movement mechanism *at al=
l*
>> > > is that a one-size-fits-all initial-placement heuristic feels gross
>> > > when we're, at least ideologically, moving toward "software defined =
memory".
>> > >
>> > > Personally I think the movement mechanism is a good idea that gets f=
olks
>> > > where they're going sooner, and it doesn't hurt anything by existing=
. We
>> > > can change the initial placement mechanism too.
>> >
>> > I think providing users a way to "FIX" the memory tiering is a backup
>> > option. Given that DDRs with different access characteristics provide
>> > the relevant CDAT/HMAT information, the kernel should be able to
>> > correctly establish memory tiering on boot.
>>
>> Include hotplug and I'll be happier!  I know that's messy though.
>>
>> > Current memory tiering code has
>> > 1) memory_tier_init() to iterate through all boot onlined memory
>> > nodes. All nodes are assumed to be fast tier (adistance
>> > MEMTIER_ADISTANCE_DRAM is used).
>> > 2) dev_dax_kmem_probe to iterate through all devdax controlled memory
>> > nodes. This is the place the kernel reads the memory attributes from
>> > HMAT and recognizes the memory nodes into the correct tier (devdax
>> > controlled CXL, pmem, etc).
>> > If we want DDRs with different memory characteristics to be put into
>> > the correct tier (as in the guest VM memory tiering case), we probably
>> > need a third path to iterate the boot onlined memory nodes and also be
>> > able to read their memory attributes. I don't think we can do that in
>> > 1) because the ACPI subsystem is not yet initialized.
>>
>> Can we move it later in general?  Or drag HMAT parsing earlier?
>> ACPI table availability is pretty early, it's just that we don't bother
>> with HMAT because nothing early uses it.
>> IIRC SRAT parsing occurs way before memory_tier_init() will be called.
>
> I tested the call sequence under a debugger earlier. hmat_init() is
> called after memory_tier_init(). Let me poke around and see what our
> options are.

This sounds reasonable.

Please keep in mind that we need a way to identify the base line memory
type(default_dram_type).  A simple method is to use NUMA nodes with CPU
attached.  But I remember that Aneesh said that some NUMA nodes without
CPU will need to be put in default_dram_type too on their systems.  We
need a way to identify that.

--
Best Regards,
Huang, Ying

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from mail-ed1-f46.google.com (mail-ed1-f46.google.com [209.85.208.46])
	(using TLSv1.2 with cipher ECDHE-RSA-AES128-GCM-SHA256 (128/128 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 34E234E1D0
	for <linux-cxl@vger.kernel.org>; Wed, 10 Jan 2024 19:29:27 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=quarantine dis=none) header.from=bytedance.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=bytedance.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=bytedance.com header.i=@bytedance.com header.b="WvQqHhrA"
Received: by mail-ed1-f46.google.com with SMTP id 4fb4d7f45d1cf-557535489d0so5260434a12.2
        for <linux-cxl@vger.kernel.org>; Wed, 10 Jan 2024 11:29:27 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=bytedance.com; s=google; t=1704914966; x=1705519766; darn=vger.kernel.org;
        h=content-transfer-encoding:cc:to:subject:message-id:date:from
         :in-reply-to:references:mime-version:from:to:cc:subject:date
         :message-id:reply-to;
        bh=XF/kkrIsaG794mVwrrAfpZE9995QUYT1bMP4o8ReX7Q=;
        b=WvQqHhrARPDegULMf10+YOiuYdEb2EPK7z5S38HyCs3NtQmfXDevGtYsZlw+hSaESo
         V4N8UACkXj5xUauBJRspcEevoPcdnOrN1DCqUMV020H42NnfJ1w++Wf9y09JO6Seppxc
         6MmwPbG30riRLNmjIEBb3dH+y5QjQNybsnKIn/LkWE8kGy4MPIelqX73ek1Wux3fgP8k
         /OIkbAlc9pjJ4VovD2Ay2lMdjA17TZVSeHgAW1XAH+esJOm5VQonxZY58V5jgqo32M/Q
         YAeElTeEVaQFXdbDi+PyISNnkgFvraFP6qSRiKZKc8LVPnrlZ6Tg7U5zhG8tGkITxf9K
         /tSw==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20230601; t=1704914966; x=1705519766;
        h=content-transfer-encoding:cc:to:subject:message-id:date:from
         :in-reply-to:references:mime-version:x-gm-message-state:from:to:cc
         :subject:date:message-id:reply-to;
        bh=XF/kkrIsaG794mVwrrAfpZE9995QUYT1bMP4o8ReX7Q=;
        b=j3L6H/bfM06gcPtENHJgPEzO1/3jBIvk5vmLhOm3E1/WkQfI8dPYH/uyALPcDv1K6X
         l4nzq/Q4Sw1hw/konkRl+9xWJ5be27TG/63J01wYDBqLHxh2tVSLrditPZdFeREUy12P
         IaHuz7dPPDB0z+ZWk+3nBvvAY69hIHB3c0NrYnse/li8MHlmlSPttXecacK63WcxfqTO
         A+WGSrsaosH0uL0gQj3uskt+yrffwSPy0cFNswppoMy8cyfksPn+TCsP7vi/aUYOcqfM
         YYQTCbdo5OKDbmiesSfJEEV/wS76I5bVs50ooFVd6/lhMSx+j3v6Ib5vaCv4EvKYPK12
         9B9Q==
X-Gm-Message-State: AOJu0Ywk+AOOWIjRsSYsroe5ojdY3PKdOmWd+1u2uKlfIFR9frxurx1E
	lVqlshgwoXzg92dLjmEQ2Vc4anzhO9aToTeVzuWBe/e0eqfGrw==
X-Google-Smtp-Source: AGHT+IGvbQcEEgvmp16OVS1C36qH64KspcuiSNtSm+dV5L85ETMA6+jldtw2mOoqiHwjDJy0RzCb258FX3Elz9K8krs=
X-Received: by 2002:a17:907:9606:b0:a28:9d4e:f065 with SMTP id
 gb6-20020a170907960600b00a289d4ef065mr16815ejc.13.1704914966385; Wed, 10 Jan
 2024 11:29:26 -0800 (PST)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
References: <87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
 <PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com> <PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com> <PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87wmspbpma.fsf@yhuang6-desk2.ccr.corp.intel.com> <ZZwrIoP9+ey7rp3C@memverge.com>
 <87o7dv897s.fsf@yhuang6-desk2.ccr.corp.intel.com> <20240109155049.00003f13@Huawei.com>
 <ZZ2Jd7/7rFD0o5S3@memverge.com> <CAAYibXhe81ez06tP5K7zGkX9P=Ot+DcSysVyDvh13aSEDD63aA@mail.gmail.com>
 <20240110141821.0000370d@Huawei.com>
In-Reply-To: <20240110141821.0000370d@Huawei.com>
From: Hao Xiang <hao.xiang@bytedance.com>
Date: Wed, 10 Jan 2024 11:29:14 -0800
Message-ID: <CAAYibXgwqY6Og_4NqGGEni=2Xgx=DPxaMc3GdBUE6FREKVCq8w@mail.gmail.com>
Subject: Re: [External] Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration
 between memory tiers
To: Jonathan Cameron <Jonathan.Cameron@huawei.com>
Cc: Gregory Price <gregory.price@memverge.com>, "Huang, Ying" <ying.huang@intel.com>, 
	Srinivasulu Thanneeru <sthanneeru@micron.com>, Srinivasulu Opensrc <sthanneeru.opensrc@micron.com>, 
	"linux-cxl@vger.kernel.org" <linux-cxl@vger.kernel.org>, "linux-mm@kvack.org" <linux-mm@kvack.org>, 
	"aneesh.kumar@linux.ibm.com" <aneesh.kumar@linux.ibm.com>, 
	"dan.j.williams@intel.com" <dan.j.williams@intel.com>, "mhocko@suse.com" <mhocko@suse.com>, 
	"tj@kernel.org" <tj@kernel.org>, "john@jagalactic.com" <john@jagalactic.com>, 
	Eishan Mirakhur <emirakhur@micron.com>, Vinicius Tavares Petrucci <vtavarespetr@micron.com>, 
	Ravis OpenSrc <Ravis.OpenSrc@micron.com>, 
	"linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>, Johannes Weiner <hannes@cmpxchg.org>, 
	Wei Xu <weixugc@google.com>, "Ho-Ren (Jack) Chuang" <horenchuang@bytedance.com>
Content-Type: text/plain; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

On Wed, Jan 10, 2024 at 6:18=E2=80=AFAM Jonathan Cameron
<Jonathan.Cameron@huawei.com> wrote:
>
> On Tue, 9 Jan 2024 16:28:15 -0800
> Hao Xiang <hao.xiang@bytedance.com> wrote:
>
> > On Tue, Jan 9, 2024 at 9:59=E2=80=AFAM Gregory Price <gregory.price@mem=
verge.com> wrote:
> > >
> > > On Tue, Jan 09, 2024 at 03:50:49PM +0000, Jonathan Cameron wrote:
> > > > On Tue, 09 Jan 2024 11:41:11 +0800
> > > > "Huang, Ying" <ying.huang@intel.com> wrote:
> > > > > Gregory Price <gregory.price@memverge.com> writes:
> > > > > > On Thu, Jan 04, 2024 at 02:05:01PM +0800, Huang, Ying wrote:
> > > > > It's possible to change the performance of a NUMA node changed, i=
f we
> > > > > hot-remove a memory device, then hot-add another different memory
> > > > > device.  It's hoped that the CDAT changes too.
> > > >
> > > > Not supported, but ACPI has _HMA methods to in theory allow changin=
g
> > > > HMAT values based on firmware notifications...  So we 'could' make
> > > > it work for HMAT based description.
> > > >
> > > > Ultimately my current thinking is we'll end up emulating CXL type3
> > > > devices (hiding topology complexity) and you can update CDAT but
> > > > IIRC that is only meant to be for degraded situations - so if you
> > > > want multiple performance regions, CDAT should describe them form t=
he start.
> > > >
> > >
> > > That was my thought.  I don't think it's particularly *realistic* for
> > > HMAT/CDAT values to change at runtime, but I can imagine a case where
> > > it could be valuable.
> > >
> > > > > > https://lore.kernel.org/linux-cxl/CAAYibXjZ0HSCqMrzXGv62cMLncS_=
81R3e1uNV5Fu4CPm0zAtYw@mail.gmail.com/
> > > > > >
> > > > > > This group wants to enable passing CXL memory through to KVM/QE=
MU
> > > > > > (i.e. host CXL expander memory passed through to the guest), an=
d
> > > > > > allow the guest to apply memory tiering.
> > > > > >
> > > > > > There are multiple issues with this, presently:
> > > > > >
> > > > > > 1. The QEMU CXL virtual device is not and probably never will b=
e
> > > > > >    performant enough to be a commodity class virtualization.
> > > >
> > > > I'd flex that a bit - we will end up with a solution for virtualiza=
tion but
> > > > it isn't the emulation that is there today because it's not possibl=
e to
> > > > emulate some of the topology in a peformant manner (interleaving wi=
th sub
> > > > page granularity / interleaving at all (to a lesser degree)). There=
 are
> > > > ways to do better than we are today, but they start to look like
> > > > software dissagregated memory setups (think lots of page faults in =
the host).
> > > >
> > >
> > > Agreed, the emulated device as-is can't be the virtualization device,
> > > but it doesn't mean it can't be the basis for it.
> > >
> > > My thought is, if you want to pass host CXL *memory* through to the
> > > guest, you don't actually care to pass CXL *control* through to the
> > > guest.  That control lies pretty squarely with the host/hypervisor.
> > >
> > > So, at least in theory, you can just cut the type3 device out of the
> > > QEMU configuration entirely and just pass it through as a distinct nu=
ma
> > > node with specific hmat qualities.
> > >
> > > Barring that, if we must go through the type3 device, the question is
> > > how difficult would it be to just make a stripped down type3 device
> > > to provide the informational components, but hack off anything
> > > topology/interleave related? Then you just do direct passthrough as y=
ou
> > > described below.
> > >
> > > qemu/kvm would report errors if you tried to touch the naughty bits.
> > >
> > > The second question is... is that device "compliant" or does it need
> > > super special handling from the kernel driver :D?  If what i describe=
d
> > > is not "compliant", then it's probably a bad idea, and KVM/QEMU shoul=
d
> > > just hide the CXL device entirely from the guest (for this use case)
> > > and just pass the memory through as a numa node.
> > >
> > > Which gets us back to: The memory-tiering component needs a way to
> > > place nodes in different tiers based on HMAT/CDAT/User Whim. All thre=
e
> > > of those seem like totally valid ways to go about it.
> > >
> > > > > >
> > > > > > 2. When passing memory through as an explicit NUMA node, but no=
t as
> > > > > >    part of a CXL memory device, the nodes are lumped together i=
n the
> > > > > >    DRAM tier.
> > > > > >
> > > > > > None of this has to do with firmware.
> > > > > >
> > > > > > Memory-type is an awful way of denoting membership of a tier, b=
ut we
> > > > > > have HMAT information that can be passed through via QEMU:
> > > > > >
> > > > > > -object memory-backend-ram,size=3D4G,id=3Dram-node0 \
> > > > > > -object memory-backend-ram,size=3D4G,id=3Dram-node1 \
> > > > > > -numa node,nodeid=3D0,cpus=3D0-4,memdev=3Dram-node0 \
> > > > > > -numa node,initiator=3D0,nodeid=3D1,memdev=3Dram-node1 \
> > > > > > -numa hmat-lb,initiator=3D0,target=3D0,hierarchy=3Dmemory,data-=
type=3Daccess-latency,latency=3D10 \
> > > > > > -numa hmat-lb,initiator=3D0,target=3D0,hierarchy=3Dmemory,data-=
type=3Daccess-bandwidth,bandwidth=3D10485760 \
> > > > > > -numa hmat-lb,initiator=3D0,target=3D1,hierarchy=3Dmemory,data-=
type=3Daccess-latency,latency=3D20 \
> > > > > > -numa hmat-lb,initiator=3D0,target=3D1,hierarchy=3Dmemory,data-=
type=3Daccess-bandwidth,bandwidth=3D5242880
> > > > > >
> > > > > > Not only would it be nice if we could change tier membership ba=
sed on
> > > > > > this data, it's realistically the only way to allow guests to a=
ccomplish
> > > > > > memory tiering w/ KVM/QEMU and CXL memory passed through to the=
 guest.
> > > >
> > > > This I fully agree with.  There will be systems with a bunch of nor=
mal DDR with different
> > > > access characteristics irrespective of CXL. + likely HMAT solutions=
 will be used
> > > > before we get anything more complex in place for CXL.
> > > >
> > >
> > > Had not even considered this, but that's completely accurate as well.
> > >
> > > And more discretely: What of devices that don't provide HMAT/CDAT? Th=
at
> > > isn't necessarily a violation of any standard.  There probably could =
be
> > > a release valve for us to still make those devices useful.
> > >
> > > The concern I have with not implementing a movement mechanism *at all=
*
> > > is that a one-size-fits-all initial-placement heuristic feels gross
> > > when we're, at least ideologically, moving toward "software defined m=
emory".
> > >
> > > Personally I think the movement mechanism is a good idea that gets fo=
lks
> > > where they're going sooner, and it doesn't hurt anything by existing.=
 We
> > > can change the initial placement mechanism too.
> >
> > I think providing users a way to "FIX" the memory tiering is a backup
> > option. Given that DDRs with different access characteristics provide
> > the relevant CDAT/HMAT information, the kernel should be able to
> > correctly establish memory tiering on boot.
>
> Include hotplug and I'll be happier!  I know that's messy though.
>
> > Current memory tiering code has
> > 1) memory_tier_init() to iterate through all boot onlined memory
> > nodes. All nodes are assumed to be fast tier (adistance
> > MEMTIER_ADISTANCE_DRAM is used).
> > 2) dev_dax_kmem_probe to iterate through all devdax controlled memory
> > nodes. This is the place the kernel reads the memory attributes from
> > HMAT and recognizes the memory nodes into the correct tier (devdax
> > controlled CXL, pmem, etc).
> > If we want DDRs with different memory characteristics to be put into
> > the correct tier (as in the guest VM memory tiering case), we probably
> > need a third path to iterate the boot onlined memory nodes and also be
> > able to read their memory attributes. I don't think we can do that in
> > 1) because the ACPI subsystem is not yet initialized.
>
> Can we move it later in general?  Or drag HMAT parsing earlier?
> ACPI table availability is pretty early, it's just that we don't bother
> with HMAT because nothing early uses it.
> IIRC SRAT parsing occurs way before memory_tier_init() will be called.

I tested the call sequence under a debugger earlier. hmat_init() is
called after memory_tier_init(). Let me poke around and see what our
options are.

>
> Jonathan
>
>
>
> >
> > >
> > > </2cents>
> > >
> > > ~Gregory
>

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from mgamail.intel.com (mgamail.intel.com [192.55.52.93])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id BA17315A8;
	Mon, 15 Jan 2024 01:26:18 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=none dis=none) header.from=intel.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=intel.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=intel.com header.i=@intel.com header.b="akUr5ml6"
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/simple;
  d=intel.com; i=@intel.com; q=dns/txt; s=Intel;
  t=1705281978; x=1736817978;
  h=from:to:cc:subject:in-reply-to:references:date:
   message-id:mime-version:content-transfer-encoding;
  bh=RAN96hU9YlRYVx95l6KQuFTyks7KtMSlSqiqq5bKzoM=;
  b=akUr5ml6h/mmpYIXdPz/3014bTZyZyXayEjUSoDmphoGFLUINd+qyXN1
   3D4IHU3RrrDxmJGPN/gln1y8t8nowqvou2aYN/iewwmq7vcBuezq8Amzl
   o/oa36hHb7jxkssptNxdnCidV3YG6Qbe5YzksOrlEjJuFalqB5Jsld5Zr
   5Ac8eDOY2aezz7bcgUWHlceUUWMXMFsGgMeahylk2KJnVwVSp1DT1fC/B
   v3JMjaYhKkRHX1o4nxurqhADSzJEv7HLX8poJZvJOAGybWUlFfT+bZB5k
   fs9yUgD1n5fqathgDcs2lRVuS0EhAz8o61XRuZpdBSYac8ATX8TeS0CvE
   Q==;
X-IronPort-AV: E=McAfee;i="6600,9927,10953"; a="396653515"
X-IronPort-AV: E=Sophos;i="6.04,195,1695711600"; 
   d="scan'208";a="396653515"
Received: from orsmga002.jf.intel.com ([10.7.209.21])
  by fmsmga102.fm.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 14 Jan 2024 17:26:17 -0800
X-ExtLoop1: 1
X-IronPort-AV: E=McAfee;i="6600,9927,10953"; a="783653565"
X-IronPort-AV: E=Sophos;i="6.04,195,1695711600"; 
   d="scan'208";a="783653565"
Received: from yhuang6-desk2.sh.intel.com (HELO yhuang6-desk2.ccr.corp.intel.com) ([10.238.208.55])
  by orsmga002-auth.jf.intel.com with ESMTP/TLS/ECDHE-RSA-AES256-GCM-SHA384; 14 Jan 2024 17:26:11 -0800
From: "Huang, Ying" <ying.huang@intel.com>
To: Hao Xiang <hao.xiang@bytedance.com>
Cc: "aneesh.kumar@linux.ibm.com" <aneesh.kumar@linux.ibm.com>,  Jonathan
 Cameron <Jonathan.Cameron@huawei.com>,  Gregory Price
 <gregory.price@memverge.com>,  Srinivasulu Thanneeru
 <sthanneeru@micron.com>,  Srinivasulu Opensrc
 <sthanneeru.opensrc@micron.com>,  "linux-cxl@vger.kernel.org"
 <linux-cxl@vger.kernel.org>,  "linux-mm@kvack.org" <linux-mm@kvack.org>,
  "dan.j.williams@intel.com" <dan.j.williams@intel.com>,  "mhocko@suse.com"
 <mhocko@suse.com>,  "tj@kernel.org" <tj@kernel.org>,
  "john@jagalactic.com" <john@jagalactic.com>,  Eishan Mirakhur
 <emirakhur@micron.com>,  Vinicius Tavares Petrucci
 <vtavarespetr@micron.com>,  Ravis OpenSrc <Ravis.OpenSrc@micron.com>,
  "linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>,  Johannes
 Weiner <hannes@cmpxchg.org>,  Wei Xu <weixugc@google.com>,  "Ho-Ren (Jack)
 Chuang" <horenchuang@bytedance.com>
Subject: Re: [External] Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration
 between memory tiers
In-Reply-To: <CAAYibXh5DWcAJrqXi-V1v61DY_Xeb8BiMGoOxn1fJ_YBc2L8KQ@mail.gmail.com>
	(Hao Xiang's message of "Fri, 12 Jan 2024 00:14:04 -0800")
References: <87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
	<87wmspbpma.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<ZZwrIoP9+ey7rp3C@memverge.com>
	<87o7dv897s.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<20240109155049.00003f13@Huawei.com> <ZZ2Jd7/7rFD0o5S3@memverge.com>
	<CAAYibXhe81ez06tP5K7zGkX9P=Ot+DcSysVyDvh13aSEDD63aA@mail.gmail.com>
	<20240110141821.0000370d@Huawei.com>
	<CAAYibXgwqY6Og_4NqGGEni=2Xgx=DPxaMc3GdBUE6FREKVCq8w@mail.gmail.com>
	<87il3z2g03.fsf@yhuang6-desk2.ccr.corp.intel.com>
	<CAAYibXh5DWcAJrqXi-V1v61DY_Xeb8BiMGoOxn1fJ_YBc2L8KQ@mail.gmail.com>
Date: Mon, 15 Jan 2024 09:24:13 +0800
Message-ID: <871qaj2xtu.fsf@yhuang6-desk2.ccr.corp.intel.com>
User-Agent: Gnus/5.13 (Gnus v5.13)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

Hao Xiang <hao.xiang@bytedance.com> writes:

> On Thu, Jan 11, 2024 at 11:02=E2=80=AFPM Huang, Ying <ying.huang@intel.co=
m> wrote:
>>
>> Hao Xiang <hao.xiang@bytedance.com> writes:
>>
>> > On Wed, Jan 10, 2024 at 6:18=E2=80=AFAM Jonathan Cameron
>> > <Jonathan.Cameron@huawei.com> wrote:
>> >>
>> >> On Tue, 9 Jan 2024 16:28:15 -0800
>> >> Hao Xiang <hao.xiang@bytedance.com> wrote:
>> >>
>> >> > On Tue, Jan 9, 2024 at 9:59=E2=80=AFAM Gregory Price <gregory.price=
@memverge.com> wrote:
>> >> > >
>> >> > > On Tue, Jan 09, 2024 at 03:50:49PM +0000, Jonathan Cameron wrote:
>> >> > > > On Tue, 09 Jan 2024 11:41:11 +0800
>> >> > > > "Huang, Ying" <ying.huang@intel.com> wrote:
>> >> > > > > Gregory Price <gregory.price@memverge.com> writes:
>> >> > > > > > On Thu, Jan 04, 2024 at 02:05:01PM +0800, Huang, Ying wrote:
>> >> > > > > It's possible to change the performance of a NUMA node change=
d, if we
>> >> > > > > hot-remove a memory device, then hot-add another different me=
mory
>> >> > > > > device.  It's hoped that the CDAT changes too.
>> >> > > >
>> >> > > > Not supported, but ACPI has _HMA methods to in theory allow cha=
nging
>> >> > > > HMAT values based on firmware notifications...  So we 'could' m=
ake
>> >> > > > it work for HMAT based description.
>> >> > > >
>> >> > > > Ultimately my current thinking is we'll end up emulating CXL ty=
pe3
>> >> > > > devices (hiding topology complexity) and you can update CDAT but
>> >> > > > IIRC that is only meant to be for degraded situations - so if y=
ou
>> >> > > > want multiple performance regions, CDAT should describe them fo=
rm the start.
>> >> > > >
>> >> > >
>> >> > > That was my thought.  I don't think it's particularly *realistic*=
 for
>> >> > > HMAT/CDAT values to change at runtime, but I can imagine a case w=
here
>> >> > > it could be valuable.
>> >> > >
>> >> > > > > > https://lore.kernel.org/linux-cxl/CAAYibXjZ0HSCqMrzXGv62cML=
ncS_81R3e1uNV5Fu4CPm0zAtYw@mail.gmail.com/
>> >> > > > > >
>> >> > > > > > This group wants to enable passing CXL memory through to KV=
M/QEMU
>> >> > > > > > (i.e. host CXL expander memory passed through to the guest)=
, and
>> >> > > > > > allow the guest to apply memory tiering.
>> >> > > > > >
>> >> > > > > > There are multiple issues with this, presently:
>> >> > > > > >
>> >> > > > > > 1. The QEMU CXL virtual device is not and probably never wi=
ll be
>> >> > > > > >    performant enough to be a commodity class virtualization.
>> >> > > >
>> >> > > > I'd flex that a bit - we will end up with a solution for virtua=
lization but
>> >> > > > it isn't the emulation that is there today because it's not pos=
sible to
>> >> > > > emulate some of the topology in a peformant manner (interleavin=
g with sub
>> >> > > > page granularity / interleaving at all (to a lesser degree)). T=
here are
>> >> > > > ways to do better than we are today, but they start to look like
>> >> > > > software dissagregated memory setups (think lots of page faults=
 in the host).
>> >> > > >
>> >> > >
>> >> > > Agreed, the emulated device as-is can't be the virtualization dev=
ice,
>> >> > > but it doesn't mean it can't be the basis for it.
>> >> > >
>> >> > > My thought is, if you want to pass host CXL *memory* through to t=
he
>> >> > > guest, you don't actually care to pass CXL *control* through to t=
he
>> >> > > guest.  That control lies pretty squarely with the host/hyperviso=
r.
>> >> > >
>> >> > > So, at least in theory, you can just cut the type3 device out of =
the
>> >> > > QEMU configuration entirely and just pass it through as a distinc=
t numa
>> >> > > node with specific hmat qualities.
>> >> > >
>> >> > > Barring that, if we must go through the type3 device, the questio=
n is
>> >> > > how difficult would it be to just make a stripped down type3 devi=
ce
>> >> > > to provide the informational components, but hack off anything
>> >> > > topology/interleave related? Then you just do direct passthrough =
as you
>> >> > > described below.
>> >> > >
>> >> > > qemu/kvm would report errors if you tried to touch the naughty bi=
ts.
>> >> > >
>> >> > > The second question is... is that device "compliant" or does it n=
eed
>> >> > > super special handling from the kernel driver :D?  If what i desc=
ribed
>> >> > > is not "compliant", then it's probably a bad idea, and KVM/QEMU s=
hould
>> >> > > just hide the CXL device entirely from the guest (for this use ca=
se)
>> >> > > and just pass the memory through as a numa node.
>> >> > >
>> >> > > Which gets us back to: The memory-tiering component needs a way to
>> >> > > place nodes in different tiers based on HMAT/CDAT/User Whim. All =
three
>> >> > > of those seem like totally valid ways to go about it.
>> >> > >
>> >> > > > > >
>> >> > > > > > 2. When passing memory through as an explicit NUMA node, bu=
t not as
>> >> > > > > >    part of a CXL memory device, the nodes are lumped togeth=
er in the
>> >> > > > > >    DRAM tier.
>> >> > > > > >
>> >> > > > > > None of this has to do with firmware.
>> >> > > > > >
>> >> > > > > > Memory-type is an awful way of denoting membership of a tie=
r, but we
>> >> > > > > > have HMAT information that can be passed through via QEMU:
>> >> > > > > >
>> >> > > > > > -object memory-backend-ram,size=3D4G,id=3Dram-node0 \
>> >> > > > > > -object memory-backend-ram,size=3D4G,id=3Dram-node1 \
>> >> > > > > > -numa node,nodeid=3D0,cpus=3D0-4,memdev=3Dram-node0 \
>> >> > > > > > -numa node,initiator=3D0,nodeid=3D1,memdev=3Dram-node1 \
>> >> > > > > > -numa hmat-lb,initiator=3D0,target=3D0,hierarchy=3Dmemory,d=
ata-type=3Daccess-latency,latency=3D10 \
>> >> > > > > > -numa hmat-lb,initiator=3D0,target=3D0,hierarchy=3Dmemory,d=
ata-type=3Daccess-bandwidth,bandwidth=3D10485760 \
>> >> > > > > > -numa hmat-lb,initiator=3D0,target=3D1,hierarchy=3Dmemory,d=
ata-type=3Daccess-latency,latency=3D20 \
>> >> > > > > > -numa hmat-lb,initiator=3D0,target=3D1,hierarchy=3Dmemory,d=
ata-type=3Daccess-bandwidth,bandwidth=3D5242880
>> >> > > > > >
>> >> > > > > > Not only would it be nice if we could change tier membershi=
p based on
>> >> > > > > > this data, it's realistically the only way to allow guests =
to accomplish
>> >> > > > > > memory tiering w/ KVM/QEMU and CXL memory passed through to=
 the guest.
>> >> > > >
>> >> > > > This I fully agree with.  There will be systems with a bunch of=
 normal DDR with different
>> >> > > > access characteristics irrespective of CXL. + likely HMAT solut=
ions will be used
>> >> > > > before we get anything more complex in place for CXL.
>> >> > > >
>> >> > >
>> >> > > Had not even considered this, but that's completely accurate as w=
ell.
>> >> > >
>> >> > > And more discretely: What of devices that don't provide HMAT/CDAT=
? That
>> >> > > isn't necessarily a violation of any standard.  There probably co=
uld be
>> >> > > a release valve for us to still make those devices useful.
>> >> > >
>> >> > > The concern I have with not implementing a movement mechanism *at=
 all*
>> >> > > is that a one-size-fits-all initial-placement heuristic feels gro=
ss
>> >> > > when we're, at least ideologically, moving toward "software defin=
ed memory".
>> >> > >
>> >> > > Personally I think the movement mechanism is a good idea that get=
s folks
>> >> > > where they're going sooner, and it doesn't hurt anything by exist=
ing. We
>> >> > > can change the initial placement mechanism too.
>> >> >
>> >> > I think providing users a way to "FIX" the memory tiering is a back=
up
>> >> > option. Given that DDRs with different access characteristics provi=
de
>> >> > the relevant CDAT/HMAT information, the kernel should be able to
>> >> > correctly establish memory tiering on boot.
>> >>
>> >> Include hotplug and I'll be happier!  I know that's messy though.
>> >>
>> >> > Current memory tiering code has
>> >> > 1) memory_tier_init() to iterate through all boot onlined memory
>> >> > nodes. All nodes are assumed to be fast tier (adistance
>> >> > MEMTIER_ADISTANCE_DRAM is used).
>> >> > 2) dev_dax_kmem_probe to iterate through all devdax controlled memo=
ry
>> >> > nodes. This is the place the kernel reads the memory attributes from
>> >> > HMAT and recognizes the memory nodes into the correct tier (devdax
>> >> > controlled CXL, pmem, etc).
>> >> > If we want DDRs with different memory characteristics to be put into
>> >> > the correct tier (as in the guest VM memory tiering case), we proba=
bly
>> >> > need a third path to iterate the boot onlined memory nodes and also=
 be
>> >> > able to read their memory attributes. I don't think we can do that =
in
>> >> > 1) because the ACPI subsystem is not yet initialized.
>> >>
>> >> Can we move it later in general?  Or drag HMAT parsing earlier?
>> >> ACPI table availability is pretty early, it's just that we don't both=
er
>> >> with HMAT because nothing early uses it.
>> >> IIRC SRAT parsing occurs way before memory_tier_init() will be called.
>> >
>> > I tested the call sequence under a debugger earlier. hmat_init() is
>> > called after memory_tier_init(). Let me poke around and see what our
>> > options are.
>>
>> This sounds reasonable.
>>
>> Please keep in mind that we need a way to identify the base line memory
>> type(default_dram_type).  A simple method is to use NUMA nodes with CPU
>> attached.  But I remember that Aneesh said that some NUMA nodes without
>> CPU will need to be put in default_dram_type too on their systems.  We
>> need a way to identify that.
>
> Yes, I am doing some prototyping the way you described. In
> memory_tier_init(), we will just set the memory tier for the NUMA
> nodes with CPU. In hmat_init(), I am trying to call back to mm to
> finish the memory tier initialization for the CPUless NUMA nodes. If a
> CPUless numa node can't get the effective adistance from
> mt_calc_adistance(), we will fallback to add that node to
> default_dram_type.

Sound reasonable for me.

> The other thing I want to experiment is to call mt_calc_adistance() on
> a memory node with CPU and see what kind of adistance will be
> returned.

Anyway, we need a base line to start.  The abstract distance is
calculated based on the ratio of the performance of a node to that of
default DRAM node.

--
Best Regards,
Huang, Ying

From mboxrd@z Thu Jan  1 00:00:00 1970
Received: from mail-ed1-f52.google.com (mail-ed1-f52.google.com [209.85.208.52])
	(using TLSv1.2 with cipher ECDHE-RSA-AES128-GCM-SHA256 (128/128 bits))
	(No client certificate requested)
	by smtp.subspace.kernel.org (Postfix) with ESMTPS id 8C6355D8E0
	for <linux-cxl@vger.kernel.org>; Fri, 12 Jan 2024 08:14:17 +0000 (UTC)
Authentication-Results: smtp.subspace.kernel.org; dmarc=pass (p=quarantine dis=none) header.from=bytedance.com
Authentication-Results: smtp.subspace.kernel.org; spf=pass smtp.mailfrom=bytedance.com
Authentication-Results: smtp.subspace.kernel.org;
	dkim=pass (2048-bit key) header.d=bytedance.com header.i=@bytedance.com header.b="kmAvem62"
Received: by mail-ed1-f52.google.com with SMTP id 4fb4d7f45d1cf-5578485fc0eso5142649a12.1
        for <linux-cxl@vger.kernel.org>; Fri, 12 Jan 2024 00:14:17 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=bytedance.com; s=google; t=1705047256; x=1705652056; darn=vger.kernel.org;
        h=content-transfer-encoding:cc:to:subject:message-id:date:from
         :in-reply-to:references:mime-version:from:to:cc:subject:date
         :message-id:reply-to;
        bh=VKb3pXA3O7QJEj9qo6R8Br8Dqg0hH16HzN0jOTIU5CY=;
        b=kmAvem62xRtqzawnQQOaqI15wcoVqj92DAXCh0Rv6MfOzPs8rndR5I4Yutt6uGi9jk
         eIb5edVc8e92YMcnnQsdFiOPYXhc6/LNxt8ZVf5UCNHD2WiDYAXzGz/OZUqqQMsERtz3
         9a6YwW3rC0VOoSXut8mVzUwQKiYP7tiyVTcyjYaX5n2aBBIS0/ItHBoa1Q8EJR5CEcFl
         eoYxYsfyAaRHm/Czf/rf0TtMn65gNCMHFLkWASVWi6xLknItAZhb13PS6n28JeuRe3SO
         GRvMG7ujotqmMJiL0bhl0TxeNk7Rs7rN2hrvasN0MvoMxDS+7TycmKFVJxWUvJKAi7GG
         THSw==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20230601; t=1705047256; x=1705652056;
        h=content-transfer-encoding:cc:to:subject:message-id:date:from
         :in-reply-to:references:mime-version:x-gm-message-state:from:to:cc
         :subject:date:message-id:reply-to;
        bh=VKb3pXA3O7QJEj9qo6R8Br8Dqg0hH16HzN0jOTIU5CY=;
        b=pSQVM4QO7PfJsBLMz2pfd9Mfx6LlMVvuukkZ8yILIdRbeIIg2FAQMv62JPbiMw6yT+
         tJhtFXtD12SrH5bpn446IcpoqO4XCDURwo+5gjlbMNbkim0RbMnalis5eueovfxPb/FF
         fRa06YrJGqVT8Kl9FD+JanM3ERfldbGIIbqhFLGYrV2bgB/+dCuTqmjZHL1+f4g6ausL
         Dz2T3LbU1nKHfMgnHtYF1YlVZc3VMzitXxXKUrWsGplJpDjmKzszCv7c/4JNIHL8d/iN
         ZSyKiyNckVVslNnq7URC3eAPWsncwuUSzs2mRjm9IN8W8uqKmfJVn4/kPowNatR0+3di
         y17A==
X-Gm-Message-State: AOJu0YwJ9Kyw6OxL5pTaNT8LPYPtfv4+i2Vj0BWCDjLRgZtGNv1ZfcBW
	YBKngz+k2A8ufFsfuPvwkeDDYivQuKFnN6z5w1Ky2Xu1cOh+hQ==
X-Google-Smtp-Source: AGHT+IFiFE1mg3Ou42N8EKtfdnhiQN1fItrBbzyubruEBUXHkcUgv7iMSLfYfu4GiAjCUieiEfS7XXBwbT3DdXNntPk=
X-Received: by 2002:aa7:d859:0:b0:554:4dde:4ca6 with SMTP id
 f25-20020aa7d859000000b005544dde4ca6mr511278eds.4.1705047255771; Fri, 12 Jan
 2024 00:14:15 -0800 (PST)
Precedence: bulk
X-Mailing-List: linux-cxl@vger.kernel.org
List-Id: <linux-cxl.vger.kernel.org>
List-Subscribe: <mailto:linux-cxl+subscribe@vger.kernel.org>
List-Unsubscribe: <mailto:linux-cxl+unsubscribe@vger.kernel.org>
MIME-Version: 1.0
References: <87fs00njft.fsf@yhuang6-desk2.ccr.corp.intel.com>
 <PH0PR08MB7955E9F08CCB64F23963B5C3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87edezc5l1.fsf@yhuang6-desk2.ccr.corp.intel.com> <PH0PR08MB79550922630FEC47E4B4D3A3A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87a5pmddl5.fsf@yhuang6-desk2.ccr.corp.intel.com> <PH0PR08MB79552F35351FA57EF4BD64B4A860A@PH0PR08MB7955.namprd08.prod.outlook.com>
 <87wmspbpma.fsf@yhuang6-desk2.ccr.corp.intel.com> <ZZwrIoP9+ey7rp3C@memverge.com>
 <87o7dv897s.fsf@yhuang6-desk2.ccr.corp.intel.com> <20240109155049.00003f13@Huawei.com>
 <ZZ2Jd7/7rFD0o5S3@memverge.com> <CAAYibXhe81ez06tP5K7zGkX9P=Ot+DcSysVyDvh13aSEDD63aA@mail.gmail.com>
 <20240110141821.0000370d@Huawei.com> <CAAYibXgwqY6Og_4NqGGEni=2Xgx=DPxaMc3GdBUE6FREKVCq8w@mail.gmail.com>
 <87il3z2g03.fsf@yhuang6-desk2.ccr.corp.intel.com>
In-Reply-To: <87il3z2g03.fsf@yhuang6-desk2.ccr.corp.intel.com>
From: Hao Xiang <hao.xiang@bytedance.com>
Date: Fri, 12 Jan 2024 00:14:04 -0800
Message-ID: <CAAYibXh5DWcAJrqXi-V1v61DY_Xeb8BiMGoOxn1fJ_YBc2L8KQ@mail.gmail.com>
Subject: Re: [External] Re: [EXT] Re: [RFC PATCH v2 0/2] Node migration
 between memory tiers
To: "Huang, Ying" <ying.huang@intel.com>
Cc: "aneesh.kumar@linux.ibm.com" <aneesh.kumar@linux.ibm.com>, 
	Jonathan Cameron <Jonathan.Cameron@huawei.com>, Gregory Price <gregory.price@memverge.com>, 
	Srinivasulu Thanneeru <sthanneeru@micron.com>, Srinivasulu Opensrc <sthanneeru.opensrc@micron.com>, 
	"linux-cxl@vger.kernel.org" <linux-cxl@vger.kernel.org>, "linux-mm@kvack.org" <linux-mm@kvack.org>, 
	"dan.j.williams@intel.com" <dan.j.williams@intel.com>, "mhocko@suse.com" <mhocko@suse.com>, 
	"tj@kernel.org" <tj@kernel.org>, "john@jagalactic.com" <john@jagalactic.com>, 
	Eishan Mirakhur <emirakhur@micron.com>, Vinicius Tavares Petrucci <vtavarespetr@micron.com>, 
	Ravis OpenSrc <Ravis.OpenSrc@micron.com>, 
	"linux-kernel@vger.kernel.org" <linux-kernel@vger.kernel.org>, Johannes Weiner <hannes@cmpxchg.org>, 
	Wei Xu <weixugc@google.com>, "Ho-Ren (Jack) Chuang" <horenchuang@bytedance.com>
Content-Type: text/plain; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

On Thu, Jan 11, 2024 at 11:02=E2=80=AFPM Huang, Ying <ying.huang@intel.com>=
 wrote:
>
> Hao Xiang <hao.xiang@bytedance.com> writes:
>
> > On Wed, Jan 10, 2024 at 6:18=E2=80=AFAM Jonathan Cameron
> > <Jonathan.Cameron@huawei.com> wrote:
> >>
> >> On Tue, 9 Jan 2024 16:28:15 -0800
> >> Hao Xiang <hao.xiang@bytedance.com> wrote:
> >>
> >> > On Tue, Jan 9, 2024 at 9:59=E2=80=AFAM Gregory Price <gregory.price@=
memverge.com> wrote:
> >> > >
> >> > > On Tue, Jan 09, 2024 at 03:50:49PM +0000, Jonathan Cameron wrote:
> >> > > > On Tue, 09 Jan 2024 11:41:11 +0800
> >> > > > "Huang, Ying" <ying.huang@intel.com> wrote:
> >> > > > > Gregory Price <gregory.price@memverge.com> writes:
> >> > > > > > On Thu, Jan 04, 2024 at 02:05:01PM +0800, Huang, Ying wrote:
> >> > > > > It's possible to change the performance of a NUMA node changed=
, if we
> >> > > > > hot-remove a memory device, then hot-add another different mem=
ory
> >> > > > > device.  It's hoped that the CDAT changes too.
> >> > > >
> >> > > > Not supported, but ACPI has _HMA methods to in theory allow chan=
ging
> >> > > > HMAT values based on firmware notifications...  So we 'could' ma=
ke
> >> > > > it work for HMAT based description.
> >> > > >
> >> > > > Ultimately my current thinking is we'll end up emulating CXL typ=
e3
> >> > > > devices (hiding topology complexity) and you can update CDAT but
> >> > > > IIRC that is only meant to be for degraded situations - so if yo=
u
> >> > > > want multiple performance regions, CDAT should describe them for=
m the start.
> >> > > >
> >> > >
> >> > > That was my thought.  I don't think it's particularly *realistic* =
for
> >> > > HMAT/CDAT values to change at runtime, but I can imagine a case wh=
ere
> >> > > it could be valuable.
> >> > >
> >> > > > > > https://lore.kernel.org/linux-cxl/CAAYibXjZ0HSCqMrzXGv62cMLn=
cS_81R3e1uNV5Fu4CPm0zAtYw@mail.gmail.com/
> >> > > > > >
> >> > > > > > This group wants to enable passing CXL memory through to KVM=
/QEMU
> >> > > > > > (i.e. host CXL expander memory passed through to the guest),=
 and
> >> > > > > > allow the guest to apply memory tiering.
> >> > > > > >
> >> > > > > > There are multiple issues with this, presently:
> >> > > > > >
> >> > > > > > 1. The QEMU CXL virtual device is not and probably never wil=
l be
> >> > > > > >    performant enough to be a commodity class virtualization.
> >> > > >
> >> > > > I'd flex that a bit - we will end up with a solution for virtual=
ization but
> >> > > > it isn't the emulation that is there today because it's not poss=
ible to
> >> > > > emulate some of the topology in a peformant manner (interleaving=
 with sub
> >> > > > page granularity / interleaving at all (to a lesser degree)). Th=
ere are
> >> > > > ways to do better than we are today, but they start to look like
> >> > > > software dissagregated memory setups (think lots of page faults =
in the host).
> >> > > >
> >> > >
> >> > > Agreed, the emulated device as-is can't be the virtualization devi=
ce,
> >> > > but it doesn't mean it can't be the basis for it.
> >> > >
> >> > > My thought is, if you want to pass host CXL *memory* through to th=
e
> >> > > guest, you don't actually care to pass CXL *control* through to th=
e
> >> > > guest.  That control lies pretty squarely with the host/hypervisor=
.
> >> > >
> >> > > So, at least in theory, you can just cut the type3 device out of t=
he
> >> > > QEMU configuration entirely and just pass it through as a distinct=
 numa
> >> > > node with specific hmat qualities.
> >> > >
> >> > > Barring that, if we must go through the type3 device, the question=
 is
> >> > > how difficult would it be to just make a stripped down type3 devic=
e
> >> > > to provide the informational components, but hack off anything
> >> > > topology/interleave related? Then you just do direct passthrough a=
s you
> >> > > described below.
> >> > >
> >> > > qemu/kvm would report errors if you tried to touch the naughty bit=
s.
> >> > >
> >> > > The second question is... is that device "compliant" or does it ne=
ed
> >> > > super special handling from the kernel driver :D?  If what i descr=
ibed
> >> > > is not "compliant", then it's probably a bad idea, and KVM/QEMU sh=
ould
> >> > > just hide the CXL device entirely from the guest (for this use cas=
e)
> >> > > and just pass the memory through as a numa node.
> >> > >
> >> > > Which gets us back to: The memory-tiering component needs a way to
> >> > > place nodes in different tiers based on HMAT/CDAT/User Whim. All t=
hree
> >> > > of those seem like totally valid ways to go about it.
> >> > >
> >> > > > > >
> >> > > > > > 2. When passing memory through as an explicit NUMA node, but=
 not as
> >> > > > > >    part of a CXL memory device, the nodes are lumped togethe=
r in the
> >> > > > > >    DRAM tier.
> >> > > > > >
> >> > > > > > None of this has to do with firmware.
> >> > > > > >
> >> > > > > > Memory-type is an awful way of denoting membership of a tier=
, but we
> >> > > > > > have HMAT information that can be passed through via QEMU:
> >> > > > > >
> >> > > > > > -object memory-backend-ram,size=3D4G,id=3Dram-node0 \
> >> > > > > > -object memory-backend-ram,size=3D4G,id=3Dram-node1 \
> >> > > > > > -numa node,nodeid=3D0,cpus=3D0-4,memdev=3Dram-node0 \
> >> > > > > > -numa node,initiator=3D0,nodeid=3D1,memdev=3Dram-node1 \
> >> > > > > > -numa hmat-lb,initiator=3D0,target=3D0,hierarchy=3Dmemory,da=
ta-type=3Daccess-latency,latency=3D10 \
> >> > > > > > -numa hmat-lb,initiator=3D0,target=3D0,hierarchy=3Dmemory,da=
ta-type=3Daccess-bandwidth,bandwidth=3D10485760 \
> >> > > > > > -numa hmat-lb,initiator=3D0,target=3D1,hierarchy=3Dmemory,da=
ta-type=3Daccess-latency,latency=3D20 \
> >> > > > > > -numa hmat-lb,initiator=3D0,target=3D1,hierarchy=3Dmemory,da=
ta-type=3Daccess-bandwidth,bandwidth=3D5242880
> >> > > > > >
> >> > > > > > Not only would it be nice if we could change tier membership=
 based on
> >> > > > > > this data, it's realistically the only way to allow guests t=
o accomplish
> >> > > > > > memory tiering w/ KVM/QEMU and CXL memory passed through to =
the guest.
> >> > > >
> >> > > > This I fully agree with.  There will be systems with a bunch of =
normal DDR with different
> >> > > > access characteristics irrespective of CXL. + likely HMAT soluti=
ons will be used
> >> > > > before we get anything more complex in place for CXL.
> >> > > >
> >> > >
> >> > > Had not even considered this, but that's completely accurate as we=
ll.
> >> > >
> >> > > And more discretely: What of devices that don't provide HMAT/CDAT?=
 That
> >> > > isn't necessarily a violation of any standard.  There probably cou=
ld be
> >> > > a release valve for us to still make those devices useful.
> >> > >
> >> > > The concern I have with not implementing a movement mechanism *at =
all*
> >> > > is that a one-size-fits-all initial-placement heuristic feels gros=
s
> >> > > when we're, at least ideologically, moving toward "software define=
d memory".
> >> > >
> >> > > Personally I think the movement mechanism is a good idea that gets=
 folks
> >> > > where they're going sooner, and it doesn't hurt anything by existi=
ng. We
> >> > > can change the initial placement mechanism too.
> >> >
> >> > I think providing users a way to "FIX" the memory tiering is a backu=
p
> >> > option. Given that DDRs with different access characteristics provid=
e
> >> > the relevant CDAT/HMAT information, the kernel should be able to
> >> > correctly establish memory tiering on boot.
> >>
> >> Include hotplug and I'll be happier!  I know that's messy though.
> >>
> >> > Current memory tiering code has
> >> > 1) memory_tier_init() to iterate through all boot onlined memory
> >> > nodes. All nodes are assumed to be fast tier (adistance
> >> > MEMTIER_ADISTANCE_DRAM is used).
> >> > 2) dev_dax_kmem_probe to iterate through all devdax controlled memor=
y
> >> > nodes. This is the place the kernel reads the memory attributes from
> >> > HMAT and recognizes the memory nodes into the correct tier (devdax
> >> > controlled CXL, pmem, etc).
> >> > If we want DDRs with different memory characteristics to be put into
> >> > the correct tier (as in the guest VM memory tiering case), we probab=
ly
> >> > need a third path to iterate the boot onlined memory nodes and also =
be
> >> > able to read their memory attributes. I don't think we can do that i=
n
> >> > 1) because the ACPI subsystem is not yet initialized.
> >>
> >> Can we move it later in general?  Or drag HMAT parsing earlier?
> >> ACPI table availability is pretty early, it's just that we don't bothe=
r
> >> with HMAT because nothing early uses it.
> >> IIRC SRAT parsing occurs way before memory_tier_init() will be called.
> >
> > I tested the call sequence under a debugger earlier. hmat_init() is
> > called after memory_tier_init(). Let me poke around and see what our
> > options are.
>
> This sounds reasonable.
>
> Please keep in mind that we need a way to identify the base line memory
> type(default_dram_type).  A simple method is to use NUMA nodes with CPU
> attached.  But I remember that Aneesh said that some NUMA nodes without
> CPU will need to be put in default_dram_type too on their systems.  We
> need a way to identify that.

Yes, I am doing some prototyping the way you described. In
memory_tier_init(), we will just set the memory tier for the NUMA
nodes with CPU. In hmat_init(), I am trying to call back to mm to
finish the memory tier initialization for the CPUless NUMA nodes. If a
CPUless numa node can't get the effective adistance from
mt_calc_adistance(), we will fallback to add that node to
default_dram_type.
The other thing I want to experiment is to call mt_calc_adistance() on
a memory node with CPU and see what kind of adistance will be
returned.

>
> --
> Best Regards,
> Huang, Ying

